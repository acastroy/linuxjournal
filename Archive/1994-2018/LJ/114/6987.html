<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
Cooking with Linux</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;Make simple backups and keep every copy of your Web or FTP site up to date with some&#10;standard tools that probably are already on your system.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x23bd580.0x24b4ab0"></a>
Cooking with Linux</h1></div><div><h3 class="subtitle"><i>Mirror, Mirror, of It All</i></h3></div><div><div class="author"><h3 class="author">Marcel Gagn&eacute;</h3></div><div class="issuemoyr">Issue #114, October 2003</div></div><div><p>
Make simple backups and keep every copy of your Web or FTP site up to date with some
standard tools that probably are already on your system.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x23bd580.0x24b5348"></a></h2></div></div><p>
Fran&ccedil;ois, what are you doing? When I asked you to mirror our Web sites,
I did not mean that you should hold a mirror up to the screen. You can
be very silly, <span   class="foreignphrase"><i>mon ami</i></span>. What I meant was that you should make a
copy of our Web sites onto that other machine. Fran&ccedil;ois, what are you
looking at? Ah, our guests have arrived! Why did you not tell me?
Welcome, <span   class="foreignphrase"><i>mes amis</i></span>, to <span   class="foreignphrase"><i>Chez
Marcel</i></span>, home of fine Linux fare
and exceptional wines.
</p><p>
Speaking of wine, Fran&ccedil;ois! To the wine cellar,
<span   class="foreignphrase"><i>imm&eacute;diatement</i></span>.
Please bring back the 1999 California Stag's Leap District Cabernet
Sauvignon. This bold, smooth wine is the perfect mirror to today's
menu. As you know, <span   class="foreignphrase"><i>mes amis</i></span>, the theme of this issue is system
administration. On today's menu, we are going to sample a number of
alternatives for mirroring data. The reasons for mirroring data are many.
The obvious first reason is the not altogether sexy but extremely
important subject of backups. Other reasons include creating mirrors
of FTP sites for local network updates, such as your own RPM update
repository, or mirroring Web sites for fast, off-line reading.
</p><p>
Many people who do regular backups are doing them to a disk on
one of their other machines. Others still are backing up to a second
disk on the same machine. Given that an extra hard drive added to a
system is extremely inexpensive these days and high-capacity tape drives
can cost substantially more, it isn't that unusual to find this
kind of solution being used.
</p><p>
Backing up from one disk to the other, or creating a mirror of your data,
can be as simple as doing a recursive copy using <b  >cp</b>. For instance,
if I wanted to copy everything in my home directory to a second disk
with a lot of space, I might do the following:

<pre     class="programlisting">
cp -rfupv /home/mgagne /disk2/
</pre>
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x23bd580.0x24b57c0"></a></h2></div></div><p>
As you probably expect, the -r option indicates a recursive copy
(all the subdirectories), and the -v tells the command
to be verbose. Because I don't want to be warned about each file being
overwritten, I add -f to force the copy;
the -p ensures that permissions are saved properly as well.
Finally, the -u option tells the cp command to
copy only files that have been updated. This speeds up the process on
subsequent copies.
</p><p>
It all works very well, but copying from machine to machine requires a few extra
steps. With your Linux system, you actually have a lot of tools at your
disposal beyond the humble cp. For starters, if you want
to copy or back up an entire Web site, try the <b  >wget</b>
command, originally written by Hrvoje Niksic:

<pre     class="programlisting">
wget -m http://www.websitename.dom
</pre>
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x23bd580.0x24b59d0"></a></h2></div></div><p>
Starting at the top of your chosen Web site, wget walks through the entire site, saving all appropriate HTML files
and images. The -m in this case means mirror, but it also
encompasses several other options, specifically -r, -N,
-l inf and -nr. These options tell
wget to do a recursive fetch, turn on timestamps, allow for an
infinite number of levels and not to remove the FTP directory
.listing files, respectively.
</p><p>
All files on the Web site are saved in a local directory with
the same name as the Web site. In the example above, that would be
www.websitename.dom. Add a new file to your Web server, run the
command again and only that new file is transferred, thus making
the job of keeping things up to date that much faster.
</p><p>
This is a great tool for its intended purpose, but its
primary function is to deal with Web sites. It is possible, however,
to use wget to download from FTP servers as well. If you are
transferring from anonymous sites, the format is almost identical to
the one used to mirror a Web site:

<pre     class="programlisting">
wget -m ftp://ftp.ftpsitename.dom
</pre>
</p><p>
If, on the other hand, you want to back up a user directory where a
user name and password are required, you need to be a little fancier:


<pre     class="programlisting">

wget -m ftp://username:password@ftp.sitename.dom

</pre>
</p><p>
This approach has a couple downsides. First, your
password is sent across the network in plain text, which may not be
a big deal depending on how much you trust your network. In a pinch,
you could do a recursive secure copy with the <b  >scp</b> command.
Because scp is part of OpenSSH, you have the advantage of knowing
that you are using secure, encrypted file transfers. Pretend that you
want to copy your whole Web site, starting from the Apache server root.
It would look something like this:

<pre     class="programlisting">

scp -rpv /var/www root@remote_host:/mnt/backupdir

</pre>
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x23bd580.0x24b5df0"></a></h2></div></div><p>
The -r indicates a recursive copy, and the -p tells
scp to preserve modification times, ownership and permissions
from the original files and directories. If you are transferring large
amounts of data, you might consider using the -C option, which does compression on the fly. It can make a substantial difference
in throughput.
</p><p>
Possibly the biggest problem with all these methods of mirroring data
is it can take a great deal of time. wget will
download new files from an FTP server, but there is no option to keep a
directory entirely in sync by deleting files. Secure copy is nice, but
it doesn't have any mechanism for transferring only files that are changed.
That's the second downside. Making sure that the data stays in sync
without transferring every single file and directory requires a program
with a bit more finesse.
</p><p>
The best program I know for this is probably Andrew Tridgell's
rsync. <i  >Linux Journal</i>'s own Mick Bauer did a superb job
of covering this package in the March and April 2003 issues of this fine
magazine, so I won't go over it again other than to say you might want
to look up his two-parter on the subject.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x23bd580.0x24b6000"></a>ftpcopy</h2></div></div><p>
In many cases, that leaves us with our old friend, FTP&mdash;well, sort of.
On one side (the machine you want to mirror), you would use your FTP
server, whether it was ProFTPD or wu-ftpd. On the other side, you would
use Uwe Ohse's <b  >ftpcopy</b> program. ftpcopy is a fast,
easy-to-set-up
and easy-to-use program that does a nice job of copying entire directory
hierarchies. As it copies, it maintains permissions and modification dates
and times, and it does it fast. Furthermore, it keeps track of files that
already have been downloaded. This is handy because the next time you
run ftpcopy, it transfers only those files that have been changed,
thus making your backup even faster.
</p><p>
Some distributions come with ftpcopy, but
for the latest version of ftpcopy, go to <a href="http://www.ohse.de/uwe/ftpcopy/ftpcopy.html" target="_self">www.ohse.de/uwe/ftpcopy/ftpcopy.html</a> to pick up the download.
Building the package is easy and takes only a few steps:

<pre     class="programlisting">
tar -xzvf ftpcopy-0.6.2.tar.gz
cd web/ftpcopy-0.6.2
make
</pre>
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x23bd580.0x24b6268"></a></h2></div></div><p>
In the directory called command, you'll find three binaries:
ftpcopy, ftpcp and ftpls. You can run it
from here or copy the three files to /usr/local/bin or somewhere
else in your $PATH.
</p><p>
Here's how it works. Let's say I wanted to mirror or back up my
home directory on a remote system. A basic ftpcopy command looks something like this:

<pre     class="programlisting">
ftpcopy -u marcel -p secr3t! \
remote.hostname /home/marcel /mirdir/
</pre>
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x23bd580.0x24b6420"></a></h2></div></div><p>
The -u and -p options are obviously for my user name and
(fake) password on the remote system. What follows is the path to the
directory you want to copy and then the local directory where
this directory structure will be re-created. As the download progresses,
you will see something like this:

<pre     class="programlisting">
/mirdir/scripts/backup.log: download successful
/mirdir/scripts/checkhosts.pl: download successful
/mirdir/scripts/ftplogin.msg: download successful
/mirdir/scripts/gettime.pl: download successful
</pre>
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x23bd580.0x24b6580"></a></h2></div></div><p>
If you want a little more information on your download, add the
--bps option. The results then report the rate of data transfer
in bytes per second.
</p><p>
You should consider running ftpcopy with the --help
option at least once, and you should be aware of some options.
For instance, -s deals with symbolic links, and -l
lets you increase the level of logging. If you want to set mirroring
to run by means of a cron job, you might want to set logging to 0.
Another useful option is -n. If a file is
deleted on the remote side, it also will be deleted locally when you
run ftpcopy. If you truly are trying to keep systems in sync, this is
what you would want. To override this behavior, add -n
and no deletes will occur.
</p><p>
Well, <span   class="foreignphrase"><i>mes amis</i></span>, the hour has arrived, and we must all go to
our respective homes. Still, it is early enough for a final glass of
wine, <span   class="foreignphrase"><i>non</i></span>? Fran&ccedil;ois, <span   class="foreignphrase"><i>mon
ami</i></span>, if you will do the honors&mdash;in fact, make it two glasses, one to mirror the other,
<span   class="foreignphrase"><i>non</i></span>?
Until next time, <span   class="foreignphrase"><i>mes amis</i></span>, let us all drink to one another's health.
<span   class="foreignphrase"><i>A v&ocirc;tre sant&eacute; Bon app&eacute;tit!</i></span>!
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x23bd580.0x24b6948"></a></h2></div></div><div class="sidebar"><p class="title"><b>Resources</b></p><p>
ftpcopy: <a href="http://www.ohse.de/uwe/ftpcopy/ftpcopy.html" target="_self">www.ohse.de/uwe/ftpcopy/ftpcopy.html</a>
</p><p>
OpenSSH: <a href="http://www.openssh.org" target="_self">www.openssh.org</a>
</p><p>
rsync: <a href="http://rsync.samba.org" target="_self">rsync.samba.org</a>
</p><p>
wget: <a href="http://wget.sunsite.dk" target="_self">wget.sunsite.dk</a>
</p><p>
Marcel's Wine Page: <a href="http://www.marcelgagne.com/wine.html" target="_self">www.marcelgagne.com/wine.html</a>
</p></div></div></div>
<div class="authorblurb"><p>
Marcel Gagn&eacute; (<a href="mailto:mggagne@salmar.com">mggagne@salmar.com</a>) lives in Mississauga,
Ontario. He is the author of the newly published <span   class="emphasis"><em>Moving
to Linux: Kiss the Blue Screen of Death Goodbye!</em></span> (ISBN
0-321-15998-5) from Addison-Wesley. His first book is the highly
acclaimed <span   class="emphasis"><em>Linux System Administration: A User's Guide</em></span>
(ISBN 0-201-71934-7). In real life, he is president of Salmar Consulting,
Inc., a systems integration and network consulting firm.

</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../114/toc114.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>