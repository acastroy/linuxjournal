<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>Economical Fault-Tolerant Networks</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;    We present a software solution which achieves fault tolerance by&#10;    capitalizing on redundant replication of data and elimination of&#10;    any single point of failure and with transparent switchover.&#10;    "><meta name="keywords" content="network, fault, tolerance, redundant, data, replication, LAN, cluster"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x15f6580.0x16edab0"></a>Economical Fault-Tolerant Networks</h1></div><div><div class="authorgroup"><div class="author"><h3 class="author">Ali Raza Butt</h3></div><div class="author"><h3 class="author">Jahangir Hasan</h3></div><div class="author"><h3 class="author">Kamran Khalid</h3></div><div class="author"><h3 class="author">Farhan-ud-din Mirza</h3></div><div class="issuemoyr">Issue #74, June 2000</div></div></div><div><p>
    We present a software solution which achieves fault tolerance by
    capitalizing on redundant replication of data and elimination of
    any single point of failure and with transparent switchover.
    </p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16eed40"></a></h2></div></div><p>In the past decade or so, we have seen
the evolution of computer networks as a merger of the communication
and computing worlds. This revolution has made the dream of global
connectivity possible, and with it has brought an explosion in the
number of people utilizing computer networks for numerous vital
tasks. The sheer volume and importance of tasks being ported to
network-based applications and services has made reliability an
undeniable need. On the other hand, networks fail all the time for
a variety of reasons, including but not limited to power failures,
communication link breakdowns, hardware failures and software
crashes. Overcoming these failures and maintaining network services
to users is addressed by implementing fault tolerance.
</p><p>One common method for implementing fault tolerance is
redundant data replication. Employment of an exact copy in place of
a failed network component ensures availability of services on the
network. The process of fault detection and replacement must be
quick and automatic in order to make the fault invisible at the
client end.</p><p>Our solution bases itself on a cluster of identical Linux
servers, providing various network services. We did not employ any
additional links other than the standard network connectivity.
Various components within the solution include an algorithm to
select a successor to a failed component, and both clock and data
synchronization procedures among the processes. The services and
data are replicated on all computers within the cluster. In the
event of failure of a server, it is to be replaced by a replica,
which carries a redundant copy of all data and service
configurations offered by the crashed machine. After the detection
of a failure, an election process is enacted among the identical
servers and a replacement for the crashed server comes forward.
Under normal working conditions of the network, the current server
regularly pushes clock time, data and key configuration files to
the rest of the cluster in order to maintain them as peers.</p><p><a href="3907s3.html" target="_self">Terminology</a></p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16eefa8"></a>The Problem</h2></div></div><p>The standard techniques for improving the reliability of the
network can be divided into two broad groups.</p><div class="itemizedlist"><ul type="disc"><li><p>Dedicated hardware: this is expensive, and needs
special maintenance. Examples of such a method include RAID
(redundant array of inexpensive disks) and non-IP solutions
requiring secondary communication links between machines.</p></li><li><p>Secondary backup machines: these are machines
identical to the primary server and are maintained as mirrors of
the primary. Their major drawback is not their high cost, but that
under conditions of network failure, the switchover to the backup
machine is not transparent to the clients. In fact, the clients
need to be configured in advance with secondary (or slave) server
parameters. The clients for most of the services will usually try
the primary server first; then, on timeout, attempt to use the
secondary server. This introduces unnecessary overhead and delay.
Another important thing to note is that the backup machine is 100
percent redundant, used only when the primary server is under
fault.</p></li></ul></div><p>The problem is in achieving a software solution to ensure
reliability, without the need of additional hardware and to keep
the switchover transparent to the clients. Furthermore, we would
not like to waste resources by completely dedicating one or more
machines to a backup role.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16ef2c0"></a>Proposed Solution</h2></div></div><p>Our solution finds its roots in the already-established
backup system of primary and secondary servers. Instead of using
two computers, we employ a set of computers. One of these computers
is selected to act as a master machine to coordinate the network
services, while the rest assume the role of slave machines:
general-purpose server-class machines that take part in the
election. The master server sets up a virtual IP address and starts
all services required for normal operation of the network. The
slaves monitor the status of the master for failures. If a failure
occurs, a new master will be chosen and services to the network
restored; the change is transparent to the clients. The slaves are
not intended to be dedicated solely to this purpose; rather, they
may be employed to perform other tasks (compute servers,
workstations, etc.). Only on being chosen master does a machine
also take on the task of establishing the virtual server.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16ef3c8"></a>Selection of the Master</h2></div></div><p>The most crucial task in the event of failure is the
selection of a new master machine. It is not possible to predict
which machines in the chain would be unavailable due to earlier
failures or being switched off. Therefore, a simple pre-established
hierarchy of switchover, like the one in primary/secondary servers,
is not practical. Moreover, a single coordinator for selecting a
master cannot be used, because failure of this coordinator would
result in total failure of the network.</p><p>With these facts in mind, we used a distributed election
algorithm to select the appropriate successor to the dead master.
Election algorithms are widely used to select a coordinator process
in parallel and distributed computing. Initially, we tried the
&ldquo;Bully Election&rdquo; algorithm. (See Resources.) This suffers from a
handicap in that when a failed master is fixed and brought back
into the network, it bullies the already-established master into
handing over services. This creates an unnecessary switchover and
results in loss of newer and updated data, besides causing network
delay. The data loss occurs because updates may have been made in
the new master machine, and when the original crashed master
revives, it does not have the updated data.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16ef528"></a>Modified Bully Election Algorithm</h2></div></div><p></p><p>
<div       class="mediaobject"><a href="3907f1.large.jpg"><img src="3907f1.jpg"></a><div class="caption"><p>Figure 1. Election Algorithm</p></div></div>
</p><p>The &ldquo;Modified Bully Election&rdquo; algorithm is our modification
of the basic Bully Election algorithm. Assume a stable network in
which an array of servers is available. One of these machines is
acting as the master machine and providing services to the network.
The master server also multicasts a &ldquo;heartbeat&rdquo; signal to all
slaves, apprising them of its existence. All the machines are
assigned a performance index number. This number depends on various
parameters such as processor speed, availability of latest data,
available resources, etc. It may be dynamically assigned at each
election, or in the simplest case, is an IP address. The higher the
sequence number of a machine, the more it is suitable to act as the
master server.</p><p>Now, assume a fault occurs, causing the master to crash. The
rest of the machines detect its failure from the absence of the
heartbeat and move into the election state. In this state, a
machine sends election calls to all those with a higher index
number than it has. If a higher-indexed machine is available, it
will reply to this election call. On receiving an election reply,
the machine moves into a &ldquo;bind-wait&rdquo; state. If a machine in
election state receives no reply within a specified amount of time,
it concludes that it has the highest index number. It then moves
into &ldquo;init&rdquo; state. In this state, it starts the interrupted
network services and resumes the heartbeat signal. It also sends a
bind signal to other machines, moving them into slave state.
Finally, it moves itself into master state, and the network becomes
stable again.</p><p>
<div       class="mediaobject"><a href="3907f2.large.jpg"><img src="3907f2.jpg"></a><div class="caption"><p>Figure 2. State Diagram</p></div></div>
</p><p>After receiving election replies, if the lower-numbered
machines are unable to reach the slave state within a specified
time, the election is timed out and restarted. Hence, this
distributed process will elect a master under any sequence of
failure. If the failed master is now fixed and brought up again, it
will not initiate an election. In fact, it starts by listening to
the heartbeat. If a master is found, it simply moves to slave state
until the next failure occurs.</p><p>Our modification of the original Bully Election algorithm is
that the computer with the highest index number is not necessarily
the master at all times. In the original algorithm, a
higher-index-number machine will always call for re-election and
take control whenever it appears, regardless of the state of the
network. In our case, this bullying procedure was found to be
impractical for actual implementation. We implemented a variation,
such that a stable network with a master will not be disturbed when
a higher-indexed computer revives. It detects the presence of a
master during startup, and on finding one, moves into slave state.
Only if a new election is initiated will the highest-indexed
machine take over. The current master is always the winner of the
most recent election, and thus of the highest-indexed machine alive
at that time but not necessarily at the current time.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16efbb0"></a>The Two-Master Problem</h2></div></div><p>A direct consequence of not including the bullying part in
the election algorithm is the possibility of the existence of two
masters. As we are relying on the master to take control of a key
IP address as virtual server, two masters are simply unacceptable.
Such a problem may occur when a master is isolated due to network
congestion, the other machines conclude it dead and elect another
master. As the congestion resolves and the original master
reappears, there will be two masters. A very simple technique to
overcome this is that all machines monitor the source of the
heartbeat signal. If it is not found to be unique, a re-election is
done, resulting in a single master once again.</p><p>By following this algorithm, we are able to facilitate the
infallible presence of a working master server on the network.
Since it is a distributed implementation, failure of any single
component does not affect the election. Hence, various services can
be continuously provided to the network.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16e65a0"></a>Virtual Server</h2></div></div><p></p><p>
<div       class="mediaobject"><a href="3907f3.large.jpg"><img src="3907f3.jpg"></a><div class="caption"><p>Figure 3. Virtual Server Diagram</p></div></div>
</p><p>The election process elects a master, but we are still far
from making this change of masters transparent at the client end.
In order to achieve transparency, we choose an arbitrary IP address
henceforth referred to as the virtual server address. This address
is not that of a machine in the cluster, but a separate one. All
the clients are configured to use the virtual server address for
requesting services. Whenever a machine becomes master, it takes
over the virtual server address and continues with its original. IP
aliasing is used to achieve this, i.e., assigning more than one IP
address to a single network adapter. The new master then starts
providing the network services previously provided by the failed
master. Thus, the virtual server is always available, powered by
any of the machines taking part in the election process. Since the
clients always communicate with the virtual server, the proceedings
of the fault-tolerance algorithm remain invisible to them.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16e6910"></a>Machine Address Problem</h2></div></div><p>The newly elected master server quietly takes over the
virtual server address. However, the clients already have an
address resolution protocol (ARP) cache entry connecting the
virtual server IP address to the machine address (MAC) of the
failed master. This cache would inhibit a client from communicating
with the newer master, because the client would still try to
communicate with the old MAC address. One solution which overcomes
this problem is having an arbitrary MAC address be selected and
taken over by elected masters. The problem with this approach is
that not all network adapters support this function. Another
solution would be to bluntly dump the ARP cache of all the clients
and then reset the cache, which is also not an efficient
technique.</p><p>The method we devised is to delete the virtual server IP
address entry in the ARP cache of the newly elected master. Now the
master automatically tries to update its ARP cache. In this
process, it contacts the machines on the network, clients as well
as slave servers. This not only updates the master's ARP cache, but
also that of the clients. The advantage of this technique is that
our software does not have to send special update packets to each
computer&mdash;the already-working ARP mechanism does that for
us.</p><p>Updating the ARP cache, followed by the IP address takeover,
transparently causes the client to request services from the newly
elected master. The clients may experience some delay while the
actual election takes place, but other than that, they continue
uninterrupted.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16e6ac8"></a>Maintaining Peers</h2></div></div><p>A very critical perspective of the whole switchover scenario
is that the machines should be maintained identically. Only then
will the switchover become truly transparent. Steps must be taken
to ensure that in the event of a failure, the likely new masters
would have as much updated data as possible. Two important aspects
of maintaining the peers are time and file synchronization.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16e6bd0"></a>Time Synchronization</h2></div></div><p>Important and critical files need to be circulated on all the
servers. Any server could have been a master, and might have newer
versions of files. Thus, it becomes imperative that the servers be
time synchronized, so that their file timestamps are comparable.
This ensures that only the updated versions are distributed at the
time of file synchronization. An important thing to note is that
the time does not have to be matched with the real time. The only
requirement is that all the servers have the same time. We relied
on simply setting the clock to the time of the master server, using
a remote shell procedure. No special time servers were used,
although running NTPD or TIMED would have been a better
technique.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16e6cd8"></a>File Synchronization</h2></div></div><p>Another important task in maintaining peers is performing
synchronization and replication of data over the entire array of
servers in order to keep them consistently identical. The
replication process is time consuming and often congests the
network. The frequency of replication should be high enough to
accommodate replacement transparency and minimize data losses
during switchovers, while simultaneously low enough to allow proper
network operation without undue congestion.</p><p>In a very dynamic scenario, it may not be possible to
continuously distribute the updates on all machines taking part in
an election. In such a situation, a switchover may cause a
retrograde to the last synchronized version of files. Typically,
the synchronization is scheduled during low workload hours.
Additionally, instead of making backups, data is now distributed to
the server array which better serves the purpose.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16e6e38"></a>Implementation</h2></div></div><p>Having discussed various necessary aspects of the software
solution, we move on to its description. We implemented this
solution using Perl 5.0 running on Red Hat Linux 6.0. Owing to the
portability of Perl, the software runs on any version of Linux/UNIX
with minor or no changes. The program is implemented as a daemon
that is initiated at startup of the servers. It moves to the
background after spawning four processes:</p><div class="itemizedlist"><ul type="disc"><li><p>Heartbeat listener process for processing heartbeat
signals generated by the master server.</p></li><li><p>Listener process for receiving and parsing various
signals generated from other servers.</p></li><li><p>Doctor process to interpret the heartbeat signal
and decide whether the master server has failed.</p></li><li><p>Elector process to actually implement the election
algorithm and decide which actions need to be taken. It also
generates a heartbeat signal if running on a master server.</p></li></ul></div><p>The main daemon is supplemented with special scripts to
handle startup and synchronization. Separate scripts are created
for master and slave servers. This makes the configuration of
startup services on both master and slave servers very easy.
</p><p>Besides subordinate scripts, a host of scripts is provided
for file synchronization and distribution. They may be initiated
for scheduled synchronization and backup.</p><p>We employed UDP communication for heartbeat signals in order
to minimize network load. For election calls and other signals, TCP
is used to ensure reliability.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16e7360"></a>Security</h2></div></div><p>If unchecked, any alien machine can generate an election call
and the servers will move into an unwanted election state. For this
reason, security and integrity of the signals exchanged between
servers is highly stressed. We have implemented three levels of
security for safe operation.</p><div class="itemizedlist"><ul type="disc"><li><p>Level 1: a list of all servers taking part in the
election is maintained at all servers. Only signals from these
machines are accepted; all other messages related to the election
process are discarded.</p></li><li><p>Level 2: the servers are state-oriented. That is,
they acquire certain states, e.g., election state, master state,
etc. In every state, some signals are anticipated and only these
are accepted. Any other signal received, even originating from
listed servers, is discarded.</p></li><li><p>Level 3: an encryption scheme is used to encrypt
all the signals. A random key is created for encryption and is
valid for only one message. Therefore, even if a signal is
intercepted and cracked, the encryption key will not be valid at
any other time.</p></li></ul></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16e76d0"></a>Results</h2></div></div><p>For our implementation, we empirically found that weekly
synchronization of large data suffices, while the password
databases are replicated on every election. Other scenarios may
require a more frequent synchronization.</p><p>The level of reliability and fault tolerance of the cluster
increases in proportion to the size of the cluster. Increasing the
number of servers increases the maintenance time for
synchronization and unduly lengthens the election process. In our
situation, we determined from experimenting that three to four
servers are enough to guarantee a practical working
solution.</p><p>On average, the slave servers are negligibly loaded, while
the master servers are not loaded for more than 0.1% of the CPU
usage. Network load is also very low, except during heavy
synchronization, which is therefore run as a scheduled
process.</p><p>Our test bed for this implementation is the Digital Computer
Laboratory, UET, Lahore, Pakistan. The lab consists of 10
Pentium-based servers and 60 diskless workstations connected by
10MBps Ethernet.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16e78e0"></a>Future Directions</h2></div></div><p>There is a need for development and implementation of
techniques that provide for an immediate synchronization. One
method could be that whenever a file is updated, all the servers
update their versions of the file. In this way, all data on all
servers at all times is perfectly synchronized, thus eliminating
heavy network/server loads during scheduled synchronization.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x15f6580.0x16e79e8"></a>Conclusions</h2></div></div><p>This technique is a practical and feasible implementation of
fault tolerance for low-budget LANs running open-source operating
systems, such as in developing countries and resource-scarce
academic institutions where expensive commercial solutions are just
that&mdash;expensive.</p><p><a href="3907s1.html" target="_self">Acknowledgements</a></p><p><a href="3907s2.html" target="_self">Resources</a></p></div></div>
<div class="authorblurb"><p>
          <div       class="mediaobject"><img src="3907aa.jpg"></div>
          <span   class="bold"><b>Ali Raza Butt</b></span> (<a href="mailto:drewrobb@mediaone.net">drewrobb@mediaone.net</a>),
          is a final-year student of EE-Communication Systems at UET, Lahore, Pakistan.
          Ali and the other authors are project group fellows for implementing this work and system
          administrators of the computer lab.
          Ali loves to program for network management and build PC-controlled gizmos.
        </p><p>
          <span   class="bold"><b>Jahangir Hasan</b></span>
          is a final-year student of EE-Communication Systems at UET, Lahore, Pakistan.
        </p><p>
          <span   class="bold"><b>Kamran Khalid</b></span>
          is a final-year student of EE-Communication Systems at UET, Lahore, Pakistan.
        </p><p>
          <span   class="bold"><b>Farhan-ud-din Mirza</b></span>
          is a final-year student of EE-Communication Systems at UET, Lahore, Pakistan.
        </p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../074/toc074.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>