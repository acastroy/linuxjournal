<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>Transform Methods and Image Compression</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;    An introduction to JPEG and wavelet transform techniques&#10;    using Octave and Matlab.&#10;    "><meta name="keywords" content="image, JPG, Matlab, Octave, script, programming"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0xbe2580.0xcd9ab0"></a>Transform Methods and Image Compression</h1></div><div><div class="authorgroup"><div class="author"><h3 class="author">Greg A. Harris</h3></div><div class="author"><h3 class="author">Darrel Hankerson</h3></div><div class="issuemoyr">Issue #57, January 1999</div></div></div><div><p>
    An introduction to JPEG and wavelet transform techniques
    using Octave and Matlab.
    </p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xbe2580.0xcda870"></a></h2></div></div><p>This article has its origins in a data
compression course we've been developing over the past few years at
Auburn University. The course is elementary and begins with the
basic (text) compression methods of Shannon and Huffman. Some of
these methods can be appreciated with pencil-and-paper examples;
others, such as images to be modified by compression, need some
machine experimentation.
</p><p>Students may choose to present a project as part of their
course evaluation. We've seen various projects, including an
amusing example of Huffman-on-a-hand-calculator, an overview
presentation of PNG (Portable Network Graphics) and a project
concerning smoothing in JPEG.</p><p>We will introduce the transform techniques of JPEG and
wavelets, discuss some mathematical themes shared by these methods,
and illustrate the use of a high-level linear algebra package in
understanding such schemes. The images were generated using Octave
and Matlab, primarily on GNU/Linux (x86) and Solaris (SPARC), but
also on a Macintosh.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xbe2580.0xcdaa28"></a>Image Compression and Transforms</h2></div></div><p>Data compression methods with zero information loss have been
used on image data for some time. In fact, the popular GIF format
uses an LZW scheme (the basic method used in UNIX
<span   class="emphasis"><em>compress</em></span>) to compress 256-color images. PNG is
more sophisticated and capable, using a predictor (or filter) to
prepare the data for a <span   class="emphasis"><em>gzip</em></span>-style compressor.
(Greg Roelofs has an introduction to PNG and some notes on patent
questions concerning GIF [see Resources 8].) However, applications
using high-resolution images with thousands of colors may require
more compression than can be achieved with these
<span   class="emphasis"><em>lossless</em></span> methods.</p><p><span   class="emphasis"><em>Lossy</em></span> schemes discard some of the data
in order to obtain better compression. The problem, of course, is
deciding just which information is to be compromised. Loss of
information in compressing text is typically unacceptable, although
simple schemes such as elimination of every vowel from English text
may find application somewhere. The situation is different with
images and sound; in those cases, some loss of data may be quite
acceptable, even imperceptible.</p><p>In the 1980s, the Joint Photographic Experts Group (JPEG) was
formed to develop standards for still-image compression. The
specification includes both lossless and lossy modes, although the
latter is perhaps of the most interest (and is usually what is
meant by &ldquo;JPEG compression&rdquo;). G. K. Wallace has a paper (see
Resources 10) discussing the standard in some detail.</p><p>The method in lossy JPEG depends on an important mathematical
and physical theme for its compression: local approximation. The
JPEG group took this idea and fine-tuned it with results gained
from studies on the human visual system. The resulting scheme
enjoys wide use, in part because it is an open standard but mostly
because it does well on a large class of images, with fairly modest
resource requirements.</p><p>JPEG and wavelet schemes fall under the general category of
transform methods. The development of wavelet techniques has taken
place more recently than the classical method in JPEG, and is a
consequence of the never-ending search for &ldquo;better&rdquo; basic
images.</p><p>Roughly speaking, the first step in lossy compression schemes
like JPEG and wavelets is to break down an image into a weighted
sequence of simpler, more basic images. At this stage, the image
may be reconstructed <span   class="emphasis"><em>exactly</em></span> from knowledge of
the basic images and their corresponding weights. The effectiveness
of the method depends to a great extent on the choice of the basic
images. Once a set of basic images, or <span   class="emphasis"><em>basis</em></span>,
has been chosen, arbitrary images can be replaced by equivalent
collections of weights. A basic image having a correspondingly
large weight is an indication of its characteristic importance in
the overall image. (The assumption here is that the basis images
have been <span   class="emphasis"><em>normalized</em></span>, so that they have the
same mathematical size.)</p><p>The mathematics behind this process is expressed in the
language of linear algebra. There is considerable mathematical
freedom in the choice of basis images; however, in practice they
are usually chosen to exhibit features intrinsic to the class of
images of interest. For example, JPEG chooses basic images designed
to reflect certain classical spatial frequencies.</p><p>The process of using a basis to resolve an image into a
collection of weights is called a <span   class="emphasis"><em>transform</em></span>.
To simplify things, we'll consider gray-scale images (color is
discussed briefly in the conclusion), which can be represented as
<b  >mxn</b>
arrays of integers. The range of values isn't important in
understanding the mathematical ideas, although it is common to
restrict values to the interval <b  >[0,255]</b>, giving
a total of 256 levels of gray. As an example, Figure 3(a) shows an
image containing <b  >256x256</b> pixels with 145 shades
of gray represented.</p><p>Mathematically, any basis for the space of
<b  >mxn</b>
gray-scale images must contain exactly
<b  >mn</b> images&mdash;the number
of pixels in an
<b  >mxn</b>
image. Consequently, the transform of an
<b  >mxn</b>
image will have <b  >mn</b>
weights. The weights can be conveniently arranged into an
<b  >mxn</b>
array called the <span   class="emphasis"><em>transformed image</em></span> even though
it isn't a true image at all.</p><p>The transformation process, in itself, is certainly not a
compression technique (since the transformed image is the same size
as the original), but it can lead to one. Suppose the basis images
can be chosen so that, for a wide class of images, many of the
weights turn out to be small: for a given image, set these small
weights to zero and use the resulting array of modified weights to
represent it. Since the transform of the image has been modified,
it can be used only to approximate the original. How good is the
approximation? That depends on how good the scheme is for throwing
out nonzero weights, that is, on the appropriateness of the basis
elements and the number of weights which can be discarded. JPEG and
wavelet methods both employ this type of process and offer
significant compression benefits, often with minimal impact on the
quality of the reproduction. They differ in the choice of basis
images, i.e., in the transform used, and subsequently in the method
used to discard small weights. However, both share the idea of
picking a basis that can efficiently represent an image, often
using only a small number of its basic images.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xbe2580.0xcdb478"></a>The Cosine Transform and JPEG</h2></div></div><p>In this section, several examples using the <span   class="emphasis"><em>cosine
transform</em></span> are presented. This transform is used by JPEG,
applied to <b  >8x8</b> portions of an image. An
<b  >NxN</b>
cosine transform exists for every
<b  >N</b>, which exchanges
spatial information for frequency information. For the case
<b  >N=4</b>, a given
<b  >4x4</b> portion of an image can be written as a
linear combination of the 16 basis images which appear in Figure
1(a).</p><div       class="mediaobject"><img src="2567f1.jpg"></div><p>The transform provides the coefficients in the linear
combination, allowing approximations or adjustments to the original
image based on frequency content. One possibility is simply to
eliminate certain frequencies, obtaining a kind of partial sum
approximation. The implicit assumption in JPEG, for example, is
that the higher-frequency information in an image tends to be of
less importance to the eye.</p><p>The images in Figure 1 can be obtained from the scripts
supplied on our web site (see Resources 4) as follows. We'll use
&ldquo;&gt;&rdquo; to denote the prompt printed by Matlab or Octave, but this
will vary by platform.</p><p>Define the test image:</p><pre     class="programlisting">
&gt; x = round(rand(4)*50) % 4x4 random matrix,
                       % integer entries in
[0,50]
</pre><p>This will display some (random) matrix, perhaps</p><pre     class="programlisting">
    | 10 20 10 41 |
    | 40 30 2  12 |
    | 20 35 20 15 |
</pre><p>and we can view this &ldquo;image&rdquo; with the instructions:</p><pre     class="programlisting">
&gt; imagesc(x);      % Matlab users
&gt; imagesc(x, 8);   % Octave users
</pre><p>Something similar to the smaller image at the lower left in Figure
1(b) will be displayed. (We chose the <b  >4x4</b>
example for clarity; however, the viewer in Octave may fail to
display it properly. In this case, either the image can be padded
before display or a larger image can be chosen.) Now ask for the
matrix of partial sums (the larger image in Figure 1(b)):</p><pre     class="programlisting">
&gt; imagesc(psumgrid(x)); % Display the 16 partial
                        % sums
</pre><p>The partial sums are built up from the basis elements in the
order shown in the zigzag sequence above. This path through Figure
1(a) is based on increasing frequency of the basis elements.
Roughly speaking, the artificial image in Figure 1(b) is the worst
kind as far as JPEG compression is concerned. Since it is random,
it will likely have significant high-frequency terms. We can see
these by performing the discrete cosine transform:</p><pre     class="programlisting">
&gt; Tx = dct(x, 4) % 4
                 % of x
</pre><p>For the example above, this gives the matrix</p><pre     class="programlisting">
     | 79.25   9.47  4.75 -11.77 |
     |  6.25 -19.69 -4.25 -11.60 |
     |  5.97   8.02 12.73 -15.64 |
</pre><p>of coefficients used to build the partial sums in Figure 1 from the
basis elements. The top left entry gets special recognition as the
<span   class="emphasis"><em>DC coefficient</em></span>, representing the average gray
level; the others are the <span   class="emphasis"><em>AC coefficients</em></span>,
AC0,1 through AC3,3.</p><p>The terms in the lower right of
<b  >Tx</b> correspond to the
high-frequency portion of the image. Notice that even in this
&ldquo;worst case&rdquo;, Figure 1 suggests that a fairly good image can be
obtained without using all 16 terms.</p><div       class="mediaobject"><img src="2567f2.jpg"></div><p>The process of approximation by partial sums is applied to a
&ldquo;real&rdquo; image in Figure 2, where <b  >1/4</b>,
<b  >1/2</b> and <b  >3/4</b> of the 1024 terms
for a <b  >32x32</b> image are displayed. These can be
generated with calls of the form:</p><pre     class="programlisting">
&gt; x = getpgm('math4.pgm'); % Get a graymap image
&gt; n = length(x);        % n is the number of rows
                        % in the square image
&gt; y = psum(x, n*n / 2); % y is the partial sum
                        % using 1/2 of the terms
&gt; imagesc(y);           % Display the result
</pre><p>Our approximations retain all of the frequency information
corresponding to terms from the zigzag sequence below some selected
threshold value; the remaining higher-frequency information is
discarded. Although this can be considered a special case of a
JPEG-like scheme, JPEG allows more sophisticated use of the
frequency information.</p><p>JPEG exploits the idea of local approximation for its
compression: <b  >8x8</b> portions of the complete image
are transformed using the cosine transform, then each block is
<span   class="emphasis"><em>quantized</em></span> by a method which tends to suppress
higher-frequency elements and reduce the number of bits required
for each term. To &ldquo;recover&rdquo; the image, a dequantizing step is
used, followed by an inverse transform. (We've ignored the portion
of JPEG which does lossless compression on the output of the
quantizer, but this doesn't affect the image quality.) The matrix
operations can be diagrammed as:</p><p></p><pre     class="programlisting">
  transform    quantize     dequantize     invert
<span   class="emphasis"><em>x</em></span>  ------&gt;  <span   class="emphasis"><em>Tx</em></span>  -----&gt;  <span   class="emphasis"><em>QTx</em></span>  -------&gt; <span   class="emphasis"><em>Ty</em></span>  ---&gt; <span   class="emphasis"><em>y</em></span>
</pre><p>In Octave or Matlab, the individual steps can be written:</p><pre     class="programlisting">
&gt; x = getpgm('bird.pgm'); % Get a graymap image
&gt; Tx = dct(x);       % Do the 8
&gt; QTx = quant(Tx);   % Quantize, using standard
                     % 8
&gt; Ty = dequant(QTx); % Dequantize
&gt; y = invdct(Ty);    % Recover the image
&gt; imagesc(y);        % Display the image
</pre><p>To be precise, a rounding procedure should be done on the matrix
<b  >y</b>. In addition, we have ignored the zero-shift
specified in the standard, which affects the quantized DC
coefficients.</p><p>It should be emphasized that we cannot recover the image
completely&mdash;there has been loss of information at the quantizing
stage. It is illustrative to compare the matrices
<b  >x</b> and
<b  >y</b>, and the difference
image <b  >x-y</b> for this
kind of experiment appears in Figure 3(f). There is considerable
interest in measuring the &ldquo;loss of image quality&rdquo; using some
function of these matrices. This is a difficult problem given the
complexity of the human visual system.</p><p>The images in Figure 3 were generated at several &ldquo;quality&rdquo;
levels, using software from the Independent JPEG Group (see
Resources 5). The sizes are given in bits per pixel (bpp); i.e.,
the number of bits, on average, required to store each of the
numbers in the matrix representation of the image. The sizes for
the GIF and PNG versions are included for reference. (&ldquo;Bird&rdquo; is
part of a proposed collection of standard images at the Waterloo
BragZone [see Resources 11] and has been modified for the purposes
of this article.)</p><div       class="mediaobject"><img src="2567f3.jpg"></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xbe2580.0xcd3308"></a>A JPEG Enhancement</h2></div></div><p>One troublesome aspect of JPEG-like schemes is the appearance
of &ldquo;blocking artifacts,&rdquo; the telltale discontinuities between
blocks which often follow aggressive quantizing. The image on the
left in Figure 6 was produced using a scalar multiple of the
suggested luminance quantizer. Clearly visible blocks can be seen,
especially in the &ldquo;smoother&rdquo; areas of the image.</p><p>JPEG operates on individual <b  >8x8</b> blocks in
the image and processes them independently. There can be
significant loss of detail information within the individual blocks
if the quantizing is aggressive. The cosine transform used in JPEG
has properties which may (indirectly) help smooth the transition
between neighboring blocks; however, the tracks of the
block-by-block processing can be apparent when the blocks are
reassembled and the image restored. In this case, it may be
desirable to implement a smoothing scheme as part of the
restoration process. This section considers the back-end smoothing
procedure discussed in the book <span   class="emphasis"><em>JPEG Still Image Data
Compression Standard</em></span> (see Resources 7).</p><p>The JPEG decompresser may have only rough estimates about
much of the original frequency information, but it typically has
fairly good estimates of the average level of gray in each original
<b  >8x8</b> block (because of the way quantizers are
chosen). The idea is to use the average gray (DC-coefficient)
information of its nearest neighbors to adjust a given block's
(AC-coefficient) frequency information. Figure 4 illustrates the
process with a single &ldquo;superblock&rdquo; consisting of a center
<b  >8x8</b> image and its nearest neighbors. The center
block in the image on the right has been &ldquo;smoothed&rdquo; by the
influence of its nearest neighbors (the surrounding eight
<b  >8x8</b> blocks).</p><div       class="mediaobject"><img src="2567f4.jpg"></div><p>The process on a more complicated image is illustrated in
Figure 5. Here, the image is plotted as a surface where, at each
pixel <b  >(y,x)</b>, the
height of the surface represents the gray value. For a given
<b  >8x8</b> block, the <b  >3x3</b> superblock
consisting of its nearest neighbors contains
<b  >3282</b> total entries. The polynomial</p><pre     class="programlisting">
         + <span   class="emphasis"><em>a</em></span>6<span   class="emphasis"><em>y</em></span>2 + <span   class="emphasis"><em>a</em></span>7<span   class="emphasis"><em>x</em></span> + <span   class="emphasis"><em>a</em></span>8<span   class="emphasis"><em>y</em></span> + <span   class="emphasis"><em>a</em></span>9
</pre><p>is fitted by requiring that the average value over each
subblock matches the average gray estimate (this gives nine
equations for the unknowns
<b  >a1,...,a9</b>).
The polynomial defines a surface over the center block, which
approximates the corresponding portion of the original surface.
Figure 5 shows a surface in (a) and its polynomial approximation in
(b).
</p><div       class="mediaobject"><img src="2567f5.jpg"></div><p>The JPEG decompresser can perform the transform procedure on
a polynomial approximation, obtaining a set of predictors for the
frequency information of the original image. The original estimates
passed by the compressor can be adjusted using these predictors in
the hope of reducing the blocking problem.</p><p>In Figure 5, the lowest five frequencies were considered for
adjustment by the predictors: zero values passed by the compressor
were replaced by the predicted values (subject to a certain
clamping). The procedure applied to an aggressively-quantized bird
image appears in Figure 6. The deblock.m script (see Resources 4)
performs the smoothing. The following code was used to generate the
right-hand image:</p><pre     class="programlisting">
&gt; x = getpgm('bird.pgm'); % Get a graymap image
&gt; Tx = dct(x);       % Do the 8
&gt; QTx = quant(Tx, 4*stdQ); % Quantize, using
                           % 4*luminance
&gt; Ty = dequant(QTx);       % Dequantize
&gt; Tz = deblock(Ty);        % Smooth
&gt; z = invdct(Tz);          % Recover the image
&gt; imagesc(z);              % Display the image
</pre><div       class="mediaobject"><img src="2567f6.jpg"></div><p>This kind of smoothing scheme is attractive, in part because
of its simplicity and the fact that it can be used as a back-end
procedure to JPEG (regardless of whether the original file was
compressed with this in mind). However, JPEG achieves its rather
impressive compression by discarding information. The smoothing
procedure sometimes makes good guesses about the missing data, but
it cannot recover the original information.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xbe2580.0xcd4018"></a>A Wavelet Example</h2></div></div><p>Features of a signal we wish to examine can guide us in our
quest for the &ldquo;right&rdquo; basis vectors. For example, the cosine
transform is an offspring of the Fourier transform, the development
of which was, in a sense, a consequence of the search for basic
frequencies with which periodic signals could be resolved.</p><p>The Fourier transform is an indispensable tool in the realm
of signal analysis. When used as a compression device, we might
wish it had the additional capacity of being able to highlight
local frequency information&mdash;generally, it doesn't. The weights
given by the Fourier expansion of a signal may yield information
about the overall strength of the frequencies, but the information
is global. Even if a weight is substantial, it doesn't normally
give us any clue as to the location of the &ldquo;time interval&rdquo; over
which the corresponding frequency is significant.</p><p>The interest in and use of wavelet transforms has grown
appreciably in recent years since Ingrid Daubechies (see Resources
1) demonstrated the existence of continuous (and smoother) wavelets
with compact support. They have found homes as theoretical devices
in mathematics and physics and as practical tools applied to a
myriad of areas, including the analysis of surfaces, image editing
and querying and, of course, image compression.</p><p>In this section, we present an example using the
<span   class="emphasis"><em>Haar</em></span> wavelet, which in one sense is the
simplest of wavelets. The 16 basis elements in Figure 7 form a
basis for the set of <b  >4x4</b> images. Compare these
with the cosine transform elements in Figure 1. One can begin to
see the formation of elements with localized supports even at this
&ldquo;coarse&rdquo; resolution level.</p><div       class="mediaobject"><img src="2567f7.jpg"></div><p>The simple (lossy) compression scheme used in the example is
not as elaborate as the quantizing scheme used in JPEG. Basically,
we throw away any weight which is smaller than some selected
threshold value. In Figure 8, we have used this simple scheme on
&ldquo;bird&rdquo; at several tolerance settings.</p><div       class="mediaobject"><img src="2567f8.jpg"></div><p>Setting a weight to zero in the transformed image is
equivalent to eliminating the corresponding basis array in the
expansion of the image. This illustrates a certain kind of
simple-minded partial sum (projection) approach to compression,
similar to the example in Figure 2. Examples of more sophisticated
wavelet schemes can be done with Geoff Davis' Wavelet Image
Compression Construction Kit (see Resources 2). Strang's article
(see Resources 9) provides a short, elementary introduction to
wavelets.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xbe2580.0xcd4598"></a>Conclusion</h2></div></div><p>The discussion of JPEG and wavelets has centered on
gray-scale images. Color images may assign a red, green and blue
triple (rgb) to each pixel, although other choices are possible.
Color specified in terms of brightness, hue and saturation, known
as luminance-chrominance representations, may be desirable from a
compression viewpoint, since the human visual system is more
sensitive to errors in the luminance component than in chrominance
(see Resources 7). Given a color representation, JPEG and wavelet
schemes can be applied to each of the three planes.</p><p>This article was adapted from a recent book (see Resources
3). More information, such as details of the smoothing procedure,
along with the scripts and complete documentation may be obtained
from our web site (see Resources 4).</p><p>Information on Matlab (for GNU/Linux and other platforms) is
available through http://www.mathworks.com/. Octave is developed by
John W. Eaton with contributions from many folks, and is
distributed under the GNU General Public License. Complete sources
and ready-to-run executables for several platforms are available
via anonymous ftp from ftp.che.wisc.edu in the /octave directory.
An introduction to Octave appeared in a previous <i  >Linux Journal</i> article (see Resources 6) and on-line
information can be found via
http://www.che.wisc.edu/octave/.</p><p><a href="2567s1.html" target="_self">Resources</a></p></div></div>
<div class="authorblurb"><p>
          <div       class="mediaobject"><img src="2567f10.jpg"></div>
          <span   class="bold"><b>Greg A. Harris</b></span>
          joined the faculty at Auburn University after completing a degree in
          mathematics at the University of Nebraska-Lincoln.
          Along with Darrel Hankerson and Peter D. Johnson, Jr.,
          he is the author of Introduction to Information Theory and Data Compression, CRC Press, 1997.
          The photograph was taken in Zion National Park during winter 1997.
        </p><p>
          <span   class="bold"><b>Darrel Hankerson</b></span>
          joined the faculty at Auburn University after completing a degree in
          mathematics at the University of Utah.
          Along with Greg A. Harris and Peter D. Johnson, Jr.,
          he is the author of Introduction to Information Theory and Data Compression, CRC Press, 1997.
        </p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../057/toc057.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>