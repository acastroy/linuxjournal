<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
Under the Sink
</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;In a previous column, Chain of Custody,&#10;I wrote about some of the ways a piece of software could be&#10;compromised between the developer and the consumer. Here, I&#10;describe how developers can improve their practices&#10;in administering their development workstations to prevent&#10;compromise at the source.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x1be8580.0x1cdfac0"></a>
Under the Sink
</h1></div><div><h3 class="subtitle"><i>
Securing the Programmer, Part I
</i></h3></div><div><div class="author"><h3 class="author">
Susan
 
Sons
</h3></div><div class="issuemoyr">Issue #265, May 2016</div></div><div><p>
In a previous column, &ldquo;Chain of Custody&rdquo;,
I wrote about some of the ways a piece of software could be
compromised between the developer and the consumer. Here, I
describe how developers can improve their practices
in administering their development workstations to prevent
compromise at the source.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1be8580.0x1ce03b0"></a></h2></div></div><p>
I have a favorite saying: &ldquo;If you are a systems administrator, you
have the keys to the kingdom. If you are an open-source programmer, you
don't know which or how many kingdoms you have the keys to.&rdquo; We send
our programs out into the world to be run by anyone for any purpose.
Think about that: by anyone, for any purpose. Your code might be
running in a nuclear reactor right now, or on a missile system or on a
medical device, and <span   class="emphasis"><em>no one told you</em></span>. This is not conjecture; this is
everyday reality. Case in point: the US Army installed gpsd on all
armor (tanks, armored personnel carriers and up-armored Humvees)
<span   class="emphasis"><em>without telling its developers</em></span> (<a href="http://esr.ibiblio.org/?p=3818" target="_self">esr.ibiblio.org/?p=3818</a>).
</p><p>
This two-part series focuses on the needs of infrastructure software
developers&mdash;that is, developers of anything that runs as root,
has a security function, keeps the Internet as a whole working or is
life-critical. Of course, one never knows where one's software will be
run or under what circumstances, so feel free to follow this advice even
if all you maintain is a toddler login manager.
</p><p>
Part I covers basic security concepts and hygiene: how to think about
security needs and how to keep your development system in good shape
to reduce the risk of major computing security mishaps. Part II, in a
future issue of <span   class="emphasis"><em>Linux Journal</em></span>, will take things a step further and
discuss what it takes to improve the security culture and practices of
the projects you develop for.
</p><p>
This guide isn't going to teach you everything about security. It will
give you an idea of what to do, but in many cases, you'll need to rely
on man pages and other documentation to get the &ldquo;how&rdquo;. I did that
both for brevity and to ensure that this article covers various Linux
distributions equally and without becoming out of date in a matter
of weeks.
</p><p>
I chose the controls here carefully. It is the set of controls that
is consistently available across Linux distributions, realistic for
developers to maintain even if they are developing open-source software
as a side project and can't put many hours into it. It's maintainable without
extensive training and has highest impact for the security of the software
being developed. All of those things are judgment calls, and I welcome
debate about them. The goal of this guide is not &ldquo;ultimate
security&rdquo;
or the fabled &ldquo;uncrackable system&rdquo;. It is to raise the bar for security
hygiene among open-source infrastructure software developers significantly
from where it is right now.
</p><p>
I'd love to find that, in a year from now, we're all much more secure and can
iterate on our standards again. In my perfect world, I write this article
every spring, we all up our game a notch, and the following spring, we are
prepared to make the jobs of ransomware developers, spammers, oppressive
governments, corporate spies and so on even harder than before.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1be8580.0x1ce09e0"></a>
Concepts</h2></div></div><p>
I know programmers&mdash;being one myself&mdash;and programmers don't just want
to be told that something works, we want to know why and how it works.
Thus, before I introduce a checklist for the open-source developer,
I'm beginning with some underlying security concepts.
</p><p><span   class="bold"><b>
CIA and Software Development:</b></span>
</p><p>
No, not <span   class="emphasis"><em>that</em></span> CIA. Confidentiality, Integrity and Availability:
these are the three goals of security. In the Open Source world, we
usually are most concerned with integrity: is this the software the
developer I trust made, and can I be sure it hasn't been tampered with?
Availability typically comes second: can I get a copy of this software,
and its documentation, when I need it? Confidentiality usually comes in
last, as it applies only to a few parts of our practice: private keys
and other credentials, vulnerabilities we still are working to patch
and some sensitive intra-project communications. Even so, it is rare
that those things need remain confidential indefinitely.
</p><p><span   class="bold"><b>
Risk:</b></span>
</p><p>
<span   class="emphasis"><em>&ldquo;A ship is safe in harbor, but that's not what ships are
for.&rdquo;&mdash;William G.T. Shedd</em></span>
</p><p>
I can make my laptop perfectly secure. I can do this by removing its
battery, filling its ports with epoxy, tying it to some bricks, and
then dropping it to the bottom of the Marianas Trench. There, in the
deepest ocean chasm, it will be awfully hard to get to, and anyone who
tries will find a hunk of pulverized metal and plastic that couldn't
take the pressure or the salt water.
</p><p>
Of course, at that point, what good does the laptop do me or anyone else?
</p><p>
Computing involves risk. It always has involved risk, but never more
so than now, when we are constantly connected and running systems so
complex as to be virtually un-auditable. It is rare for me to work on a
machine so small in scope that I could audit its every line of code in
a lifetime, let alone before the next kernel patch comes out. When I
do see such a machine, it is invariably a single-purpose, life-critical
component maintained at great expense.
</p><p>
Still, the world doesn't seem to be ending (yet). This is because we
do have the power to mitigate risk to manageable levels:
</p><div class="itemizedlist"><ul type="disc"><li><p>
We can render a risk irrelevant (if I don't store credit-card numbers,
I'm not at risk of a credit-card database breach).
</p></li><li><p>
We can transfer a risk to someone else (if I insure my laptop, the
insurance company pays if it is stolen, not me).
</p></li><li><p>
We can lower the likelihood of a risk (if I never transmit or store
passwords in the clear, it is less likely that they will be compromised).
</p></li><li><p>
We can lower the impact of a risk (if I use two-factor authentication,
compromising a password alone does nothing).
</p></li></ul></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1be8580.0x1ce12d0"></a>
Controls</h2></div></div><p>
A control is something that mitigates risk in information security.
</p><p><span   class="bold"><b>
Full-Disk Encryption:</b></span>
</p><p>
&ldquo;Full-disk encryption&rdquo;, often abbreviated FDE, is something of a
misnomer. It really means full <span   class="emphasis"><em>partition</em></span> encryption in most cases.
Many distributions, such as Red Hat and Ubuntu, offer full-disk encryption
as a check-box option at install time. Some others, such as Slackware
and Gentoo, require some manual intervention in preparing the disks,
but there is reasonably good documentation available.
</p><p>
Now that you know how easy it is, let's talk about why you do it:
encrypting all of your storage (including swap!) protects you against
theft of your powered-down or hibernated computer. If you are not
using FDE, and your machine is lost or stolen, not only is your personal
information compromised, but so are your code-signing keys, the SSH keys
you use to check in code and access servers, and any information you
may have on not-yet-patched vulnerabilities. An attacker could release
patches that look as if they came from you, and most likely no one would
be the wiser.
</p><p>
Off-line attacks on the passphrases of private keys can and do happen.
Full-disk encryption makes it unlikely that the keys can be recovered
and almost certain that you will have had time to revoke them in the
meantime. It also gives your team plenty of time to patch and publish
vulnerabilities before a thief can make use of any information that may
have been on your machine.
</p><p><span   class="bold"><b>
Operating System:</b></span>
</p><p>
Quite simply: if you need Windows, run it in a VM or on another machine.
<span   class="emphasis"><em>Do not</em></span> dual-boot on your development machine. Windows is generally
prone to collecting malware, and in a scenario where the machine boots
directly to Windows (as opposed to running it in a virtual machine),
Windows may have the opportunity to overwrite your motherboard's firmware
with malicious software that would then impact your Linux system.
</p><p>
This isn't to say that Windows cannot be reasonably secured, but it's
a large, hard-to-manage attack surface, especially for those of us
who specialize in Linux and may keep a Windows system around only for
something like gaming purposes.
</p><p><span   class="bold"><b>
Password Management:</b></span>
</p><p>
Pick a decent password manager, and use it. Recycling passwords is
not okay. Using weak passwords is not okay. No one can remember a
large assortment of strong passwords. Save your brain by memorizing
only what you have to.
</p><p>
Many Linux users ask me if a password manager is really safe. What if
my password is held in RAM? What if my laptop is stolen? Full-disk
encryption will protect your machine's contents, including your password
management database, and most password management software has a layer
of encryption of its own. I'm not talking about perfect security (and
you may want to keep your 2&ndash;5 most valuable passwords in your head).
I'm talking about making decent security manageable. A weak password
out in the wild is far more open to attack than a password management
database behind a password on an encrypted hard drive on your laptop.
</p><p>
I could write an article entirely about the pros and cons of various
password managers, but the short version is this: <span   class="emphasis"><em>any</em></span> password manager
that doesn't upload all your credentials to the cloud is better than
not using a password manager.
</p><p><span   class="bold"><b>
Key Management:</b></span>
</p><p>
How you handle your private encryption keys is paramount to their
usefulness. If attackers get a copy of one of your keys&mdash;especially
if two-factor authentication is not in play&mdash;they easily can
brute-force its password off-line and use it to impersonate you. The NSA's or
China's or EvilCorp's latest back door could go out under your signature.
So, do the following:
</p><div class="itemizedlist"><ul type="disc"><li><p>
Never store private keys on a system that does not have full-disk
encryption.
</p></li><li><p>
Avoid creating passwordless private keys unless you understand the
implications of doing so, and have another protection in place to prevent
their abuse, such as encrypting the key with a key stored on a separate
hardware token.
</p></li><li><p>
Keep a log of which keys you have in use where, so that if a key is
compromised, you can ensure that it is revoked and replaced with a new key.
</p></li><li><p>
Use a different key on each of your machine. If one of your keys
is compromised, once it is used, you know from which key it was which
of your machines is in question. If all machines use the same key, you
likely will have no idea where the compromise came from. Having multiple
keys also is helpful when you are having someone else revoke a key for
you. If I find that my laptop's key may be compromised, but I'm away
at a conference, I can make a couple phone calls to get that key
revoked in the two or three places where it could cause the most damage. Then,
when I get home, I can log in via my desktop (which has its own key)
to place a new public key for my laptop in the appropriate places.
</p></li><li><p>
For GPG keys and other systems that allow it, create a revocation
certificate for each key and have a friend store those certificates
in case of emergency. This way, even if you have a major compromise
or lose access to your private key, your friend can mark that key as
compromised and no longer valid. This does not give your friend the
ability to impersonate you, only to revoke your keys.
</p></li></ul></div><p><span   class="bold"><b>
Backups:</b></span>
</p><p>
Your backups should be protected as well as you protect your primary
systems, otherwise they are as much a liability as they are an asset.
Backups always should be encrypted, and it is especially important that if
you back up to a cloud service, you have configured your backup system such
that the relevant encryption keys reside with you locally and never
are shared with the service storing the encrypted data. Be sure to keep a
backup of your keys or passwords for your backup data store somewhere
safe and separate from that data store, such as in a fireproof safe,
if they are not memorized.
</p><p><span   class="bold"><b>
Multifactor Authentication:</b></span>
</p><p>
Quite simply, multifactor authentication is your friend. Use it wherever
it is available. In most cases, this is either a password or an SSH key
combined with a second authentication factor, such as a hardware token, a
soft token on your phone that provides a time-sensitive shortcode or the
service's ability to send you an SMS or other out-of-band confirmation.
</p><p>
Passwords are fairly easy to compromise. SSH keys are less so, but at
this point, two-factor (or more) authentication has become so easy and
accessible, there is no excuse not to use it.
</p><p>
GitHub, Google and many of the other services we use regularly offer
two-factor authentication to help protect our accounts, and several
different options exist for employing it on our own infrastructure
as well.
</p><p><span   class="bold"><b>
Configuration Management:</b></span>
</p><p>
If you have a complex enough system that the overhead is worth it,
consider a configuration management system, such as Ansible or Puppet.
For most of us, with respect to our individual development machines,
this will not be the case. A much simpler and lighter solution is to
install and enable etckeeper, which will keep a revision history of your
system configuration in a git or hg repository, automatically updating
it on package manager events. You can trigger updates manually when
editing configuration files yourself.
</p><p>
Although etckeeper doesn't give you the centralized management features of a
true configuration management system, when combined with good backups, it
provides the feature most important to the security of a single-machine
setup: auditability of configuration. That audit trail can be invaluable
when things go wrong.
</p><p><span   class="bold"><b>
Updates:</b></span>
</p><p>
Keeping up with security updates should be a no-brainer, but many
developers simply become lazy or avoid updates because they are afraid
they'll have to resolve some new conflict or failure as a result.
</p><p>
However, doing critical development work on a machine that is a week
or more behind on security patches is simply taking a massive risk on
behalf of every user of your software for the sake of some convenience.
You have a package manager; use it.
</p><p><span   class="bold"><b>
Firewall:</b></span>
</p><p>
If your machine is a desktop that will live behind a hardware firewall,
you may not need to run a firewall on the machine itself. However,
if you do not have a hardware firewall protecting your machine, or if
it is mobile (a laptop you travel with, or a desktop if you ever bring
it to hackfests or LAN parties), it needs to be firewalled.
</p><p>
Almost every Linux firewall is a wrapper around iptables, which is good,
because iptables is fast, powerful and reliable. Which wrapper you
use doesn't matter terribly much. I have been using ipkungfu for a
while now to avoid having to hand-compose iptables rules on my laptop,
but other options are just as good.
</p><p><span   class="bold"><b>
SSH:</b></span>
</p><p>
You may want to <tt  >ssh</tt> between your development machines for a variety of
reasons: to transfer files, to check just one setting or to use a build
environment home from a laptop abroad. There are many good guides to
running SSH servers, but here are some general tips for your first-pass
check over sshd configuration:
</p><div class="itemizedlist"><ul type="disc"><li><p>
Never run sshd on your development machine unless you really need to
and don't have it start on boot. A development machine is a machine you
are usually sitting at, so running sshd when not in use is a needless
risk, and it's easy to start it when it is needed.
</p></li><li><p>
Never allow <tt  >ssh</tt> in as root. If you need root
access, you can <tt  >ssh</tt> in
as a regular user and then use <tt  >su</tt> or
<tt  >sudo</tt> to gain root privileges.
This helps to ensure that a single compromised key or password will not
give an attacker root privileges.
</p></li><li><p>
Never allow password-only SSH. Either require key-based authorization
or a password plus a second factor, such as a one-time password from a
soft token application.
</p></li><li><p>
Check logs or run a monitoring script to stay informed about attempts
to brute-force your sshd.
</p></li></ul></div><p><span   class="bold"><b>
Isolating Users and Services:</b></span>
</p><p>
One simple way to increase your system's security is to isolate various
services from one another using system accounts. Some distributions do
this by default most of the time, but you should check that your machine
is doing it wherever practical:
</p><div class="itemizedlist"><ul type="disc"><li><p>
Do not use root, or a user that can exercise root privileges without
a password (for example, via passwordless sudo) for everyday tasks. 
Always use the least system access necessary for any given task.
</p></li><li><p>
Do not run every service on your machine as root. In general, never
run anything as root unless you must. Developers frequently run local
instances of a number of services for testing and development purposes.
These should be isolated to their own runs-as users to help contain
any exposure that one service causes. Apache may run as
&ldquo;apache&rdquo; or
&ldquo;www-data&rdquo;; a git server may run as &ldquo;git&rdquo; or
&ldquo;gitolite&rdquo;; a mail service
may run as &ldquo;mail&rdquo;. Whatever the names are, it is important that services
are separated.
</p></li><li><p>
Never allow two users to share the same system account. System accounts
are free; make more of them as needed.
</p></li></ul></div><p><span   class="bold"><b>
What Not to Use on a Development Machine:</b></span>
</p><div class="itemizedlist"><ul type="disc"><li><p>
If you must run Adobe Flash (try not to run it at all), enable it in
only one browser, and do everything other than the one thing you tolerate
Flash for in a different browser. Better yet: run Flash only within
a VM dedicated to that purpose, if you can. Flash is closed-source,
riddled with holes and simply can't be secured.
</p></li><li><p>
Do not run an FTP service. FTP is incredibly insecure, as is FTPS.
This is not to be confused with SFTP, which serves a similar function
but operates over the more trustworthy SSH protocol.
</p></li><li><p>
Disable all FireWire and Lightning ports on your machine, in the BIOS
or UEFI firmware if possible, otherwise by physically disconnecting them
or filling them with epoxy. FireWire and Lightning use direct memory
access, meaning that an attacker connecting to one of these ports while
you are at a conference and looking away for a moment (even with your
computer's screen locked) can dump the contents of your RAM (or change
it) as long as your machine is powered up.
</p></li></ul></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1be8580.0x20db6d0"></a></h2></div></div><div class="sidebar"><p class="title"><b>
OSS Developer Security Checklist</b></p><div class="itemizedlist"><ul type="disc"><li><p>
Full Disk Encryption on workstation(s) and backups (including swap).
</p></li><li><p>
No Windows dual-boot (VMs are okay).
</p></li><li><p>
Using a password manager.
</p></li><li><p>
Never recycle passwords/passphrases.
</p></li><li><p>
Use reasonably strong passwords/passphrases for the context.
</p></li><li><p>
No keys stored on unencrypted media.
</p></li><li><p>
No keys stored passwordless (see article for exceptions).
</p></li><li><p>
Private encryption keys never entrusted to anyone else (double-check cloud
backup systems).
</p></li><li><p>
Revocation certificates for all keys stored with a trusted friend.
</p></li><li><p>
2FA is used wherever practical.
</p></li><li><p>
2FA tokens never stored on same device used to log in or store primary
credential.
</p></li><li><p>
Configuration management (at least ex-post-facto change recording) employed
on all systems.
</p></li><li><p>
root user or a user with unlimited no-password sudo privileges is not used
for day-to-day computing, coding and so on.
</p></li><li><p>
Local services run for convenience/testing, such as a Web server, gitolite
and so on, run as their own user account rather than as root and have
access only to files in their own directory, which is clearly documented.
</p></li><li><p>
No remotely accessible services are autorun on boot; remote services run
only when needed.
</p></li><li><p>
No FTP d&aelig;mon is running on workstation(s).
</p></li><li><p>
Password auth for SSH is disabled. Only key-based or multifactor auth allowed.
</p></li><li><p>
SSH as root is disabled.
</p></li><li><p>
Workstation screen is locked every time I walk away, even for a minute.
</p></li><li><p>
Application firewall (probably iptables) configured and running on
workstation(s).
</p></li><li><p>
All packages checked for updates multiple times/week.
</p></li><li><p>
Adobe Flash not installed (or disabled in all browsers).
</p></li><li><p>
Lightning and FireWire ports disabled in BIOS/UEFI firmware settings.
</p></li></ul></div></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1be8580.0x1fed1c0"></a></h2></div></div><div class="sidebar"><p class="title"><b></b></p><p>Send comments or feedback via <a href="http://www.linuxjournal.com/contact" target="_self">www.linuxjournal.com/contact</a> or to
<a href="mailto:info@linuxjournal.com">info@linuxjournal.com</a>.
</p></div></div></div>
<div class="authorblurb"><p>
Susan Sons serves as a Senior Systems Analyst at Indiana University's
Center for
Applied Cybersecurity Research (<a href="http://cacr.iu.edu" target="_self">cacr.iu.edu</a>), where
she divides her
time
between helping NSF-funded science and infrastructure projects improve
their security, helping secure a DHS-funded static analysis project, and
various attempts to save the world from poor information security practices
in general.
Susan also volunteers as Director of the Internet Civil Engineering
Institute (<a href="http://icei.org" target="_self">icei.org</a>), a nonprofit dedicated to
supporting and
securing the
common software infrastructure on which we all depend. In her free time,
she
raises an amazing mini-hacker, writes, codes, researches, practices martial
arts, lifts heavy things and volunteers as a search-and-rescue and
disaster relief worker.

</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../265/toc265.html">Issue Table of Contents</a>
    <a class="link3" href="../265/12013.html">Article</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>