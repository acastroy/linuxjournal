<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>Gnu Queue: Linux Clustering Made Easy</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;    Farm those jobs out with Gnu queue!&#10;    "><meta name="keywords" content="GNU, Queue, cluster, workstation"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x1a61580.0x1b58ab0"></a>Gnu Queue: Linux Clustering Made Easy</h1></div><div><div class="author"><h3 class="author">W. G. Krebs</h3></div><div class="issuemoyr">Issue #79, November 2000</div></div><div><p>
    Farm those jobs out with Gnu queue!
    </p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1a61580.0x1b595b0"></a></h2></div></div><p>So, your organization has finally decided
to double the number of Linux workstations in your cluster. Now
you've got twice as much computer power as before, right?
</p><p>Wrong. It's not that simple. Old habits die hard, and your
organization will probably continue trying to submit most of its
jobs to the old computers. Or, used to the old computers being
overloaded, your users will submit most of their jobs to the new
computers, leaving the old ones idle. Let's face it, it's just too
much of a pain to log into every computer on your network to see
which one's the least utilized. It's simpler just to send the job
<span   class="emphasis"><em>somewhere</em></span> and get on with the rest of the
day's work, especially if it's a quick and dirty job and there are
lots of computers. The result, however, is slower overall
performance and wasted resources.</p><p>What you need is a simple utility for sending your job to the
least utilized machine automatically. You could install a batch
processing system like NQS&mdash;maybe you've already installed one&mdash;but
it's annoying to check your e-mail or run special commands to see
if your quick and dirty job has finished running in some batch
queue. If something goes wrong, you might need to use nonstandard
commands or track down which remote machine is executing your job,
do a <span   class="bold"><b>ps</b></span> to learn its process id,
and then do a kill. Users moving to new departments or new jobs
often find that they need to relearn a complex set of nonstandard
commands, because their new organization uses a different batch
processing system than what they're used to.</p><p>You'd like something really simple, something that works
through the shell, so that you could check your job's status with a
command like <span   class="bold"><b>jobs</b></span>, and allow the
shell to notify you when the job has terminated, just as if you
were running it in the background on your local machine. You'd like
to be able to send the job into the background and foreground with
<span   class="bold"><b>bg</b></span> and
<span   class="bold"><b>fg</b></span> and kill the job with
<span   class="bold"><b>kill</b></span>, just as if the job were
running on the local node. This way, you can control remote jobs
using the same standard shell commands you and your users already
know how to use.</p><p>Enter GNU Queue. GNU Queue makes it easy to cluster Linux
workstations. If you already know how to control jobs running on
your local machine, you already know how to control remote jobs
using GNU Queue. You don't even need special privileges to install
and run GNU Queue on your cluster&mdash;anyone can do it. Once you've
discovered how incredibly easy it is to cluster Linux environments
with GNU Queue, you'll wonder why organizations continue to spend
so much money on comparatively hard-to-cluster Windows NT
environments.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1a61580.0x1b59a28"></a>Quickly Configuring Heavily-Used Software to
Farm out Every Time</h2></div></div><p>With GNU Queue, all you have to do is write a simple wrapper
shell script to cause software applications to farm out every time
to the network:</p><pre     class="programlisting">
#!/bin/sh&lt;\n&gt;
exec queue -i -w -p
-- realbogobasicinterpreter $*
</pre><p>and name it &ldquo;bogobasicinterpreter&rdquo;, with the real
bogobasicinterpreter renamed &ldquo;realbogobasicinterpreter&rdquo;. This
assumes, of course, that you have administrative privileges for
your cluster (not necessary to install and run GNU Queue). When
someone runs bogobasicinterpreter, GNU Queue is told to farm the
job out of the network.
</p><p>Another popular way to use GNU Queue is to set up an alias.
You can do this even if you don't have administrative privileges on
your cluster. If you are using
<span   class="bold"><b>csh</b></span>, change to your home directory
and add the following line to your .cshrc:</p><pre     class="programlisting">
alias q queue -i -w -p --
</pre><p>and run the command <span   class="bold"><b>source
.cshrc</b></span>. Then, you can simply farm out jobs by typing
&ldquo;q&rdquo; before the name of the job you want to farm out.
</p><p>Either way, GNU Queue does all the hard work, instantly
finding a lightly loaded machine to run the job on. It then fires
up a proxy job on your local machine that &ldquo;pretends&rdquo; to be the
remotely executing job, so that you can background, foreground and
kill the remotely running job through normal shell commands.
There's no need to teach other users new commands to interact with
some complicated batch processing system&mdash;if they understand how to
use the UNIX shell to control local jobs, they understand how to
use GNU Queue to control remotely executing jobs.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1a61580.0x1b59df0"></a>Advanced Features</h2></div></div><p>Of course, GNU Queue supports many additional features. It
supports a traditional batch processing mode, where output can
optionally be returned by e-mail. Versions 1.20.1 and higher now
have alpha support for various modes of job migration, which lets
the administrator to allow running jobs to actually move from one
machine to another in order to maintain a constant load throughout
the cluster. More importantly, GNU Queue allows administrators to
place limits on the number of a type of job that can run (say,
allow no more than five bogobasicinterpreter jobs to run on any
node) or to prevent certain jobs from running when a machines's
load is too great. For example, the bogobasicinterpreter can't be
started if the load average exceeds five; running interpreters are
suspended if the load average on the node exceeds seven. It's also
possible to place restrictions on the time of day certain jobs may
be run (no bogobasicinterpreters on Saturdays) or to have it
periodically check the return value of a custom script to determine
whether or not a program can be run. But, you'll probably never
need these advanced features.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1a61580.0x1b59ef8"></a>Obtaining and Installing GNU Queue: A Quick
Look</h2></div></div><p>All of this sounds great, you say. How do I obtain and
install GNU Queue? You can download the latest release of GNU Queue
from its web site at
<a href="http://www.gnuqueue.org" target="_self">http://www.gnuqueue.org/</a>.
It's a participating project on SourceForge, and you can find all
sorts of discussion forums, support forums and bug-tracking
databases. Download the program from the web site, unpack it and
then run:</p><pre     class="programlisting">
 ./configure&lt;\n&gt;
 make install
</pre><p>from the top-level directory. Run <b  >make
install</b> and fire up the d&aelig;mon with <b  >queued
-D &amp;</b> on each machine in your cluster.
</p><p>For a quick reference on using the
<span   class="bold"><b>queue</b></span> command to farm jobs out to
the network, visit the GNU Queue home page. That's all there is to
it!</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1a61580.0x1b5a268"></a>Detailed Instructions on Installing GNU
Queue</h2></div></div><p>Before installing GNU Queue on your cluster, you have to make
a decision that is basically guided by whether you have root
(administrative) privileges on your cluster. If you do, you'll
probably want to install GNU Queue in a manner that makes it
available to all the users on your site. This is the
<b  >--enable-root</b> option. On the other hand, if
you're just an ordinary Jane or Joe on your cluster or want to see
what the fuss is all about without giving away privileges, you can
install GNU Queue as an ordinary user, the default mode of
installation.</p><p>Yes, ordinary users can install GNU Queue as a batch
processing system on your cluster! But, if another user wants to
run GNU Queue, he'll have to change the port numbers in the source
code to insure no one else is running GNU Queue. That's why it's
better to let the system administrator install GNU Queue (with
<b  >--enable-root</b> option to the configure script) if
you expect a lot of users will want to run GNU Queue on your
cluster.</p><p>Once you've downloaded GNU Queue off the Net, the first thing
to do is to unpack it using the tar command. Under Linux, this is
just <b  >tar xzf filename</b>, where file name is the
name of the file (compressed with
<span   class="bold"><b>gzip</b></span> and having either the .tar.gz
or .tgz file extensions. On other systems it's a little bit more
involved, since the tar installed by default is not GNU tar and
doesn't support the <b  >z</b>decompression option.
You'll need to explicitly run the
<span   class="bold"><b>gunzip</b></span> decompression program:
<b  >gunzip filename.tar.gz</b>; <b  >tar xf
filename.tar</b>, where filename.tar.gz is the file, with
.tar.gz extension, that you obtained from the network. (Savvy users
might want to use the <b  >zcat filename.tar.gz|tar tf
-</b> trick, but this assumes the
<span   class="bold"><b>zcat</b></span> program installed on your
system can handle GNU zipped file.
<span   class="bold"><b>gunzip</b></span> is part of the GNU
<span   class="bold"><b>gzip</b></span> package; you can obtain it
from
<a href="ftp://ftp.gnu.org" target="_self">ftp://ftp.gnu.org/</a>.</p><p>So you've unpacked the distribution and you're sitting in the
distribution's top-level directory. Now what? Well, if you're an
ordinary Jane or Joe you install the program into the distribution
directory by running <b  >./configure</b> followed by
<b  >make install</b> on each machine in your cluster.
Then, fire up the d&aelig;mon with <b  >queued -D
&amp;</b> on each machine in your cluster. If you want more
details (or you're a system administrator), continue
reading.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1a61580.0x1b5a9f8"></a>Installation by Plain Folks</h2></div></div><p>Run ./configure. If you're installing it on a system where
you're not a superuser but an ordinary peon, configure sets the
makefile to install GNU Queue into the current directory.
<span   class="bold"><b>queue</b></span> will go into ./bin; queued
d&aelig;mon will go into ./sbin; ./com/queue will be the shared
spool directory; the host access control list file will go into
./share; and the queued pid files will go into ./var . If you want
things to go somewhere else, run <b  >./configure
--prefix=dir</b>, where <span   class="bold"><b>dir</b></span>
is the top-level directory where you want things to be
installed.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1a61580.0x1b5ac08"></a>System-Wide Installation by Superusers</h2></div></div><p>The default ./configure option is to install GNU Queue in the
local directory for use by a single user only. System
administrators should run the command <b  >./configure
--enable-root</b> instead. When installing with the
<b  >--enable-root</b> option, configure sets the
makefile to install GNU Queue under the /usr/local prefix.
<span   class="bold"><b>queue</b></span> will go in /usr/local/bin;
queued d&aelig;mon will go into /usr/local/sbin;
/usr/local/com/queue will be the shared spool directory; the host
access control list file will go into /usr/local/share; and the
queued pid files will go into /usr/local/var. If you want things to
go somewhere else, run the following:</p><pre     class="programlisting">
./configure --enable-root&lt;\n&gt;
--prefix=dir
</pre><p>where <span   class="bold"><b>dir</b></span> is the top-level
directory where you want things to be installed.
</p><p><b  >./configure</b> takes a number of additional
options that you may wish to be aware of, including options for
changing the paths of the various directories. <b  >./configure
--help</b> gives a full listing of them. Here are a few
examples, <b  >--bindir</b> specifies where queue goes;
<b  >--sbindir</b> specifies where queued goes;
<b  >--localstatedir</b> states where the spool directory
and queued pid files go; and <b  >--datadir</b> lists
where the host access control file goes. If ./configure fails
inelegantly, make sure <span   class="bold"><b>lex</b></span> is
installed. GNU flex is an implementation of lex available from the
FSF,
<a href="http://www.gnu.org" target="_self">http://www.gnu.org/</a>.</p><p>Now, run make to compile the programs. If your make complains
about a syntax error in the Makefile, you'll need to run GNU Make
which is hopefully already installed on your machine (perhaps as
<span   class="bold"><b>gmake</b></span> or
<span   class="bold"><b>gnumake</b></span>), but, if not, you can
obtain it from the FSF at
<a href="http://www.gnu.org" target="_self">http://www.gnu.org/</a>.</p><p>If all goes well, make install will install the programs into
the directory you specified with ./configure. Missing directories
will be created. The host name of the node make install is being
run on will be added to the host access control list if it is not
already there.</p><p>Now, try running Queue. Start up <b  >./queued -D
&amp;</b> on the local machine. (If you did a make install on
the node, the host name should already be in the host access
control list file.)</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1a61580.0x1b51d30"></a>Examples and Options</h2></div></div><p>Here are some simple examples:</p><pre     class="programlisting">
&gt; queue -i -w -n -- hostname&lt;\n&gt;
&gt; queue -i -r -n -- hostname
</pre><p>For a more sophisticated example, try suspending and resuming
it with <b  >Control-Z</b> and
<span   class="bold"><b>fg</b></span>:
<pre     class="programlisting">
&gt; queue -i -w -p -- emacs -nw
</pre>


If this example works on the localhost, you will want to add
additional hosts to the host access control list in share (or
--datadir) and start up queued on these.
</p><p>This line:</p><pre     class="programlisting">
&gt; queue -i -w -p -h hostname -- emacs
-nw
</pre><p>will run Emacs on host name. Without the
<b  >-h</b> argument, it will run the job on the best or
least-loaded host in the Access Control List file. There is also a
<b  >-H hostname</b> option, which causes hostname to be
preferred, but the job will run on other hosts if hostname is
unavailable.
</p><p>At this point, you might be wondering what some of the other
options for queue do. <span   class="bold"><b>./queue
--help</b></span> gives a list of options to Queue. The &ldquo;--&rdquo;
separates GNU Queue options from the options to be given to the
command to be run. <b  >-i</b> stands for immediate; it
places the job to be run in the &ldquo;now&rdquo; batch queue.
<b  >-w</b> invokes the proxy job system, as opposed to
<b  >-r</b>, which causes output to be returned to the
user via e-mail (traditional batch processing mode).
<b  >-n</b> turns off virtual terminal support. Most
users will probably only use <b  >-i -w -p</b> (full
virtual terminal support, for interactive jobs like Emacs) and
<b  >-i</b> w -n (no virtual terminal support, for
noninteractive jobs).</p><p>More details on the protocol GNU Queue uses for host
selection can be found in the on-line manual and the on-line
Internet draft protocol at
<a href="http://www.gnuqueue.org" target="_self">http://www.gnuqueue.org/</a>.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1a61580.0x1b52518"></a>Segregating Jobs Using Spool Directories</h2></div></div><p>You can also create additional queues for use with the
<b  >-q</b> and <b  >-d spooldir</b> options.
They might be used to specify different queuing behavior for
different classes of jobs. Each
<span   class="bold"><b>spooldir</b></span> must have a profile
associated with it. The profile determines queuing behavior for
jobs running in that spooldir. See the on-line manual for more
details.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1a61580.0x1b52728"></a>Fine-Tuning Cluster Performance</h2></div></div><p>That's all there is to it! Of course, for GNU Queue to work
well there needs to be some sort of file sharing between nodes in
the cluster (for example, NFS, the Network File System). If you
have the same home directory, regardless of which machine you log
into, your system administrator has somehow configured your home
directory to be shared across all cluster nodes. You want to make
sure that enough of the file system is shared (i.e., is the same)
between cluster nodes so that your programs don't get confused when
they run. Typically, you'll want system temporary directories (/tmp
and /usr/tmp) to be non-shared, but everything else (except maybe
the root file system containing kernel images and basic commands)
to be shared. Because this configuration is so common to UNIX and
Linux clusters, we've assumed here that this is the case, but it
isn't necessarily so; so check with your system administrator if
you have questions about how files are shared across your network
cluster.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1a61580.0x1b52830"></a>Documentation and Mailing Lists</h2></div></div><p>Documentation about GNU Queue is also available off the web
site, including an Internet draft on the protocol GNU Queue uses to
farm out jobs. While you're there, you'll probably want to sign up
for one of the three mailing lists (queue-announce,
queue-developers and queue-support) so that you can learn of new
features as they're announced and interact with other GNU Queue
users. At the time of writing, queue-developers is by far the most
active list, with lively discussion of improvements to GNU Queue's
many features and suggested ports to new platforms. You can obtain
advice for any problems you encounter from the queue-support
mailing list.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1a61580.0x1b52938"></a>CVS Repository: Joining the Developer
Community</h2></div></div><p>Another SourceForge feature mentioned on the home page is the
CVS repository for GNU Queue. Interested readers can obtain the
latest prerelease development code, containing the latest features
(and bugs) as they are added by developers, by unpacking the GNU
Queue distribution and running the command
<span   class="bold"><b>cvs update</b></span> inside the top-level
directory. If you're actively making changes to GNU Queue, you can
apply for write access to the CVS directory and instantly publish
your changes via the <span   class="bold"><b>cvs ci</b></span>
command. If you can get other developers interested in your work
(via the queue-developers mailing list, of course), you can bounce
code changes back and forth amongst yourselves via repeated cycles
of cvs, ci and cvs update. All of this assumes you have cvs
installed, which is the default with many Linux
distributions.</p><p>Code isn't the only way interested readers can contribute to
GNU Queue. There are many ways to contribute to the GNU Queue
effort on SourceForge. With a login on SourceForge, one of the
project administrators can give you editor privileges for the
documentation tree, moderator privileges in the discussion forums,
or administrative privileges in the bug tracking and patch database
sections of the site.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1a61580.0x1b52b48"></a>Getting Help</h2></div></div><p>If you encounter problems with installation not explained
here, you may wish to check out the support forum and support
mailing list, available off GNU Queue's home page,
<a href="http://www.gnuqueue.org" target="_self">http://www.gnuqueue.org/</a>.
Bugs should be reported to bug-queue@gnu.org.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1a61580.0x1b52ca8"></a>Farm out that Job!</h2></div></div><p>So remember: the next you have a quick and dirty job to run,
don't waste time or resources. Farm that sucker out using GNU
Queue!</p></div></div>
<div class="authorblurb"><p>
        <div       class="mediaobject"><img src="4208aa.jpg"></div>


      <span   class="bold"><b>W. G. Krebs</b></span>
      is a PhD candidate in
      molecular biophysics and biochemistry at Yale University, where he
      researches web-based biological databases. He has been a systems
      programmer for longer, and in more languages, than he cares to
      relate. His wide-ranging interests include political economics,
      classical and folk music, and the Chinese game of Go; he welcomes
      your comments at wkrebs@gnu.org or by snail mail c/o
      <i  >Linux Journal</i>.</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../079/toc079.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>