<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
Hack and /
</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;Learn from my mistakes in this article covering on-call alert&#10;best practices.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0xbb0580.0xca7ac0"></a>
Hack and /
</h1></div><div><h3 class="subtitle"><i>
Sysadmin 101: Alerting
</i></h3></div><div><div class="author"><h3 class="author">
Kyle
 
Rankin
</h3></div><div class="issuemoyr">Issue #274, February 2017</div></div><div><p>
Learn from my mistakes in this article covering on-call alert
best practices.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xbb0580.0xca83b0"></a></h2></div></div><p>

This is the first in a series of articles on system administrator
fundamentals. These days, DevOps has made even the job title &ldquo;system
administrator&rdquo; seem a bit archaic, much like the &ldquo;systems
analyst&rdquo; title it
replaced. These DevOps positions are rather different from typical sysadmin jobs in
the past in that they have a much larger emphasis on software development far beyond
basic shell scripting. As a result, they often are filled with people with
software development backgrounds without much prior sysadmin experience. In
the past, sysadmins would enter the role at a junior level and be mentored
by a senior sysadmin on the team, but in many cases currently, companies go
quite a while with cloud outsourcing before their first DevOps hire. As a
result, DevOps engineers might be thrust into the role at a junior level
with no mentor around apart from search engines and Stack Overflow posts.
In this series of articles, I'm going to expound on some of the lessons I've
learned through the years that might be obvious to longtime sysadmins but may
be news to someone just coming into this position.

</p><p>
In this first article, I cover on-call alerting. Like with any job
title, the responsibilities given to sysadmins, DevOps and Site Reliability
Engineers may differ, and in some cases, they may not involve any kind of
24x7 on-call duties, if you're lucky. For everyone else, though, there are many ways
to organize on-call alerting, and there also are many ways to shoot
yourself in the foot. 
</p><p>
The main enemies of on-call alerting are false
positives, with the main risks being ignoring alerts or burnout for members
of your team. This article talks about some best practices you can
apply to your alerting policies that hopefully will reduce burnout and make
sure alerts aren't ignored.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xbb0580.0xca86c8"></a>
Alert Thresholds</h2></div></div><p>
A common pitfall sysadmins run into when setting up monitoring systems is to
alert on too many things. These days, it's simple to monitor just about any
aspect of a server's health, so it's tempting to overload your
monitoring system with all kinds of system checks. One of the main ongoing
maintenance tasks for any monitoring system is setting appropriate alert
thresholds to reduce false positives. This means the more checks you have
in place, the higher the maintenance burden. As a result, I have a few
different rules I apply to my monitoring checks when determining thresholds
for notifications.
</p><p><span   class="bold"><b>
Critical alerts must be something I want to be woken up about at
3am.</b></span>
</p><p>
A common cause of sysadmin burnout is being woken up with alerts for
systems that don't matter. If you don't have a 24x7 international
development team, you probably don't care if the build server has a problem
at 3am, or even if you do, you probably are going to wait until the morning
to fix it. By restricting critical alerts to just those systems that must
be online 24x7, you help reduce false positives and make sure that real
problems are addressed quickly.
</p><p>
<span   class="bold"><b>Critical alerts must be actionable.</b></span>
</p><p>
Some organizations send alerts when just about anything happens on a
system. If I'm being woken up at 3am, I want to have a specific action plan
associated with that alert so I can fix it. Again, too many false positives
will burn out a sysadmin that's on call, and nothing is more frustrating
than getting woken up with an alert that you can't do anything about. Every
critical alert should have an obvious action plan the sysadmin can follow
to fix it.
</p><p>
<span   class="bold"><b>Warning alerts tell me about problems that will be
critical if I don't fix them.</b></span>
</p><p>
There are many problems on a system that I may want to know about and may
want to investigate, but they aren't worth getting out of bed at 3am. Warning
alerts don't trigger a pager, but they still send me a quieter notification. For
instance, if load, used disk space or RAM grows to a certain point where
the system is still healthy but if left unchecked may not be, I get a
warning alert so I can investigate when I get a chance. On the other hand,
if I got only a warning alert, but the system was no longer responding,
that's an indication I may need to change my alert thresholds.
</p><p><span   class="bold"><b>
Repeat warning alerts periodically.</b></span>
</p><p>
I think of warning alerts like this thing nagging at you to look at it and
fix it during the work day. If you send warning alerts too frequently, they
just spam your inbox and are ignored, so I've found that spacing them out to
alert every hour or so is enough to remind me of the problem but not so
frequent that I ignore it completely.
</p><p>
<span   class="bold"><b>Everything else is monitored, but doesn't send an
alert.</b></span>
</p><p>
There are many things in my monitoring system that help provide overall
context when I'm investigating a problem, but by themselves, they aren't
actionable and aren't anything I want to get alerts about. In other cases, I
want to collect metrics from my systems to build trending graphs later. I
disable alerts altogether on those kinds of checks. They still show up in my
monitoring system and provide a good audit trail when I'm investigating a
problem, but they don't page me with useless notifications.
</p><p>
<span   class="bold"><b>Kyle's rule.</b></span>
</p><p>
One final note about alert thresholds: I've developed a practice in my
years as a sysadmin that I've found is important enough as a way to reduce
burnout that I take it with me to every team I'm on. My rule is this:
</p><div class="blockquote"><blockquote class="blockquote"><p>
If sysadmins were kept up during the night because of false alarms, they
can clear their projects for the next day and spend time tuning alert
thresholds so it doesn't happen again.
</p></blockquote></div><p>
There is nothing worse than being kept up all night because of false
positive alerts and knowing that the next night will be the same and
that there's nothing you can do about it. If that kind of thing continues, it
inevitably will lead either to burnout or to sysadmins silencing their
pagers. Setting aside time for sysadmins to fix false alarms helps,
because they get a chance to improve their night's sleep the next night. As
a team lead or manager, sometimes this has meant that I've taken on a sysadmin's
tickets for them during the day so they can fix alerts. 
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xbb0580.0xca8f60"></a>
Paging</h2></div></div><p>
Sending an alert often is referred to as paging or being paged, because in
the past, sysadmins, like doctors, carried pagers on them. Their monitoring
systems were set to send a basic numerical alert to the pager when there was
a problem, so that sysadmins could be alerted even when they weren't at a
computer or when they were asleep. Although we still refer to it as
paging, and some older-school teams still pass around an actual pager, these
days, notifications more often are handled by alerts to mobile phones.
</p><p>
The first question you need to answer when you set up alerting is what
method you will use for notifications. When you are deciding how to set up
pager notifications, look for a few specific qualities. 
</p><p>
<span   class="bold"><b>Something that will alert you wherever you are
geographically.</b></span>
</p><p>
A number of cool office projects on the web exist where a broken
software build triggers a big red flashing light in the office. That kind
of notification is fine for office-hour alerts for non-critical systems,
but it isn't appropriate as a pager notification even during the day,
because a
sysadmin who is in a meeting room or at lunch would not be notified. These
days, this generally means some kind of notification needs to be sent to your phone.
</p><p><span   class="bold"><b>
An alert should stand out from other notifications.</b></span>
</p><p>
False alarms can be a big problem with paging systems, as sysadmins 
naturally will start ignoring alerts. Likewise, if you use the same ringtone for
alerts that you use for any other email, your brain will start to tune
alerts out. If you use email for alerts, use filtering rules so that
on-call alerts generate a completely different and louder ringtone from regular
emails and vibrate the phone as well, so you can be notified even if you
silence your phone or are in a loud room. In the past, when BlackBerries were
popular, you could set rules such that certain emails generated a &ldquo;Level
One&rdquo; alert that was different from regular email notifications. 
</p><p>
The
BlackBerry days are gone now, and currently, many organizations (in
particular startups) use Google Apps for their corporate email. The Gmail
Android application lets you set per-folder (called labels)
notification rules so you can create a filter that moves all on-call alerts
to a particular folder and then set that folder so that it generates a
unique alert, vibrates and does so for every new email to that folder. If
you don't have that option, most email software that supports multiple
accounts will let you set different notifications for each account so you
may need to resort to a separate email account just for alerts.
</p><p><span   class="bold"><b>
Something that will wake you up all hours of the night.</b></span>
</p><p>
Some sysadmins are deep sleepers, and whatever notification system you choose
needs to be something that will wake them up in the middle of the night.
After all, servers always seem to misbehave at
around 3am. Pick a
ringtone that is loud, possibly obnoxious if necessary, and also make sure
to enable phone vibrations. Also configure your alert system to re-send
notifications if an alert isn't acknowledged within a couple minutes.
Sometimes the first alert isn't enough to wake people up completely, but it
might move them from deep sleep to a lighter sleep so the follow-up alert
will wake them up.
</p><p>
While ChatOps (using chat as a method of getting notifications and
performing administration tasks) might be okay for general non-critical
daytime notifications, they are not appropriate for pager alerts. Even if
you have an application on your phone set to notify you about unread
messages in chat, many chat applications default to a &ldquo;quiet
time&rdquo; in the
middle of the night. If you disable that, you risk being paged in the
middle of the night just because someone sent you a message. Also, many
third-party ChatOps systems aren't necessarily known for their
mission-critical reliability and have had outages that have spanned many
hours. You don't want your critical alerts to rely on an unreliable system.
</p><p><span   class="bold"><b>
Something that is fast and reliable.</b></span>
</p><p>
Your notification system needs to be reliable and able to alert you quickly
at all times. To me, this means alerting is done in-house, but many
organizations opt for third parties to receive and escalate their
notifications. Every additional layer you can add to your alerting is another
layer of latency and another place where a notification may be dropped.
Just make sure whatever method you choose is reliable and that you have some
way of discovering when your monitoring system itself is offline. 
</p><p>
In the
next section, I cover how to set up escalations&mdash;meaning, how you alert
other members of the team if the person on call isn't responding. Part of
setting up escalations is picking a secondary, backup method of
notification that relies on a different infrastructure from your primary
one.
So if you use your corporate Exchange server for primary notifications, you
might select a personal Gmail account as a secondary. If you have a Google
Apps account as your primary notification, you may pick SMS as your
secondary alert. 
</p><p>
Email servers have outages like anything else, and the goal
here is to make sure that even if your primary method of notifications has
an outage, you have some alternate way of finding out about it. I've had a
number of occasions where my SMS secondary alert came in before my primary
just due to latency with email syncing to my phone.
</p><p><span   class="bold"><b>
Create some means of alerting the whole team.</b></span>
</p><p>
In addition to having individual alerting rules that will page someone who
is on call, it's useful to have some way of paging an entire team in the
event of an &ldquo;all hands on deck&rdquo; crisis. This may be a particular email
alias or a particular key word in an email subject. However you set it up,
it's important that everyone knows that this is a &ldquo;pull in case of
fire&rdquo;
notification and shouldn't be abused with non-critical messages.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xbb0580.0xca9900"></a>
Alert Escalations</h2></div></div><p>
Once you have alerts set up, the next step is to configure alert
escalations. Even the best-designed notification system alerting the most
well intentioned sysadmin will fail from time to time either because a
sysadmin's phone crashed, had no cell signal, or for whatever reason, the
sysadmin didn't notice the alert. When that happens, you want to make sure
that others on the team (and the on-call person's second notification) is
alerted so someone can address the alert.
</p><p>
Alert escalations are one of those areas that some monitoring systems do
better than others. Although the configuration can be challenging compared to
other systems, I've found Nagios to provide a rich set of escalation
schedules. Other organizations may opt to use a third-party notification
system specifically because their chosen monitoring solution doesn't have
the ability to define strong escalation paths. A simple escalation system
might look like the following:
</p><div class="itemizedlist"><ul type="disc"><li><p>
Initial alert goes to the on-call sysadmin and repeats every five minutes.
</p></li><li><p>
If the on-call sysadmin doesn't acknowledge or fix the alert within 15
minutes, it escalates to the secondary alert and also to the rest of
the team.
</p></li><li><p>
These alerts repeat every five minutes until they are acknowledged or fixed.
</p></li></ul></div><p>
The idea here is to give the on-call sysadmin time to address the alert so
you aren't waking everyone up at 3am, yet also provide the rest of the
team with a way to find out about the alert if the first sysadmin can't fix
it in time or is unavailable. Depending on your particular SLAs, you may want
to shorten or lengthen these time periods between escalations or make them
more sophisticated with the addition of an on-call backup who is alerted
before the full team. In general, organize your escalations so they
strike the right balance between giving the on-call person a chance to
respond before paging the entire team, yet not letting too much time pass
in the event of an outage in case the person on call can't respond.
</p><p>
If you are part of a larger international team, you even may be able to set
up escalations that follow the sun. In that case, you would select on-call
administrators for each geographic region and set up the alerts so that
they were aware of the different time periods and time of day in those
regions,
and then alert the appropriate on-call sysadmin first. Then you can have
escalations page the rest of the team, regardless of geography, in the event
that an alert isn't solved.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xbb0580.0xca0660"></a>
On-Call Rotation</h2></div></div><p>
During World War One, the horrors of being in the trenches at the front
lines were such that they caused a new range of psychological problems
(labeled shell shock) that, given time, affected even the most hardened
soldiers. The steady barrage of explosions, gun fire, sleep deprivation and
fear day in and out took its toll, and eventually both sides in the war
realized the importance of rotating troops away from the front line to
recuperate.
</p><p>
It's not fair to compare being on call with the horrors of war, but that
said, it also takes a kind of psychological toll that if left unchecked, it will
burn out your team. The responsibility of being on call is a burden even if
you aren't alerted during a particular period. It usually means you must
carry your laptop with you at all times, and in some organizations, it may
affect whether you can go to the movies or on vacation. In some badly run
organizations, being on call means a nightmare of alerts where you can
expect to have a ruined weekend of firefighting every time. Because being
on call can be stressful, in particular if you get a lot of nighttime
alerts, it's important to rotate out sysadmins on call so they get a break.
</p><p>
The length of time for being on call will vary depending on the size of
your team and how much of a burden being on call is. Generally speaking, a
one- to four-week rotation is common, with two-week rotations often hitting
the sweet spot. With a large enough team, a two-week rotation is short enough
that any individual member of the team doesn't shoulder too much of the
burden. But, even if you have only a three-person team, it means a sysadmin
gets a full month without worrying about being on call.
</p><p><span   class="bold"><b>
Holiday on call.</b></span>
</p><p>
Holidays place a particular challenge on your on-call rotation, because it
ends up being unfair for whichever sysadmin it lands on. In particular, being on call
in late December can disrupt all kinds of family time. If you have a
professional, trustworthy team with good teamwork, what I've found works
well is to share the on-call burden across the team during specific known
holiday days, such as Thanksgiving, Christmas Eve, Christmas and New Year's
Eve. In this model, alerts go out to every member of the team, and everyone
responds to the alert and to each other based on their availability. After
all, not everyone eats Thanksgiving dinner at the same time, so if one
person is sitting down to eat, but another person has two more hours before
dinner, when the alert goes out, the first person can reply &ldquo;at
dinner&rdquo;,
but the next person can reply &ldquo;on it&rdquo;, and that way, the burden is shared.
</p><p>
If you are new to on-call alerting, I hope you have found this list of
practices useful. You will find a lot of these practices in place in many
larger organizations with seasoned sysadmins, because over time, everyone runs
into the same kinds of problems with monitoring and alerting. Most of these
policies should apply whether you are in a large organization or a small
one, and even if you are the only DevOps engineer on staff, all that means
is that you have an advantage at creating an alerting policy that will avoid
some common pitfalls and overall burnout.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xbb0580.0xca0a28"></a></h2></div></div><div class="sidebar"><p class="title"><b></b></p><p>Send comments or feedback via <a href="http://www.linuxjournal.com/contact" target="_self">www.linuxjournal.com/contact</a> or to
<a href="mailto:info@linuxjournal.com">info@linuxjournal.com</a>.
</p></div></div></div>
<div class="authorblurb"><p>
Kyle Rankin is a Sr. Systems Administrator in the San Francisco Bay Area
and
the
author of a number of books, including <span   class="emphasis"><em>The Official Ubuntu Server
Book</em></span>,
<span   class="emphasis"><em>Knoppix Hacks</em></span> and <span   class="emphasis"><em>Ubuntu Hacks</em></span>.
He is currently the president of the North
Bay Linux Users' Group.

</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../274/toc274.html">Issue Table of Contents</a>
    <a class="link3" href="../274/12141.html">Article</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>