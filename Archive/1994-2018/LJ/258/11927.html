<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
Hack and /
</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;What's better than three-letter acronyms? Three-letter command-line tools.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x1cd5580.0x1dccac0"></a>
Hack and /
</h1></div><div><h3 class="subtitle"><i>
AWS EC2 VPC CLI
</i></h3></div><div><div class="author"><h3 class="author">Kyle Rankin</h3></div><div class="issuemoyr">Issue #258, October 2015</div></div><div><p>
What's better than three-letter acronyms? Three-letter command-line tools.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1cd5580.0x1dcd3b0"></a></h2></div></div><p>
There's just something about the fresh start you get with a new job. Both my
previous job and my new one began with the opportunity to build a new
infrastructure from scratch. In both cases, as is common with startup
infrastructure in its early stages, everything was to be built using Amazon Web
Services (AWS), specifically using its Elastic Cloud Computing (EC2)
infrastructure. Two significant things had changed in the years between the two
jobs that led me to a fresh approach to the infrastructure, and those are the
things I'm going to explore in this article: Amazon's Virtual Private Cloud (VPC) and the AWS command-line tools.
</p><p>
VPC has been around for some time, and it was around back when I started work on
my previous infrastructure, but it was an extra feature. At the time, you defaulted
to what Amazon now calls &ldquo;EC2 Classic&rdquo;, which meant you essentially
were sharing an
internal IP space with everyone else on EC2. With VPC, you can define different
subnets, including ones that have only non-Internet-routable RFC1918 IP
addresses.
You get to choose which hosts get external IPs and which don't, and you can define
not only what subnet a host is in, but you also even can assign it a specific internal IP
if you want. Additionally, you have more control over Security Groups (which allow you to
assign firewall rules to groups of hosts), and you can filter not only incoming
(ingress) traffic but also egress (outgoing) traffic. You even can add or remove
security groups from a host after it has spawned&mdash;something just not possible in EC2
Classic.
</p><p>
Today, new Amazon accounts are VPC only. It's clear that Amazon is phasing out EC2
Classic not just by calling it &ldquo;Classic&rdquo; and making VPC the
default, but also by
creating new lower-cost instance types that are available only on VPC. Even though
by default the subnets that come with a VPC behave much like on EC2 Classic with
public and private IPs, there still are enough differences and potential once you
consider private subnets that it forces you to take a fresh approach to how you
build things. 
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1cd5580.0x1dcd720"></a>
The Amazon Command-Line Interface</h2></div></div><p>
It may not come as any surprise at all to my regular readers that when I initially
got started with Amazon infrastructure, I avoided the Web interface whenever
possible and stuck with command-line tools. Although back then there were a number of
different libraries (such as the boto library for Python) that you could use to
interact with Amazon's API with software, the main command-line interface for
Amazon EC2 was known as EC2 API Tools (or the ec2-api-tools package in Ubuntu). It
was Java based and provided a way to perform all of the common functions you might
perform on the Web interface via commands named <tt  >ec2-&lt;some
function&gt;</tt>. It wasn't so
bad once you got used to it. The primary complaint I had with EC2 API tools was
how slow it was between issuing a command and getting a response back.
</p><p>
A year or so ago I discovered that Amazon had developed a new Python-based
command-line tool called AWS CLI and made a mental note to try it when I had a
chance. Since I already had scripts in place that took advantage of the EC2 API
tools, and they worked, I didn't have any compelling reason at the time to switch.
Now that I was faced with building new scripts for a new infrastructure, however, it seemed
as good a time as any to try it out.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1cd5580.0x1dcd8d8"></a>
Using AWS CLI</h2></div></div><p>
I'm going to skip the details of how to install and configure AWS CLI since that's
already well documented on the main page for Amazon CLI, and it's probably already
packaged for your Linux distribution (and if not, you can do <tt  >pip
install awscli</tt> to
get it). Although you can use AWS CLI for a number of different AWS APIs, I'm going
to stick to how it compares to EC2 API tools. Instead of every command starting
with <tt  >ec2-</tt>, every command starts with <tt  >aws
ec2</tt> followed by the command. Fortunately,
most of the commands match in both environments, so where before you might have
typed:

<pre     class="programlisting">
$ ec2-describe-instances
</pre>
</p><p>
Now you type:

<pre     class="programlisting">
$ aws ec2 describe-instances
</pre>
</p><p>
Unfortunately, the similarities pretty much end there. Where with
<tt  >ec2-describe-instances</tt>
you could just append a list of IDs, with AWS CLI, you need to use the
<tt  >--instance-ids</tt> argument first:

<pre     class="programlisting">
$ aws ec2 describe-instances --instance-ids i-someid
</pre>
</p><p>
Another difference between the two tools is the output. You can select between a
table, text and JSON output with AWS CLI; however, the text output ends up being
quite different from the format in EC2 API tools. This means if, like me, you have
tools that parse through that output, you'll need to rework them.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1cd5580.0x1dcde00"></a>
Check Whether a Host Exists</h2></div></div><p>
For instance, I wrote a wrapper script to spawn new EC2 hosts that captures all of
the common options I might pass along the command line based on a host's name. One
check I perform before I spawn a host though is to test whether I already have
an instance tagged with that host's name. So something like this:

<pre     class="programlisting">
ec2-describe-tags --region $REGION | cut -f5 | 
 &#8618;egrep -q "^$MYHOST$"
</pre>
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1cd5580.0x1dcdf60"></a></h2></div></div><p>
becomes something like this:

<pre     class="programlisting">
aws ec2 describe-tags --region $REGION | grep Name | 
 &#8618;grep instance | cut -f5 | egrep -q "^$MYHOST$"
</pre>
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1cd5580.0x1dce0c0"></a>
Find the Security Group ID by Name</h2></div></div><p>
I had to make another change to my script when it came to assigning security
groups. With EC2 Classic, you could refer to security groups by name when spawning
a host by passing multiple <tt  >-g</tt> options to
<tt  >ec2-run-instances</tt>. Once you use VPCs
though, you must refer to a security group by its ID when spawning a host. What I
do is assign all of the security groups that belong to a host to a variable like
so:

<pre     class="programlisting">
SEC_GROUPS='default foo'
</pre>
</p><p>
Then I iterate through that list to pull out the IDs:

<pre     class="programlisting">
for g in ${SEC_GROUPS}; do
  SGID=$(aws ec2 describe-security-groups --filters 
   &#8618;"Name=group-name,Values=$g" |
grep ^SECURITYGROUPS | cut -f3)                                            
  SGIDS="$SGIDS $SGID"
done
</pre>
</p><p>
Then I can pass <tt  >--security-group-ids $SGIDS</tt> to my
<tt  >aws ec2 run-instances</tt> command.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1cd5580.0x1dce488"></a>
Find the Subnet ID by Name</h2></div></div><p>
Another difference I ran across was in handling VPC subnets. With EC2 Classic, you
didn't have to worry about subnets at all, and although you can label subnets with
names in a VPC, when you spawn a host, it wants you to specify the ID. Again, I put
the subnet label into a variable and use the AWS CLI to pull out the ID:

<pre     class="programlisting">
SUBNETID=$(aws ec2 describe-subnets --filters 
 &#8618;"Name=tag:Name,Values=${SUBNET}" | grep ^SUBNETS | cut -f8)
</pre>
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1cd5580.0x1dce5e8"></a>
Pull Data about a Specific Host</h2></div></div><p>
Back with EC2 API tools, it was easy to get the information about a specific host:

<pre     class="programlisting">
$ ec2-describe-instances | grep myhostname
</pre>
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1cd5580.0x1dce748"></a></h2></div></div><p>
Or the shorthand form:

<pre     class="programlisting">
$ ec2din | grep myhostname
</pre>
</p><p>
Unfortunately, things aren't quite as easy with AWS CLI due to how the text
output is formatted. Instead, you should use the <tt  >--filters</tt> option to limit your
search only to instances that have a Name tag that matches your hostname:

<pre     class="programlisting">
$ aws ec2 describe-instances --filters 
 &#8618;"Name=tag:Name,Values=myhostname"
</pre>
</p><p>
I ended up turning the previous command into a quick script called ec2dingrep:

<pre     class="programlisting">
#!/bin/bash

HOSTNAME=$1
aws ec2 describe-instances --filters 
 &#8618;"Name=tag:Name,Values=${HOSTNAME}"
~
</pre>
</p><p>
All in all, it really took me only part of a day to climb the learning curve of
interacting with VPCs with AWS CLI and rewrite the script I use to spawn servers.
Although so far it does take me a bit longer to string together the commands, much of
that is muscle memory, and the much better speed of AWS CLI over EC2 API tools
makes it worth it.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1cd5580.0x1dceb10"></a></h2></div></div><div class="sidebar"><p class="title"><b>
Resources</b></p><p>
Amazon CLI Documentation: <a href="https://aws.amazon.com/cli" target="_self">https://aws.amazon.com/cli</a>
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1cd5580.0x21c6fc8"></a></h2></div></div><div class="sidebar"><p class="title"><b></b></p><p>Send comments or feedback via <a href="http://www.linuxjournal.com/contact" target="_self">www.linuxjournal.com/contact</a> or to
<a href="mailto:info@linuxjournal.com">info@linuxjournal.com</a>.
</p></div></div></div>
<div class="authorblurb"><p>
Kyle Rankin is a Sr. Systems Administrator in the San Francisco Bay Area
and
the
author of a number of books, including <span   class="emphasis"><em>The Official Ubuntu Server
Book</em></span>,
<span   class="emphasis"><em>Knoppix Hacks</em></span> and <span   class="emphasis"><em>Ubuntu Hacks</em></span>.
He is currently the president of the North
Bay Linux Users' Group.

</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../258/toc258.html">Issue Table of Contents</a>
    <a class="link3" href="../258/11927.html">Article</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>