<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>The &ldquo;Virtual File System&rdquo; in Linux</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;    This article outlines the VFS structure and gives an overview of&#10;    how the Linux kernel accesses its file hierarchy. The information&#10;    herein refers to Linux 2.0.x (for any x) and 2.1.y (with y up to at&#10;    least 18).&#10;    "><meta name="keywords" content="kernel, development, filesystem, programming"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0xaf1580.0xbe8ab0"></a>The &ldquo;Virtual File System&rdquo; in Linux</h1></div><div><div class="author"><h3 class="author">Alessandro Rubini</h3></div><div class="issuemoyr">Issue #37, May 1997</div></div><div><p>
    This article outlines the VFS structure and gives an overview of
    how the Linux kernel accesses its file hierarchy. The information
    herein refers to Linux 2.0.x (for any x) and 2.1.y (with y up to at
    least 18).
    </p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xaf1580.0xbe93a0"></a></h2></div></div><p>The main data item in any Unix-like
system is the &ldquo;file&rdquo;, and a unique path name identifies each file
within a running system. Every file appears like any other file in
the way it is accessed and modified: the same system calls and the
same user commands apply to every file. This applies independently
of both the physical medium that holds information and the way
information is laid out on the medium. Abstraction from the
physical storage of information is accomplished by dispatching data
transfer to different device drivers. Abstraction from the
information layout is obtained in Linux through the VFS
implementation.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xaf1580.0xbe94a8"></a>The Unix Way</h2></div></div><p>Linux looks at its file system in the same way Unix
does&mdash;adopting the concepts of super block, inode, directory and
file. The tree of files accessible at any time is determined by how
the different parts are assembled, each part being a partition of
the hard drive or other physical storage device that is &ldquo;mounted&rdquo;
to the system.</p><p>While the reader is assumed to be well acquainted with the
concept of mounting a file system, I'll detail the concepts of
super block, inode, directory and file.</p><div class="itemizedlist"><ul type="disc"><li><p>The <span   class="bold"><b>super block</b></span>
owes its name to its heritage, from when the first data block of a
disk or partition was used to hold meta information about the
partition itself. The super block is now detached from the concept
of data block, but it still contains information about each mounted
file system. The actual data structure in Linux is called
<b  >struct super_block</b> and holds various
housekeeping information, like mount flags, mount time and device
block size. The 2.0 kernel keeps a static array of such structures
to handle up to 64 mounted file systems.</p></li><li><p>An <span   class="bold"><b>inode</b></span> is
associated with each file. Such an &ldquo;index node&rdquo; holds all the
information about a named file except its name and its actual data.
The owner, group, permissions and access times for a file are
stored in its inode, as well as the size of the data it holds, the
number of links and other information. The idea of detaching file
information from file name and data is what allows the
implementation of hard-links&mdash;and the use of &ldquo;dot&rdquo; and
&ldquo;dot-dot&rdquo; notations for directories without any need to treat
them specially. An inode is described in the kernel by a
<b  >struct inode</b>.</p></li><li><p>The <span   class="bold"><b>directory</b></span> is a
file that associates inodes to file names. The kernel has no
special data structure to represent a directory, which is treated
like a normal file in most situations. Functions specific to each
file system type are used to read and modify the contents of a
directory independently of the actual layout of its data.</p></li><li><p>The <span   class="bold"><b>file</b></span> itself is
associated with an inode. Usually files are data areas, but they
can also be directories, devices, fifos (first-in-first-out) or
sockets. An &ldquo;open file&rdquo; is described in the Linux kernel by a
<b  >struct file</b> item; the structure holds a pointer
to the inode representing the file. <b  >file</b>
structures are created by system calls like <b  >open,
pipe</b> and <b  >socket</b>, and are shared by
father and child across <b  >fork</b>.</p></li></ul></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xaf1580.0xbe9ce8"></a>Object Orientedness</h2></div></div><p>While the previous list describes the theoretical
organization of information, an operating system must be able to
deal with different ways to layout information on disk. While it is
theoretically possible to look for an optimum layout of information
on disks and use it for every disk partition, most computer users
need to access all of their hard drives without reformatting, to
mount NFS volumes across the network, and to sometimes even access
those funny CD-ROMs and floppy disks whose file names can't exceed
8+3 characters.</p><p>The problem of handling different data formats in a
transparent way has been addressed by making super blocks, inodes
and files into &ldquo;objects&rdquo;; an object declares a set of operations
that must be used to deal with it. The kernel won't be stuck into
big <b  >switch</b> statements to be able to access the
different physical layouts of data, and new file system types can
be added and removed at run time.</p><p>The entire VFS idea, therefore, is implemented around sets of
operations to act on the objects. Each object includes a structure
declaring its own operations, and most operations receive a pointer
to the &ldquo;self&rdquo; object as the first argument, thus allowing
modification of the object itself.</p><p>In practice, a super block structure encloses a field
<b  >struct super_operations *s_op</b>, an inode encloses
<b  >struct inode_operations *i_op</b> and a file
encloses <b  >struct file_operations *f_op</b>.</p><p>All the data handling and buffering performed by the Linux
kernel is independent of the actual format of the stored data.
Every communication with the storage medium passes through one of
the <b  >operations</b> structures. The file system type,
then, is the software module which is in charge of mapping the
operations to the actual storage mechanism&mdash;either a block device,
a network connection (NFS) or virtually any other means of storing
and retrieving data. These modules can either be linked to the
kernel being booted or compiled as loadable modules.</p><p>The current implementation of Linux allows use of loadable
modules for all file system types but root (the root file system
must be mounted before loading a module from it). Actually, the
<b  >initrd</b> machinery allows loading of a module
before mounting the root file system, but this technique is usually
exploited only on installation floppies.</p><p>In this article I use the phrase &ldquo;file system module&rdquo; to
refer either to a loadable module or a file system decoder linked
to the kernel.</p><p>This is in summary how all file handling happens for any
given file system type, and is depicted in Figure 1:</p><div       class="mediaobject"><a href="2108f1.large.jpg"><img src="2108f1.jpg"></a></div><div class="itemizedlist"><ul type="disc"><li><p><b  >struct file_system_type</b> is a
structure that declares only its own name and a
<b  >read_super</b> function. At <b  >mount</b>
time, the function is passed information about the storage medium
being mounted and is asked to fill a super block structure, as well
as loading the inode of the root directory of the file system as
<b  >sb-&gt;s_mounted</b> (where <b  >sb</b> is
the super-block just filled). The additional field
<b  >requires_dev</b> is used by the file system type to
state whether it will access a block device: for example, the NFS
and <b  >proc</b> types don't require a device, while
<b  >ext2</b> and <b  >iso9660</b> do. After
the super block is filled, <b  >struct
file_system_type</b> is not used any more; only the super
block just filled will hold a pointer to it in order to be able to
give back status information to the user
(<b  >/proc/mounts</b> is an example of such
information). The structure is shown in Listing 1.</p></li></ul></div><p><a href="2108l1.html" target="_self">Listing 1</a>
<div class="itemizedlist"><ul type="disc"><li><p>The <b  >super_operations</b> structure
is used by the kernel to read and write inodes, write super block
information back to disk and collect statistics (to deal with the
<span   class="emphasis"><em>statfs</em></span> and <span   class="emphasis"><em>fstatfs</em></span> system
calls). When a file system is eventually unmounted, the
<span   class="emphasis"><em>put_super</em></span> operation is called&mdash;in standard
kernel wording &ldquo;get&rdquo; means &ldquo;allocate and fill&rdquo;, &ldquo;read&rdquo; means
&ldquo;fill&rdquo; and &ldquo;put&rdquo; means &ldquo;release&rdquo;. The
<b  >super_operations</b> declared by each file system
type are shown in Listing 2.</p></li></ul></div>

<a href="2108l2.html" target="_self">Listing 2</a>
<div class="itemizedlist"><ul type="disc"><li><p>After a memory copy of the inode has been created,
the kernel will act on it using its own operations. <b  >struct
inode_operations</b> is the second set of operations declared
by file system modules, and is listed below; they deal mainly with
the directory tree. Directory-handling operations are part of the
inode operations because the implementation of a
<b  >dir_operations</b> structure would bring in extra
conditionals in file system access. Instead, inode operations that
only make sense for directories will do their own error checking.
The first field of the inode operations defines the file operations
for regular files. If the inode is a fifo, a socket or a
device-specific file operation will be used. Inode operations
appear in Listing 3; note the definition of
<b  >rename</b> was changed in release 2.0.1.</p></li></ul></div>

<a href="2108l3.html" target="_self">Listing 3</a>
<div class="itemizedlist"><ul type="disc"><li><p>The <b  >file_operations</b>, finally,
specify how data in the actual file is handled: the operations
implement the low-level details of <b  >read, write,
lseek</b> and the other data-handling system calls. Since the
same <b  >file_operations</b> structure is used to act on
devices, it also includes some fields that only make sense for
character or block devices. It's interesting to note that the
structure shown here is the structure declared in the 2.0 kernels,
while 2.1 changed the prototypes of <b  >read, write</b>
and <b  >lseek</b> to allow a wider range of file
offsets. The file operations (as of 2.0) are shown in Listing
4.</p></li></ul></div>

<a href="2108l4.html" target="_self">Listing 4</a>
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xaf1580.0xbe1a18"></a>Typical Implementation Problems</h2></div></div><p>The mechanisms to access file system data described above are
detached from the physical layout of data and are designed to
account for all the Unix semantics as far as file systems are
concerned.</p><p>Unfortunately, not all file system types support all of the
functions just described&mdash;in particular, not every type has the
concept of &ldquo;inode&rdquo;, even though the kernel identifies every file
by means of its <b  >unsigned long</b> inode number. If
the physical data accessed by a file system type has no physical
inodes, the code implementing <b  >readdir</b> and
<b  >read_inode</b> must invent an inode number for each
file in the storage medium.</p><p>A typical technique to choose an inode number is using the
offset of the control block for the file within the file system
data area, assuming the files are identified by something that can
be called a &ldquo;control block&rdquo;. The <b  >iso9660</b> type,
for example, uses this technique to create an inode number for each
file in the device.</p><p>The <b  >/proc</b> file system, on the other hand,
has no physical device from which to extract its data and,
therefore, uses hardwired numbers for files that always exist, like
<b  >/proc/interrupts</b>, and dynamically allocated
inode numbers for other files. The inode numbers are stored in the
data structure associated with each dynamic file.</p><p>Another typical problem faced when implementing a file system
type is dealing with limitations in the actual storage
capabilities. For example, how to react when the user tries to
rename a file to a name longer than the maximum allowed length for
the particular file system, or when she tries to modify the access
time of a file within a file system that doesn't have the concept
of access time.</p><p>In these cases, the standard is to return
<b  >-ENOPERM</b>, which means &ldquo;Operation not
permitted&rdquo;. Most VFS functions, like all the system calls and a
number of other kernel functions, return zero or a positive number
in case of success, and a negative number in the case of errors.
Error codes returned by kernel functions are always one of the
integer values defined in
<b  >&lt;asm/errno.h&gt;</b>.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xaf1580.0xbe1f98"></a>Dynamic /proc Files</h2></div></div><p>I'd now like to show a little code to play with VFS, but it's
quite hard to conceive of a small enough file system type to fit in
the article. Writing a new file system type is surely an
interesting task, but a complete implementation includes 39
&ldquo;operation&rdquo; functions.</p><p>Fortunately enough, the <b  >/proc</b> file system
as defined in the Linux kernel lets modules play with the VFS
internals without the need to register a whole new file system
type. Each file within <b  >/proc</b> can define its own
inode operations and file operations and is, therefore, able to
exploit all the features of the VFS. The method of creating
<b  >/proc</b> files is easy enough to be introduced
here, although not in too much detail. &ldquo;Dynamic
<b  >/proc</b> files&rdquo; are so named because their inode
number is dynamically allocated at file creation (instead of being
extracted from an inode table or generated by a block
number).</p><p>In this section we build a module called
<b  >burp</b>, for &ldquo;Beautiful and Understandable
Resource for Playing&rdquo;. Not all of the module will be shown because
the innards of each dynamic file are not related to VFS.</p><p>The main structure used in building up the file tree of
<b  >/proc</b> is <b  >struct
proc_dir_entry</b>. One such structure is associated with
each node within <b  >/proc</b>, and it is used to keep
track of the file tree. The default <b  >readdir</b> and
<b  >lookup</b> inode operations for the file system
access a tree of <b  >struct proc_dir_entry</b> to return
information to the user process.</p><p>The <b  >burp</b> module, once equipped with the
needed structures, will create three files:
<b  >/proc/root</b> is the block device associated with
the current root partition, <b  >/proc/insmod</b> is an
interface to load/unload modules without the need to become root,
and <b  >proc/jiffies</b> reads the current value of the
jiffy counter (i.e., the number of clock ticks since system boot).
These three files have no real value and are just meant to show how
the inode and file operations are used. As you see,
<b  >burp</b> is really a &ldquo;Boring Utility Relying on
Proc&rdquo;. To avoid making the utility too boring I won't give the
details about module loading and unloading, since they have been
described in previous <span   class="emphasis"><em>Kernel Korner</em></span> articles
which are now accessible on the Web. The whole
<b  >burp.c</b> file is available as well from SSC's ftp
site.</p><p>Creation and destruction of <b  >/proc</b> files is
performed by calling the following functions:</p><pre     class="programlisting">
   proc_register_dynamic(struct proc_dir_entry \
      *where, struct proc_dir_entry *self);
   proc_unregister(struct proc_dir_entry *where, \
       int inode);
</pre><p>In both functions, <b  >where</b> is the directory
where the new file belongs, and we'll use
<b  >&amp;proc_root</b> to use the root directory of the
file system. The <b  >self</b> structure, on the other
hand, is declared inside <b  >burp.c</b> for each of the
three files. The definition of the structure is reported in Listing
5 for your reference; I'll show the three <b  >burp</b>
incarnations of the structure in a while, after discussing their
role in the game.
</p><p><a href="2108l5.html" target="_self">Listing 5</a></p><p>The &ldquo;synchronous&rdquo; part of <b  >burp</b> reduces
therefore to three lines within <b  >init_module()</b>
and three within <b  >cleanup_module()</b>. Everything
else is dispatched by the VFS interface and is &ldquo;event-driven&rdquo;
inasmuch as a process accessing a file can be considered an event
(yes, this way to see things <span   class="emphasis"><em>is</em></span> unorthodox,
and you should never use it with professional people).</p><p>The three lines in <b  >ini_module()</b> look
like:</p><pre     class="programlisting">
   proc_register_dynamic(&amp;proc_root, \
      &amp;burp_proc_root);
</pre><p>and the ones in <b  >cleanup_module()</b> look
like:
<pre     class="programlisting">
   proc_unregister(&amp;proc_root, \
      burp_proc_root.low_ino);
</pre>


The <b  >low_ino</b> field is the inode number for the
file being unregistered, and has been dynamically assigned at load
time.
</p><p>But how will these three files respond to user access? Let's
look at each of them independently.</p><div class="itemizedlist"><ul type="disc"><li><p><b  >/proc/root</b> is meant to be a
block device. Its &ldquo;mode&rdquo; should, therefore, have the
<b  >S_IFBLK</b> bit set, its inode operations should be
those of block devices and its device number should be the same as
the root device currently mounted. Since the device number
associated with the inode is not part of the
<b  >proc_dir_entry</b> structure, the
<b  >fill_inode</b> field must be used. The inode number
of the root device will be extracted from the table of mounted file
systems.</p></li><li><p><b  >/proc/insmod</b> is a writable file.
It needs its own <b  >file_operations</b> to declare its
&ldquo;write&rdquo; method. Therefore, it declares its
<b  >inode_operations</b> that points to its file
operations. Whenever its <b  >write()</b> implementation
is called, the file asks <span   class="emphasis"><em>kerneld</em></span> to load or
unload the module whose name has been written. The file is writable
by anybody. This is not a big problem as loading a module doesn't
mean accessing its resources and what is loadable is still
controlled by root via <b  >/etc/modules.conf</b>.</p></li><li><p><b  >/proc/jiffies</b> is much easier;
the file is read-only. Kernel versions 2.0 and later offer a
simplified interface for read-only files: the
<b  >get_info</b> function pointer, if set, will be asked
to fill a page of data each time the file is read. Therefore,
<b  >/proc/jiffies</b> doesn't need its own file
operations nor inode operations; it just uses
<b  >get_info</b>. The function uses
<b  >sprintf()</b> to convert the integer
<b  >jiffies</b> value to a string.</p></li></ul></div><p><a href="2108l6.html" target="_self">Listing 6</a>
</p><p>The snapshot of a tty session in Listing 6 shows how the
files appear and how two of them work. Listing 7, finally, shows
the three structures used to declare the file entries in
<b  >/proc</b>. The structures have not been completely
defined, because the C compiler fills with zeroes any partially
defined structure without issuing any warning (feature, not
bug).</p><p><a href="2108l7.html" target="_self">Listing 7</a></p><p>The module has been compiled and run on a PC, an Alpha and a
Sparc, all of them running Linux version 2.0.x</p><p>The <b  >/proc</b> implementation has other
interesting features to offer, the most notable being the
<span   class="emphasis"><em>sysctl</em></span> interface. This idea is so interesting,
and it will need to be covered in a future <span   class="emphasis"><em>Kernel
Korner</em></span>.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xaf1580.0xef8170"></a>Interesting Examples</h2></div></div><p>My discussion is now finished, but there are many places
where interesting source code is available for viewing.
Implementations of file system types worth examining:</p><div class="itemizedlist"><ul type="disc"><li><p>Obviously, the &ldquo;/proc&rdquo; file system: it is quite
easy to look at, because it is neither performance-critical nor
particularly fully featured (except the <span   class="emphasis"><em>sysctl</em></span>
idea). Enough said.</p></li><li><p>The &ldquo;UMSDOS&rdquo; file system: it is part of the
mainstream kernel and runs piggy-back on the &ldquo;Ms-DOS&rdquo; file
system. It implements only a few of the operations of the VFS to
add new capabilities to an old-fashioned file system format.</p></li><li><p>The &ldquo;userfs&rdquo; module: it is available from both
tsx-11 and sunsite under <b  >ALPHA/userfs</b>; version
0.9.3 will load to Linux 2.0. This module defines a new file system
type which uses external programs to retrieve data; interesting
applications are the ftp file system and a read-only file system to
mount compressed tar files. Even though reverting to user programs
to get file system data is dangerous and might lead to unexpected
deadlocks, the idea is quite interesting.</p></li><li><p>&ldquo;supermount&rdquo;: the file system is available on
sunsite and mirrors. This file system type is able to mount
removable devices like floppies or CD-ROMs and handle device
removal without forcing the user to <b  >umount/mount</b>
the device. The module works by controlling another file system
type while arranging to keep the device unmounted when it is not
used; the operation is transparent to the user.</p></li><li><p>&ldquo;ext2&rdquo;: the extended-2 file system has been the
standard Linux file system for a few years now. It is difficult
code, but worth reading for those interested in seeing how a real
file system is implemented. It also has hooks for interesting
security features like the immutable-flag and the append-only-flag.
Files marked as immutable or append-only can only be deleted when
the system is in single-user mode, and are therefore secured from
network intruders.</p></li><li><p>&ldquo;romfs&rdquo;: this is the smallest file system I've
ever seen. It was introduced in Linux-2.1.21. It's a single source
file, and it's quite enjoyable to browse. As its name asserts, it
is read-only.</p></li></ul></div></div></div>
<div class="authorblurb"><p> is a wild soul with an attraction for
      source code. He is a fan of Linus Torvalds and Baden Powell and
      enjoys the two communities of volunteer workers they have
      attracted. He can be reached at rubini@linux.it.</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../037/toc037.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>