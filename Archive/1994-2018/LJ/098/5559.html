<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>The OSCAR Revolution</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;    Richard describes the history and goals of the Open Source&#10;    Cluster Application Resource.&#10;    "><meta name="keywords" content="OSCAR, cluster, SystemImager, LUI"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x27a3580.0x289aab0"></a>The OSCAR Revolution</h1></div><div><div class="author"><h3 class="author">Richard Ferri</h3></div><div class="issuemoyr">Issue #98, June 2002</div></div><div><p>
    Richard describes the history and goals of the Open Source
    Cluster Application Resource.
    </p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x27a3580.0x289b5b0"></a></h2></div></div><p>&ldquo;Serve no whine before its time&rdquo; is a
bad pun attributed to Rob Pennington of NCSA at the very first
OSCAR meeting, held in April 2000 at a hotel a stone's throw from
Oak Ridge National Lab. A varied cast representing the national
labs, academia and industry was assembled to discuss what was known
at the time as the CCDK (Community Cluster Development Kit), which
would morph into the OCG (Open Cluster Group) and their first
project, OSCAR (the Open Source Cluster Application Resource).
</p><p>The cast had broken clusters down into components and had
assigned &ldquo;czars&rdquo; (leaders) and &ldquo;whiners&rdquo; (interested parties)
for each component. The czars were to lead each component group,
and the whiners were to whine loudly and often enough to make sure
things got done on schedule, meeting the group's requirements. From
that very first meeting when the czars and whiners were named, it
was clear that OSCAR development would be different from all other
software development that had gone before. After all, where else
would one find companies like IBM, Dell, SGI and Intel working
closely together to produce open solutions in a hotly contested
space like clustering?</p><p>The original idea for OSCAR came about over dinner at a
DOE-sponsored cluster meeting at Argonne National Lab, where Dr.
Timothy Mattson, a research scientist at Intel, and Dr. Stephen
Scott, a research scientist at Oak Ridge National Lab, discussed
the problem of getting Linux clusters accepted into the mainstream.
The problem, they decided, was that it was just too difficult for
noncomputer programmers to assemble their own cluster. Books like
<span   class="emphasis"><em>How to Build a Beowulf</em></span> (Sterling, et. al.)
would help the computer savvy understand the concepts and construct
his or her first cluster, but there were still daunting problems.
There was an enormous amount of code to download, all at differing
levels of reliability, support, integration and documentation.
Sometimes the documentation for various packages was dated and
contradictory. There were many Linux distributions to choose from,
each trying to distinguish themselves by being slightly different
from the next distribution. This meant that some commands worked
differently or that different packages had to be installed to get a
service to work properly.</p><p>The problem, they decided, was that with everyone trying to
build their own cluster to tap into cheap cluster computing, each
cluster was being built from scratch. There had to be some economy
in compiling the best available software, practices and
documentation in a single spot, integrating the package on
different types of hardware and making it available to users for
free (as in free beer). This concept, making clusters easy to build
for the nonprogrammer, is a central tenet of OSCAR.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x27a3580.0x289b818"></a>First Meeting</h2></div></div><p>The historic first meeting in Oak Ridge was attended by Tim
Mattson and Stephen Scott, the leaders of the OCG; Gabriel Bonner
from SGI; Dave Lombard from MSC.Software; Rob Pennington of NCSA;
Greg Lindahl, now of Conservative Computers; Ken Briskey and myself
from IBM; Greg Astfalk from HP; and Clay Taylor from MPI Software
Technologies. Shortly after the first meeting, Broahn Mann from
Veridian joined to bring his parallel scheduling skill to the team,
as did Jeremy Enos and Neil Gorsuch from NCSA (who implemented SSH
on OSCAR) and Mike Brim from Oak Ridge National Lab (who wrote most
of the integration scripts and packaging). Most recently, Jeff
Squyres and Brian Barrett from Indiana University joined the OSCAR
Project representing LAM/MPI. The disparate group agreed on three
major core principles:</p><div class="orderedlist"><ol type="1"><li><p>That the adoption of clusters for mainstream,
high-performance computing is inhibited by a lack of well-accepted
software stacks that are robust and easy to use by the general
user.</p></li><li><p>That the group embraces the open-source model of
software distribution. Anything contributed to the group must be
freely distributable, preferably as source code under the Berkeley
open-source license.</p></li><li><p>That the group can accomplish its goals by
propagating best-known practices built up through many years of
hard work by cluster computing pioneers.</p></li></ol></div><p>With these principles firmly in place, the group used a
divide-and-conquer method to list the components that comprise
clusters. The component groups decided on the best-known,
open-source solutions for each component and presented the
information to the group at large. Taken collectively, these
best-known practices for each component comprised a viable cluster
solution. Even with the component solutions in hand, there was a
massive and time-consuming integration effort by Oak Ridge National
Lab, led by Mike Brim and Brian Luethke, and a separate test
effort, which was led by Jenwei Hsieh, Tau Leng and Yung-Chin Fang
from Dell. Through their efforts, and face-to-face and
remote-integration parties, OSCAR eventually morphed into something
to share with the rest of the community.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x27a3580.0x289bbe0"></a>The Software Stack</h2></div></div><p>It took nearly a full year, but OSCAR had a beta
demonstration at SC2000 in Dallas, Texas at the Oak Ridge National
Lab booth in November 2000. The beta was run on a heterogeneous
cluster of servers provided by Dell and SGI. The first release was
announced shortly thereafter and made a successful debut at
LinuxWorld Expo in New York City in February 2001, at the Intel
booth. Since then, there have been continuous improvements in the
OSCAR software stack, which currently includes:</p><div class="itemizedlist"><ul type="disc"><li><p>Linux installation: SIS (system installation
suite). SIS is an open-source cluster installation tool based on
the merger of LUI (the Linux utility for cluster install) and the
popular SystemImager. SIS, developed by Michael Chase-Salerno and
Sean Dague from IBM, made its debut in the 1.2.1 version of OSCAR.
Most recently, Brian Finley of Bald Guy Software, the creator of
SystemImager, has been attending the OSCAR meetings and looking for
free beer, as in free beer.</p></li><li><p>Security: OpenSSH&mdash;the most common way to allow
secure connections in a Linux environment. OpenSSH is a collection
of packages that handles secure connections, server-side SSH
services, secure key generation and any other functions used to
support secure connections between computers.</p></li><li><p>Cluster management: for cluster-wide management
operations, OSCAR uses the Cluster Command and Control (C3)
management package developed at Oak Ridge National Lab by Stephen
Scott and Brian Luethke, an East Tennessee State University student
working at ORNL. C3 provides a &ldquo;single-system illusion&rdquo; so that a
single command affects the entire cluster. C3 remains installed on
the cluster nodes for later use by cluster users and
administrators.</p></li><li><p>Programming environments: Message-Passing Interface
(MPI) and Parallel Virtual Machine (PVM). Most cluster users write
the software that runs on the cluster. There are many different
ways to write software for clusters. The most common approach is to
use a message-passing library. Currently, compilers or math
libraries installed by OSCAR come from the Linux distribution. Both
LAM/MPI and MPICH have been available since OSCAR 1.1.</p></li><li><p>Workload management: Portable Batch System (PBS)
from Veridian and Maui Scheduler (developed by Maui High Times
Computing Center). To time-share a cluster, some type of workload
or job management is needed. Maui acts as a job scheduler for
OSCAR, making all resource allocation and scheduling decisions. PBS
is the job server/launcher and in addition to launching and killing
jobs, handles job queues.</p></li></ul></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x27a3580.0x289c0b0"></a>MSC.Software and OSCAR</h2></div></div><p>MSC.Linux, a distribution developed by the Systems Division
of MSC.Software Corporation, is of special importance in the
acceptance of OSCAR. Shortly after the 1.0 version of OSCAR was
available, MSC.Software announced their own cluster solution, the
MSC.Linux Version 2001 operating system. This 2001 offering was in
large part based on OSCAR, the first commercial offering based on
the work of the OCG. MSC.Software's Joe Griffin added a Webmin
interface to LUI (the first OSCAR cluster installation tool), which
generated LUI bottom-line commands for multiple nodes to provide an
easy-to-use interface in defining the nodes of the cluster and what
resources to install on each. One of the original intents of the
OCG was that commercial companies would see the value in the open
OSCAR software stack and build their own proprietary or open stacks
around the OSCAR stack. In so doing, companies using OSCAR would be
freed from the mundane chores associated with building a cluster,
such as providing the basic infrastructure, and could concentrate
instead on more cutting-edge improvements to distinguish their
offering.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x27a3580.0x289c1b8"></a>Working Together</h2></div></div><p>Like other far-flung open-source projects, it was clear from
the beginning that doing the work of the consortium face to face
would not always be an option. The travel expense was simply too
great, and it was difficult to align so many schedules. To
coordinate the work, the group held open weekly phone conferences
and would rely on mailing lists and an occasional meeting at a
workshop or expo. There were face-to-face &ldquo;integration parties&rdquo;
held quarterly, one at Intel in Hillsboro, Oregon and another at
NCSA in Illinois. But for integrations held between meetings, a new
construct was developed, called DIP Day, for distributed
integration party. The intent of DIP Days was that everyone working
on the project that had a cluster would set aside those days to
work on OSCAR, jointly and remotely. Everyone would download the
OSCAR package and install and run it, reporting any bugs to the
group. On DIP Days, programmers were expected to provide fixes in
real time, so that multiple iterations of the code could be tested
shortly. Several conference calls with the entire team were held
every DIP Day to assess progress and assign new work and
priorities. By loosely coordinating the group between DIPs and
face-to-face meetings, OSCAR made great strides in reliability and
function.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x27a3580.0x289c2c0"></a>The OSCAR Experience: First Impressions</h2></div></div><p>The first thing one notices when untarring the OSCAR file is
that the OSCAR integration and test team has done a thorough job;
there is extensive documentation on how to install OSCAR, the
system requirements, the licensing (GPL) and the theory behind
OSCAR itself. There is a quick start guide for the impatient
cluster administrator, as well as a full descriptive text. One also
notices that there's nothing additional to download; it's all
included in the single OSCAR tar file. OSCAR takes the traditional
view of clusters&mdash;a single server with <span   class="emphasis"><em>N</em></span>
compute nodes; the server is responsible for installing, scheduling
and monitoring the compute nodes. Nodes in the cluster should be
running homogeneous software, meaning the same distribution and
version of Linux. The first command the user enters is
<b  >install_cluster</b>, which does a multitude of
things: creates necessary directories; manages NFS and xinetd;
installs LAM/MPI, C3, PBS, Maui, OpenSSH, SIS, Perl, SystemImager
and MPICH; updates various profiles and configuration scripts; and
launches the OSCAR wizard.</p><p>If all goes well, you're in for a pleasant surprise, namely,
the OSCAR wizard. The OSCAR team felt the wizard would be another
distinguishing feature of OSCAR in the field of Linux cluster
solutions. The purpose of the wizard is clear&mdash;follow the wizard
and you too can install a cluster painlessly. Each step along the
wizard's path has entry and exit criteria. Once the exit criteria
is successfully met, OSCAR gives a success message to indicate it's
safe to move on to the next step.</p><div       class="mediaobject"><img src="5559f1.jpg"><div class="caption"><p>
Figure 1. The OSCAR Wizard
</p></div></div><p>Following the wizard, pressing the Build OSCAR client image
button brings up the second panel, the Create a SystemImager Image
panel.</p><div       class="mediaobject"><a href="5559f2.large.jpg"><img src="5559f2.jpg"></a><div class="caption"><p>
Figure 2. Building a SystemImager Image
</p></div></div><p>The purpose of the SystemImager panel is to create a
filesystem on the server that will later be installed on each
client. The Image Name field allows the user to create multiple
SystemImager images, each with a unique name. The Package File
field provides a list of packages that will be installed on the
client; OSCAR provides sample lists that meet most user
requirements. The Packages Directory tells where the RPMs are
coming from, and the Disk Partition File field allows the user to
customize the disk partitions. Again, OSCAR provides default disk
partition definition files for both IDE and SCSI drives. Pressing
the Build Image button starts the process of building a client
image on the server. Once complete, it's time to go back to the
wizard for step two, defining the OSCAR clients.</p><div       class="mediaobject"><img src="5559f3.jpg"><div class="caption"><p>
Figure 3. Adding Clients to a SystemImager Image
</p></div></div><p>From the Add Clients panel, the user can specify a range of
IP addresses to be associated with a list of new clients. Each
client is associated with an image name using the Image Name field.
One can define a set of clients in a range of IP addresses, each
having the same netmask and default gateway. Pressing the
Addclients button builds client definitions for SIS. Once complete,
it's back to step three on the wizard, Setup Networking.</p><div       class="mediaobject"><img src="5559f4.jpg"><div class="caption"><p>
Figure 4. MAC Address Collection
</p></div></div><p>From the Setup Networking panel, MAC addresses are collected
for each client in the cluster. If the node is capable of true
network (PXE) boot, you simply associate a MAC address with a
client, and you're ready to power up the node. If the node is not
PXE-enabled, you can write a SystemImager boot diskette from the
Build Autoinstall Floppy button. Once the MAC addresses are
collected, it's time to press the button to Configure the DHCP
Server and boot all the nodes to initiate Linux
installation.</p><p>Once all the nodes are installed, each node starts this
really annoying and incessant beeping telling the system
administrator to pop out the diskette or turn off PXE and reboot
the node from the hard drive. Once they are all booted, the nodes
are ready to Complete Cluster Setup from the wizard (really just
syncing the time between servers and clients and running any
package-sensitive postiinstallation scripts). The Test Cluster
Setup button from the wizard runs short jobs, checking each flavor
of scheduler and parallel library.</p><p>Once the cluster is fully installed and functioning, there
are test scripts to check the overall health of the cluster.
Running the test_install script will check to make sure PBS or Maui
Scheduler is configured and running, that the C3 tools are
installed and that the cluster at that time is ready to start
accepting parallel jobs.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x27a3580.0x2893650"></a>OSCAR Futures</h2></div></div><p>As of this writing, OSCAR 1.2.1 is available, which runs
under Red Hat Linux 7.1. MSC.Linux Version 2001 is based on OSCAR
1.1. The 1.x1 releases were quite popular in the community&mdash;they've
been downloaded roughly 25,000 times from SourceForge. However, the
biggest problem OSCAR is now facing is that it takes the relatively
few OSCAR developers time and effort to integrate all the new
software packages that want to be included in OSCAR. The OSCAR 2.0
effort is underway, with an emphasis on establishing component APIs
so that anyone with an open software package can integrate their
package with OSCAR. The OCG itself is growing. Since Tim Mattson
went on Intel sabbatical, Jeff Squyres from the University of
Indiana has taken the leadership role in the OSCAR 2.0 architecture
and consistency. Ibrahim Haddad from Ericsson [and a frequent
<i  >LJ</i> contributor] has joined the consortium with
interesting ideas on how to bring OSCAR to near-telecom levels of
reliability. Jim Garlick, representing Lawrence Livermore National
Lab also has joined the consortium bringing his real-world large
cluster scaling experience and concerns to the group.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x27a3580.0x28937b0"></a>Platforms and Distros</h2></div></div><p>At the very first OSCAR meeting, it was agreed that OSCAR
should not be tied to a particular Linux distribution or platform.
However, to date the OCG's efforts have been largely focused on the
Red Hat and MSC.Linux distributions and the IA-32 architecture.
This focus will expand in 2002. The purpose of integrating SIS into
OSCAR was to be able to support all RPM-based distributions: SuSE,
Turbolinux, Red Hat, MSC.Linux and Caldera, and later to support
deb-based distributions such as Debian. Additionally, the
architecture of SIS makes it easy to port to new platforms. NCSA
already has a beta version of OSCAR running on Itanium, and Oak
Ridge has done extensive testing with Red Hat 7.2. Given the open
API and ability to run on many different distributions and
platforms, expect OSCAR and the OCG to expand dramatically this
year.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x27a3580.0x28938b8"></a>Final Thoughts</h2></div></div><p>The impacts of OSCAR on the Linux clustering community can be
viewed in several different perspectives. At the most apparent,
OSCAR is providing a useful clustering tool that is usable across
various manufacturers' platforms. It has removed much of the
ambiguity inherent in assembling software from various web sites by
putting together a single, integrated, documented, tested and
supported package. It is truly a clustering solution that a
nonprogrammer can implement. However, beneath the surface, the OCG
is a thriving consortium composed of national labs, academia and
industry that are cooperating to bring new open-source solutions to
Linux. Along the way, the consortium had to break new ground in
ways to cooperate, with unique concepts like DIP Days. In
retrospect, the consortium's most important long-term contribution
to the community may be in developing new ways to work together for
the betterment of open source.</p><p><a href="5559s1.html" target="_self">Resources</a></p></div></div>
<div class="authorblurb"><p>
        <div       class="mediaobject"><img src="5559aa.jpg"></div>

       email: <a href="mailto:rcferri@us.ibm.com">rcferri@us.ibm.com</a>
       </p><p><span   class="bold"><b>Richard Ferri</b></span> is
      a senior programmer in IBM's Linux Technology Center, where he
      works on open-source Linux clustering projects such as LUI and
      OSCAR. He now lives in a rural setting in upstate New York with his
      wife Pat, three teen-aged sons and three dogs of suspect
      lineage.</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../098/toc098.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>