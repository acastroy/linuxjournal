<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
Squid-Based Traffic Control and Management System</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;When Web traffic became a major use of the organization's network,&#10;this university put in a control system to track and limit access,&#10;using the open-source Squid caching system.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x2088580.0x217fab0"></a>
Squid-Based Traffic Control and Management System</h1></div><div><div class="authorgroup"><div class="author"><h3 class="author">
Tagir
 K. 
Bakirov
</h3></div><div class="author"><h3 class="author">
Vladimir
 G. 
Kozlov
</h3></div><div class="issuemoyr">Issue #134, June 2005</div></div></div><div><p>
When Web traffic became a major use of the organization's network,
this university put in a control system to track and limit access,
using the open-source Squid caching system.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2088580.0x2180608"></a></h2></div></div><p>
Internet access is one of the major and
most demanded services in the computer network of any
organization. Olifer
and Olifer, in <span   class="emphasis"><em>Computer Networks: Principles, Technologies and
Protocols</em></span> write that
 during the past 10&ndash;15 years, the
80/20 split between
internal and outgoing traffic has
turned over, and the split is now 80% outgoing (see the on-line Resources).
The speed of access, the number of services
and the volume of available content increase
permanently. And the actuality of the Internet
user access control task grows up. This problem is
quite old, but now some of its aspects are changing. In
this article, we consider the variants of its modern
solution in the example of the computer network at
Bashkir State Pedagogical University (BSPU).
</p><p>
First, we proposed some initial requirements for the
Internet access control and management system:
</p><div class="itemizedlist"><ul type="disc"><li><p>
User account support and management.
</p></li><li><p>
User traffic accounting and control.
</p></li><li><p>
Three types of user traffic limitation: per month, per week and per day.
</p></li><li><p>
Support for mobile users&mdash;people who use different computers each
time they access the Internet, such as students.
</p></li><li><p>
Daily and weekly statistics and system condition Web and e-mail reports.
</p></li><li><p>
Web-based statistics and system management.
</p></li></ul></div><p>
Apparently, these requirements do not specify the system implementation
stage in any way and hence do not limit our &ldquo;fantasy&rdquo; in this
aspect. Therefore, we have done a general consideration of the problem
and how to solve it. In the rest of this article, we discuss
the ideas and reasoning that led us to our final decision.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2088580.0x2180ce8"></a>
Common Analysis of the Problem</h2></div></div><p>
Let us revisit the Internet access process itself, with the example of
the most popular World Wide Web (WWW) service:
</p><div class="orderedlist"><ol type="1"><li><p>
The user runs the browser and enters the required URL.
</p></li><li><p>
The browser establishes the connection either
directly with the WWW server via the gateway, which
makes the network address translation or other network
packet manipulations, or with the proxy server,
which analyses the client request thoroughly and looks
through its cache for the required information. If
there is no such information or if it is outdated,
the proxy server connects with the WWW server in its
own name.
</p></li><li><p>
The obtained information is returned to the client.
</p></li><li><p>
The browser ends the connection or enters the keep-alive
state.
</p></li></ol></div><p>
Figure 1 shows the scheme of Internet user access
organization.
</p><div       class="mediaobject"><a href="8002f1.large.jpg"><img src="8002f1.jpg"></a><div class="caption"><p>
Figure 1. Internet User Access Organization
</p></div></div><p>
The main elements of the scheme are the user;
client software, including browser and operating system;
workstation and other client hardware;
network equipment; and
the gateway (or proxy server).
Other user authorization servers, such as Microsoft
Windows domain controllers, OpenLDAP or NIS also may exist in
the network.
</p><p>
As Figure 1 shows, the relation between the users and the workstations
can be of the one-to-one or the many-to-many type. For instance, members
of the university staff are mostly equipped with their own computers.
</p><p>
The main aspects of the problem are
user traffic accounting,
user authentication,
user access control and
management and reporting.
</p><p>
These aspects are quite independent of one another and each of them has several ways of
implementation. The functions of authentication, traffic accounting and
access control may be assigned to any element of the scheme above. And,
the best solution will concentrate all of the functions in the single module
or in the single access scheme element.
</p><p>
Access control can be implemented on the client side or on the
server side. Client-side access control requires using the special
client software, which also can authenticate the users. And, there
are two ways of server-side access control implementation: firewall
and proxy server. Firewall access control has the problem of user
authentication. The network packets include only the IP addresses,
which are not bound to user names. In the case of using a firewall, this
problem has two solutions:
use of VPN, which has its own user authentication mechanism and
dynamic user-to-IP assignment control. This is possible with some
external tools.
</p><p>
The simpler solution, however, is the use of the proxy server, which supports
user authentication using the browser. There are three methods of
browser authentication:
</p><div class="itemizedlist"><ul type="disc"><li><p>
Basic authentication&mdash;a simple and widely distributed scheme, which is
supported by the majority of Internet browsers and proxy servers. Its
main disadvantage is that the user password is sent over the network
with no encryption.
</p></li><li><p>
Digest authentication is a more reliable scheme, which uses password
hashes for security. Its main imperfection is the lack of special
software support.
</p></li><li><p>
NTLM authentication is specific for the Microsoft product network
infrastructure. Nevertheless, this authentication scheme is acceptable
and, furthermore, desirable in many computer networks, including Windows
workstations, which are prevalent in Russia as far as we know. The main
advantage here is the possibility of the integration of the proxy authentication
scheme with Windows and Samba domain controllers.
</p></li></ul></div><p>
The task analysis and some of the ideas above led us to the development
of two systems:
</p><div class="orderedlist"><ol type="1"><li><p>
VPN using PPTP based on the firewall internal features. Historically,
the VPN server used FreeBSD, hence, we used the ipfw firewall
interface and mpd ported application as a PPTP server. Traffic control
is made using the free, distributable NetAMS system.
</p></li><li><p>
Squid-based Internet user access control and management system.
</p></li></ol></div><p>
The first system was developed by Vladimir Kozlov and is used to
connect the university staff members, who use dedicated computers for
Internet access. Its main disadvantage is the requirement of a client-side
VPN setup. This is a considerable obstacle in the case when the computer
network is distributed and the users are not familiar enough with
computers.
</p><p>
The second system was developed by Tagir Bakirov and is used to connect
the majority of university users, who have no constant computer for
Internet access. The complexity of the development was the main drawback
of this solution.
Next, we discuss the implementation
of the second solution in detail.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2088580.0x2181a50"></a>
Squid-Based Internet User Access Control and Management System</h2></div></div><p>
Before we start, we should mention that the file paths here are
always relative to the Squid source base catalog, which, in our case, is
/usr/local/src/squid-2.5STABLE7/. The detailed information of getting,
compiling and using Squid can be obtained from the Squid site.
</p><p>
Let us now consider some characteristics of Squid, taken from the
<span   class="emphasis"><em>Squid Programming Guide</em></span>.
</p><p>
Squid is a single-process proxy server. Every client HTTP request is
handled by the main process. Its execution progresses as a sequence of
callback functions. The callback function is executed when I/O is
ready to occur or some other event has happened. As a callback function
completes, it registers the next callback function for the subsequent I/O.
</p><p>
At the core of Squid are the select(2) or the poll(2) system calls,
which work by waiting for I/O events on a set of file descriptors. Squid
uses them to process I/O on all open file descriptors. comm_select()
is the function that issues the select() system call. It scans the
entire fd_table[] array looking for handler functions. For each ready
descriptor, the handler is called. Handler functions are registered with
the commSetSelect() function. The close handlers normally are called
from comm_close(). The job of the close handlers is to deallocate
data structures associated with the file descriptor. For this reason,
comm_close() normally must be the last function in a sequence.
</p><p>
An interesting Squid feature is the client per-IP
address database support. The corresponding code is in the file
src/client_db.c. The main idea is the hash-indexed table, client_table,
consisting of the pointers to ClientInfo structures. These structures
contain different information on the HTTP client and ICCP proxy server
connections, for example, the request, traffic and time counters. The
following is the
respective code from the file src/structs.h:

<pre     class="programlisting">
struct _ClientInfo {
    /* must be first */
    hash_link hash;
    struct in_addr addr;
    struct {
	int result_hist[LOG_TYPE_MAX];
	int n_requests;
	kb_t kbytes_in;
	kb_t kbytes_out;
	kb_t hit_kbytes_out;
    } Http, Icp;
    struct {
	time_t time;
	int n_req;
	int n_denied;
    } cutoff;
    /* number of current established connections */
    int n_established;
    time_t last_seen;
};
</pre>
</p><p>
Here are some important global and local functions for managing the client
table:
</p><div class="itemizedlist"><ul type="disc"><li><p>
clientdbInit()&mdash;global function that initializes the client table.
</p></li><li><p>
clientdbUpdate()&mdash;global function that updates the record in the
table or adds a new record when needed.
</p></li><li><p>
clientdbFreeMemory()&mdash;global function that deletes the table and
releases the allocated memory.
</p></li><li><p>
clientdbAdd()&mdash;local function that is called by the function
clientdbUpdate() and adds the record into the table and schedules the
garbage records collecting procedure.
</p></li><li><p>
clientdbFreeItem()&mdash;local function that is called by the function
clientdbFreeMemory() and removes the single record from the table.
</p></li><li><p>
clientdbSheduledGC(), clientdbGC() and
clientdbStartGC()&mdash;local functions that implement the garbage records collection
procedure.
</p></li></ul></div><p>
By parallelizing the requirements to the developed system and the
possibilities of the existing client database, we can say that some key
basic features already are implemented, except the client per-user
name indexing. The other significant shortcoming of the existing client
statistic database is that the information is refreshed
after the client already has received the entire requested content.
</p><p>
In our development, we implemented another parallel and independent client
per-user database using the code from the src/client_db.c file with some
modifications. User statistics are kept in structure ClientInfo_sb. The
following
is the corresponding code from the file src/structs.h:

<pre     class="programlisting">
#ifdef SB_INCLUDE
#define SB_CLIENT_NAME_MAX_LENGTH 16
struct _ClientInfo_sb {
    /* must be the first */
    hash_link hash;
    char *name;
    unsigned int GID;
    struct {
	long value;
	char type;
	long cur;
	time_t lu;
    } lmt;
    /* HTTP Request Counter */
    int Counter;
};
#endif
</pre>
</p><p>
The client database is managed by the following global and local
functions, quite similar to those listed previously:
</p><div class="itemizedlist"><ul type="disc"><li><p>
clientdbInit_sb()&mdash;global function that initializes the client
table.
</p></li><li><p>
clientdbUpdate_sb()&mdash;global function that updates the record in
the table, disconnects the client when the limit is exceeded or adds
the new record when needed by calling the function clientdbAdd_sb().
</p></li><li><p>
clientdbEstablished_sb()&mdash;global function that counts the number
of client requests and periodically flushes the appropriate record
into the file, disconnects the client when the limit is exceeded and
adds the new record when needed by calling the function clientdbAdd_sb().
</p></li><li><p>
clientdbFreeMemory_sb()&mdash;global function that deletes the table
and releases the allocated memory.
</p></li><li><p>
clientdbAdd_sb()&mdash;local function that is called by the function
clientdbUpdate_sb() and adds the record into the table and schedules
the garbage records collecting procedure.
</p></li><li><p>
clientdbFlushItem_sb()&mdash;local function that is called by the
functions clientdbEstablished_sb() and clientdbFreeItem_sb() and flushes
the particular record into the file.
</p></li><li><p>
clientdbFreeItem_sb()&mdash;local function that is called by the function
clientdbFreeMemory_sb() and removes the single record from the table.
</p></li><li><p>
clientdbSheduledGC_sb(), clientdbGC_sb() and
clientdbStartGC_sb()&mdash;local functions that implement the garbage records collecting
procedure.
</p></li></ul></div><p>
The client database initialization and release are
implemented similarly to the original table in the
file src/main.c. The main peculiarity of our code
is the calls of the functions clientdbUpdate_sb() and
clientdbEstablished_sb() in the client-side routines
in the file src/client_side.c:
</p><div class="itemizedlist"><ul type="disc"><li><p>
call of the function clientdbUpdate_sb() from the auxiliary function
clientWriteComplete(), which is responsible for sending the portions of
data to the client.
</p></li><li><p>
call of the function clientdbEstablished_sb() from the function
clientReadRequest(), which processes the client request.
</p></li></ul></div><p>
Listing 1 shows the corresponding fragments of the functions
clientWriteComplete() and clientReadRequest() from the file
src/client_side.c.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2088580.0x257ae28"></a></h2></div></div><div class="sidebar"><p class="title"><b>Listing 1. Fragments of the Functions clientWriteComplete() and
clientReadRequest() from the src/client_side.c File
</b></p><pre     class="programlisting">

static void
clientWriteComplete(int fd,
                    char *bufnotused,
                    size_t size,
                    int errflag,
                    void *data)
{
    clientHttpRequest *http = data;

...

    if (size &gt; 0)
    {
	kb_incr(&amp;statCounter.client_http.kbytes_out,
                size);
/*-Here comes the SB section----------------------*/
#ifdef SB_INCLUDE
    if (http-&gt;request-&gt;auth_user_request)
    {
	if ( authenticateUserRequestUsername(
                http-&gt;request-&gt;auth_user_request) )
	    if (!clientdbUpdate_sb(
      authenticateUserRequestUsername(
          http-&gt;request-&gt;auth_user_request),
          size) )
            {
		comm_close(fd);
		return;
	    }
    }
#endif
/*------------------------------------------------*/
	if (isTcpHit(http-&gt;log_type))
	    kb_incr(
      &amp;statCounter.client_http.hit_kbytes_out,
      size);

    }

...

}

...

static void
clientReadRequest(int fd, void *data)
{
    ConnStateData *conn = data;
    int parser_return_code = 0;
    request_t *request = NULL;
    int size;
    void *p;
    method_t method;
    clientHttpRequest *http = NULL;
    clientHttpRequest **H = NULL;
    char *prefix = NULL;
    ErrorState *err = NULL;
    fde *F = &amp;fd_table[fd];
    int len = conn-&gt;in.size - conn-&gt;in.offset - 1;

...

    /* Process request body if any */
    if (conn-&gt;in.offset &gt; 0 &amp;&amp;
        conn-&gt;body.callback != NULL)
    {
	clientProcessBody(conn);
    }
    /* Process next request */
    while (conn-&gt;in.offset &gt; 0 &amp;&amp;
           conn-&gt;body.size_left == 0)
    {
	int nrequests;
	size_t req_line_sz;

...

	/* Process request */
	http = parseHttpRequest(conn,
	    &amp;method,
	    &amp;parser_return_code,
	    &amp;prefix,
	    &amp;req_line_sz);
	if (!http)
	    safe_free(prefix);
	if (http) {

...

	    if (request-&gt;method == METHOD_CONNECT)
            {
		/* Stop reading requests... */
		commSetSelect(fd,
                              COMM_SELECT_READ,
                              NULL,
                              NULL,
                              0);
		clientAccessCheck(http);
/*-Here comes the SB section----------------------*/
#ifdef SB_INCLUDE
	        if(http-&gt;request-&gt;auth_user_request)
                {
		    if (
      authenticateUserRequestUsername(
          http-&gt;request-&gt;auth_user_request
      )!=NULL)
                    {
		        if(!clientdbCount_sb(
          authenticateUserRequestUsername(
              http-&gt;request-&gt;auth_user_request)))
                        {
			    comm_close(fd);
			    return;
			}
                    }
                }
#endif
/*------------------------------------------------*/
		break;
	    } else {
		clientAccessCheck(http);
/*-Here comes the SB section----------------------*/
#ifdef SB_INCLUDE
		if(http-&gt;request-&gt;auth_user_request)
                {
	    	    if (
      authenticateUserRequestUsername(
           http-&gt;request-&gt;auth_user_request
      )!=NULL)
                    {
			if(!clientdbCount_sb(
          authenticateUserRequestUsername(
              http-&gt;request-&gt;auth_user_request)))
                        {
			    comm_close(fd);
			    return;
			}
                    }
		}
#endif
/*------------------------------------------------*/

/* while offset &gt; 0 &amp;&amp; body.size_left == 0 */
		continue;
	    }
	} else if (parser_return_code == 0) {

...

/* while offset &gt; 0 &amp;&amp; conn-&gt;body.size_left == 0 */
    }

...

}

</pre></div><p>
Thus, the mechanism is quite simple. Figure 2
shows the simple client request processing
diagram from the point of view of our system. Each
client request contains the user authentication
information, including the user name. The function
clientdbUpdate_sb() searches for the ClientInfo_sb
record, which corresponds to the user name obtained
from the request. In the case of the absence of such
a record, it adds the new ClientInfo_sb record using the
information from the authority files. If users
exceed their limit, they are disconnected
immediately with the function comm_close(). The call of the
function clientdbEstablished_sb() is also used to
control the number of client requests and to save
current user information into the authority files
every SB_MAX_COUNT requests. The authority files are
called passwd and group analogously to the UNIX
files. The passwd file contains the user
information, and the group file contains the user
group information. Here are the descriptive samples:

<pre     class="programlisting">

`passwd':
#&lt;name&gt;:&lt;full name&gt;:&lt;group id&gt;:
#&lt;current limit value&gt;:&lt;last limit update time&gt;

tagir:Tagir Bakirov:1:6567561:12346237467

`group':
#&lt;name&gt;:&lt;full name&gt;:&lt;group id&gt;:
#&lt;group limit value&gt;:&lt;group limit type&gt;

users:BSPU users:1:10000000:D

</pre>
</p><div       class="mediaobject"><a href="8002f2.large.jpg"><img src="8002f2.jpg"></a><div class="caption"><p>
Figure 2. Simple Client Request Processing Diagram
</p></div></div><p>
There are three types of limit: D (daily), W (weekly) and M (monthly). The passwd
and group filenames and paths can be set in the Squid configuration
file squid.conf. This was implemented by modifying the structure of the
squid.conf template file and the structure of the Squid configuration
structure.
</p><p>
Here are the other slight changes in the Squid source code:
</p><div class="itemizedlist"><ul type="disc"><li><p>
Global functions definition in the file src/protos.h.
</p></li><li><p>
ClientInfo_sb structure type definition in the file src/typedefs.h.
</p></li><li><p>
ClientInfo_sb structure identifier declaration in the structure list
in the file src/enums.h.
</p></li><li><p>
ClientInfo_sb structure initialization in the memory allocation
procedure memInit() in the file src/mem.c.
</p></li></ul></div><p>
All of these changes are made analogously to the
code, maintaining the original client per-IP database. We hope
everything was done right.
</p><p>
Looking through our modifications, you may have noticed that all the code
is put into the conditional compilation blocks (#ifdef SB_INCLUDE
... #endif). The variable SB_INCLUDE is declared when the parameter
--enable-sbclientdb is included into the command line of the Squid configure
script. This was made by recompiling the configure.in script with
autoconf after putting in some slight modifications.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2088580.0x257b6c0"></a>
Conclusion</h2></div></div><p>
In this article, we considered the state of the art in the Internet access
control problem. We proposed several methods for its solution and considered
the variant based on the Squid proxy server, which has been implemented
in the LAN of BSPU. Our solution is not the panacea and possibly has
several drawbacks, but it is rather simple, flexible and absolutely free.
</p><p>
We also should say that our Web-programmer, Elmir Mirdiev, is now finishing
the implementation of a small PHP-based Web site designed for system
management and user statistics reporting. The user-detailed statistics
are generated from the Squid logs using the Sarg system.
</p><p>
Other information can be obtained from the source code of the
system. You can get the whole modified source code of Squid version
2.5STABLE7 tarball on our site or only the patch file. We
will be glad to answer your questions by e-mail.
</p><p><span   class="bold"><b>Resources for this article:</b></span>
<a href="../134/8205.html" target="_self">/article/8205</a>.
</p></div></div>
<div class="authorblurb"><p>
Tagir K. Bakirov (<a href="mailto:batk@mail.ru">batk@mail.ru</a>) is a system
administrator at BSPU and a first-year
postgraduate student of Ufa State Aviation Technical University. His main
interests are information security, multi-agent systems and other
IT. His hobbies include sporting activities, books, music and foreign
languages.
</p><p>
Vladimir G. Kozlov (<a href="mailto:admin@bspu.ru">admin@bspu.ru</a>), doctor of pedagogical science,
assistant professor, is the senior system administrator and lecturer
of several IT disciplines at BSPU. His main interests are *NIX networking,
IT and electronics. His hobbies include ham radio (UA9WBZ), family
and sports.
</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../134/toc134.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>