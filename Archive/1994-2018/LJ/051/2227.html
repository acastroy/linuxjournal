<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>lex and yacc: Tools Worth Knowing</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;    Today, computers can talk and they can listen&mdash;but how often&#10;    do they do what you want?&#10;    "><meta name="keywords" content="lex, yacc, command"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x1d17580.0x1e0eab0"></a>lex and yacc: Tools Worth Knowing</h1></div><div><div class="author"><h3 class="author">Dean Allen Provins</h3></div><div class="issuemoyr">Issue #51, July 1998</div></div><div><p>
    Today, computers can talk and they can listen&mdash;but how often
    do they do what you want?
    </p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d17580.0x1e0f558"></a></h2></div></div><p>This article is about how Linux was used
to program a Sun machine to manipulate well-log recordings to
support finding oil and gas exploration in Western Canada. It will
describe the problem, provide enough background to make the problem
understandable, and then describe how the two fascinating UNIX
utilities <span   class="bold"><b>lex</b></span> and
<span   class="bold"><b>yacc</b></span> were used to let a user
describe exactly what he wanted to satisfy his particular need.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d17580.0x1e0f710"></a>Some Background</h2></div></div><p>In the fall of 1993, I had been recently downsized and was
approached by a former colleague for assistance. He, and another
former colleague, both of whom were still with my last employer,
were what is known in the industry as well-log analysts.</p><p>To understand what a log analyst is requires a little
knowledge of oil and gas exploration methods. Energy companies, as
they like to be known, employ several different categories of
professionals to assist them in finding salable quantities of
hydrocarbons. Chief among these are the geologists and
geophysicists (of which I am one) who study the recordings made in
bore holes, or process and examine seismic recordings to identify
what are popularly known as &ldquo;plays&rdquo; or &ldquo;anomalies&rdquo;.</p><p>Bore holes are simply the holes left when a drill rig moves
off the drilling platform. Generally, these holes are logged by
service companies who lower instruments called
<span   class="emphasis"><em>tools</em></span> into the hole, and who then record on
magnetic tape the readings made by those instruments.</p><p>There are many different types of tools, including sonic
(which measures the time needed for a pulse of sound energy to
travel through the rock wall from one end of the tool to the
other), density (a continuous recording of the rock wall density),
and gamma ray (a measure of gamma radiation intensity in the rock).
These are just a few of the types of measurements that are made,
recorded and called <span   class="emphasis"><em>logs</em></span>.</p><p>The various logs are examined by geologists to gain an
understanding of what was happening when the rocks forming the bore
hole were laid down, and what has happened to them subsequently as
shallower rocks were created above them.</p><p>Geophysicists are more inclined to study seismic recordings
which in essence are indirect measurements of the properties of the
rocks forming the subsurface. Geophysics and Linux will not be
discussed here, but you may find Sid Hellman's &ldquo;Efficient, User
Friendly Seismology&rdquo;, <i  >Linux Journal</i>, August
1995, Issue 16 of interest.</p><p>While seismic recordings provide much greater volumes of
interpretable data over large areas, well logs are definitive
measurements made at single locations, sometimes close together,
and sometimes not. Geologists often correlate adjacent well logs to
create cross sections of the subsurface, much like seismic
recordings would provide. Detailed interpretation of individual
logs, however, is often left to the log specialists.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d17580.0x1e0fb30"></a>The Problem</h2></div></div><p>My two acquaintances were log specialists who wanted an
additional tool to assist them in the processing and interpretation
of individual or combinations of logs. Specifically, they wanted to
tell the computer to perform arithmetic operations on individual or
some algebraic combination of logs.</p><p>For example, they might need to scale a specific log by an
arbitrary amount, say 1.73. In another case, they might want to
divide one log by another, and then add the result to a third, all
before adding a constant and then raising the resulting values to
some arbitrary power.</p><p>Keeping in mind that logs are composed of individual sample
values taken as frequently as every few inches (or centimeters as
they are here in Canada and many other places in the world), these
example requests would mean a reasonable amount of computation,
multiplying every sample of thousands of meters of recorded log
values by 1.73, in the first example. The simple scaling problem
isn't particularly difficult, but identifying the desired log could
be.</p><p>The energy company for which my acquaintances worked was
using a simple filing method for all the log curves (a curve
corresponds to all the recorded samples for one tool in one bore
hole) wherein each curve was identified by a name. To this was
added some additional information on units and so on, plus all the
samples for all the curves for the well. All the data were stored
as ASCII. (The file format is known as Log ASCII Standard format,
or LAS version 2.0, and although the names for curves were
generally the same from well to well, that was not
guaranteed.)</p><p>As a result, more complicated combinations of curves required
a fairly sophisticated and robust mechanism for arbitrary name
recognition, while the desired algebraic operation was being
described. Given such an interesting challenge, I recognized an
opportunity to put some relatively little-used tools to work:
<span   class="bold"><b>lex</b></span> and
<span   class="bold"><b>yacc</b></span>.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d17580.0x1e0fe48"></a>The Tools</h2></div></div><p>The program <span   class="bold"><b>lex</b></span> is a lexical
analyzer. Lexical analysis is the recognition of words in a
language. As used in this particular application, lex, or more
specifically <span   class="bold"><b>flex</b></span>, is used to
recognize characters forming the names of log curves, arithmetic
operators and algebraic groupings.</p><p><span   class="bold"><b>flex</b></span> is a particular example
of the lexical analysis programs available for UNIX systems and is
the implementation delivered with Linux distributions. The original
implementation was done by Mike Lesk and Eric Schmidt at Bell
Laboratories and is documented in the book <span   class="emphasis"><em>lex &amp;
yacc</em></span> by John R. Levine, Tony Mason &amp; Doug Brown,
O'Reilly &amp; Associates, Inc., 1992.</p><p><span   class="bold"><b>yacc</b></span> is a language parser.
It accepts word items and, given a list of rules describing how
these items form larger entities, deduces which items or
combinations of items satisfy a rule. This can also be thought of
as grammatical analysis. Once a rule is satisfied, a programmer's
code is applied to the result.</p><p>In the case of English, the words in a sentence can be
assigned grammatical types such as noun, verb, adjective and so on.
Particular combinations of words form more complex units and these
in turn can be described as complete sentences.</p><p>For example, the sentence &ldquo;The lazy dog lay in the sun,&rdquo; is
composed of an article &ldquo;the&rdquo;, a preposition &ldquo;in&rdquo;, adjective
&ldquo;lazy&rdquo;, nouns &ldquo;dog, sun&rdquo; and a verb &ldquo;lay&rdquo;. Combinations of
these grammatical items form more complex entities such as noun
phrases &ldquo;The lazy dog&rdquo; and &ldquo;in the sun&rdquo;. The first noun phrase
is the subject of the sentence, and the second, in combination with
the verb, forms the predicate. Together they form a complete
sentence.</p><p>It is possible to form parsers for the English language,
although given English's many idiosyncrasies,
<span   class="bold"><b>yacc</b></span> may prove to be inadequate
for the task. It may also be that the yacc programmer may become
exhausted in trying to describe all the nuances of the
language.</p><p><span   class="bold"><b>yacc</b></span> was originally
developed to provide a mechanism to develop compilers, but it could
just as easily be used to create interpreters. For example, BASIC
is often an interpreted language and could easily be described by a
yacc grammar. Once yacc <span   class="emphasis"><em>understood</em></span> a
particular line of BASIC code, it could cause the execution of the
equivalent instructions in the native language of the host
computer.</p><p>Some Linux distributions provide a choice of yacc programs.
One can install either (or both) Berkeley yacc or the GNU
<span   class="bold"><b>bison</b></span> program. You'll probably
find them in /usr/bin. They are quite similar; bison was originally
derived from yacc, although there has been some divergence over the
years.</p><p>The combination of lex, yacc and some programmer's C code
provides a complete means to interpret and act upon a user's
wishes. The lex program uses its regular expression interpretation
capability to recognize strings of characters as words or tokens.
(The term &ldquo;words&rdquo; is used loosely to describe any recognized
string of characters.) Once a token is identified, it is passed to
yacc where the various rules are applied until some combination of
tokens form a recognizable structure to which yacc applies some
pre-programmed C code.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d17580.0x1e10528"></a>How The Tools Are Used</h2></div></div><p>As indicated, lex uses regular expressions to recognize
strings of characters as items of interest. Regular expressions are
composed of special characters which describe acceptable
combinations of characters.</p><p>For example, regular expressions often use the character .
(period) to indicate that <span   class="emphasis"><em>any</em></span> character except
a newline (\n) is acceptable.</p><p>Similarly, the characters [ and ] (square brackets) are used
to indicate acceptance of any of the characters enclosed within
them or within the range of characters described between them. For
example, the expression <b  >[abc]</b> says to accept
<span   class="emphasis"><em>any</em></span> of the characters a, b or c; the
expression <b  >[a-c]</b> says the same thing. A more
complicated example might be <b  >[a-zA-Z0-9]</b> which
says to accept any alphanumeric character.</p><p>For a complete description of lex regular expression syntax,
see <span   class="emphasis"><em>lex &amp; yacc</em></span> by Levine, Mason and Brown
(O'Reilly, 1992).</p><p>Once a regular expression matches the text stream being
interpreted by lex, code created by the programmer is executed.
When used with yacc, this code generally amounts to passing an
indication of what was just recognized to yacc for further
processing. The indication is a token that yacc knows about, and in
fact, these are defined in the yacc portion of the analyzer/parser
program so that they are common to both lex and yacc.</p><p>Also as indicated, yacc uses a grammar description to decode
the meaning of the tokens that lex passes to it. As tokens are
passed to yacc, it applies its rules until a single token, or some
sequence of tokens, becomes a recognizable structure.</p><p>Before a programmer's C code is executed, though, yacc may
require several structures or token-structure combinations to be
recognized. For example, using our sample sentence, our rules might
look like the following:</p><pre     class="programlisting">
sentence  :  subject + predicate
{...execute some C code...}
subject       :  noun
              |  noun_phrase
predicate     :  verb + noun_phrase
noun_phrase   :  preposition + adjective + noun
              |  adjective + noun
</pre><p>The first rule says that a sentence is made up of two parts:
a subject followed by a predicate. If that rule is satisfied, then
the C code between the curly brackets will be executed. To satisfy
the first rule, yacc has to recognize both a subject and a
predicate. The subsequent rules help yacc to do just that.
</p><p>For example, the second rule says that a subject is
recognized when either a noun or a noun phrase is recognized. A
noun is the smallest unit that yacc deals with, and in the yacc
grammar, a noun is a token that yacc will want to have lex
recognize. Thus, somewhere in the yacc program, a token will be
defined (probably called NOUN) that lex and yacc will use to
communicate the fact that a noun has been interpreted. How this is
done we will see shortly.</p><p>Notice that a noun phrase is also used to create the
predicate. If a verb is recognized and it is followed by a noun
phrase, the predicate is identified. If only the noun phrase is
identified, then the subject has been identified.</p><p>The example cited is not in yacc syntax, but is meant to
provide understanding. Very detailed examples may be found in the
references.</p><p>You may be wondering how the yacc parser actually works.
<span   class="bold"><b>yacc</b></span> works as a finite-state
machine, and it has a stack (think of this as a memory of what has
been seen, as it tries to deduce what the incoming stream of tokens
represents).</p><p>A finite-state machine records its current condition as each
recognizable item is interpreted. For example, as a noun phrase is
being interpreted, it moves from state 3 when it receives a
preposition to state 4 when the adjective is interpreted and
finally to state 5 when the noun is recognized. When the entire
phrase has been recognized, it switches to another state, perhaps
37, to note that fact. Please do not attach any particular meaning
to the numbers used in this example. They have been chosen
arbitrarily to demonstrate how yacc progresses as it interprets the
tokens received from lex. You should conclude only that to reach
state 5 (noun phrase), yacc must progress through several preceding
states, each of which might lead to another final state, depending
on the grammar yacc is using.</p><p>In other words, given its current state, yacc requests from
lex the next token (if it needs it) and places onto the stack its
new state. In doing so, it may push the new state onto the stack
(as when interpreting the noun phrase), or pop the old state off
the stack, replacing it with a new state (as when the noun phrase
is completely recognized). These actions are called &ldquo;shift&rdquo; and
&ldquo;reduce&rdquo; and describe pushing and popping states to and from the
stack.</p><p>When the sentence is finally recognized, yacc accepts it and
returns to the calling program (the main program which invoked yacc
and indirectly lex). For a complete description of how a yacc
parser works, see <span   class="emphasis"><em>Inside Xenix</em></span> by Christopher
Morgan, Howard W. Sams and Co., 1986. This reference describes yacc
grammars and how yacc parses its input in exquisite detail.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d17580.0x1e076a8"></a>Basic Coding of lex and yacc Programs</h2></div></div><p>Both tools are coded in a similar manner. There are three
sections in each program: declarations, rules and user routines.
Each is separated by a line containing only the two characters
<b  >%%</b>.</p><p>For yacc, the declarations section contains the tokens it can
use while parsing the input. Each has a unique value greater than
256, and the set of tokens is introduced via
<b  >%token</b> at the beginning of the line.
<span   class="bold"><b>lex</b></span> can use the declarations
section to define aliases for items that it must recognize while
looking for tokens to pass to yacc.</p><p>For example, lex needs to know about white space which, while
not used in identifying tokens, must be accounted for in some way.
Similarly, mathematical symbols such as + or = must be recognized.
These are needed in the interpretation of the algebraic statement
coded by the user.</p><p>Within the rules section, yacc holds its parsing
intelligence. This is the section that contains the grammar rules
referred to in the English sentence example earlier. In fact, the
coding used earlier is typical of a yacc grammar: items to be
recognized are separated from the means to recognize them by a
colon (:), and alternative means of recognition are separated from
each other via a pipe (|) symbol.</p><p><span   class="bold"><b>lex</b></span> uses the rules section
to contain the regular expressions that allow it to identify tokens
to pass to yacc. These expressions may be the aliases from the
declaration section, regular expressions, or some
combination.</p><p>The last section contains C code which may be invoked as each
of the tools processes its input.</p><p>One requirement is that the yacc tokens be known to the lex
program. This is accomplished by including the following
statement:</p><pre     class="programlisting">
#include "y.tab.h"
</pre><p>in the lex declarations section and creating it when
compiling the yacc program code.
</p><p>Compilation is accomplished in the following way:</p><pre     class="programlisting">
yacc -d yacc.file -create 'y.tab.c and y.tab.h'
flex flex.file -create 'lex.yy.c'
</pre><p>The <b  >-d</b> option on yacc's command line
creates the y.tab.h file needed by lex.yy.c.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d17580.0x1e07d30"></a>How lex and yacc were employed in Log
Analysis</h2></div></div><p>To successfully interpret the user's desired process, the
program needs to know which well logs were available for
processing. This information is available in the ASCII file
selected by the user. This text file contains a one-to-one
correspondence between curve description and data values. A very
small subset of a typical file is shown in Listing 1.</p><p><a href="2227l1.html" target="_self">Listing 1</a></p><p>As can be seen, there are several sections including well
information (includes some hole parameters), curve information
(notes which curves are in the file) and &ldquo;A&rdquo; which holds the
recorded data values. Each is introduced with a tilde (~). Because
the format of the file is fixed by convention, these are easily
parsed, and needed values are stored for subsequent
processing.</p><p>As written for the client, the program is a Motif
application. The user selected the file to be processed; it was
read in its entirety and numeric text items were converted to
double-precision values.</p><p>Besides allowing file and curve merging and editing, there is
a menu item for curve processing. Upon selecting this menu item, a
dialog box is presented containing a list of available curves and
arithmetic operations. The user selects curve names, numeric
constants and operations which in turn are displayed as an
algebraic operation on a text input line. When satisfied with the
mathematical operation, the user clicks <b  >OK</b> and
the lex and yacc magic occurs. The result is stored as a separate
curve and can be included in subsequent operations.</p><p><span   class="bold"><b>lex</b></span> processed the incoming
algebraic statement with the code shown in Listing 2.</p><p><a href="2227l2.html" target="_self">Listing 2</a></p><p>Between lines 1 and 16 are declarations to be used in the
program generated by lex. In particular, you will notice the
inclusion of the header file y.tab.h which contains the following
definitions:</p><pre     class="programlisting">
#define INTEGER 257
#define FLOAT 258
#define DOUBLE 259
#define NUMBER 260
#define VARIABLE 261
#define EQUAL 262
#define LPAREN 263
#define RPAREN 264
#define PLUS 265
#define MINUS 266
#define TIMES 267
#define DIVIDE 268
#define RAISE 269
#define LHS 270
</pre><p>These definitions are used by both lex and yacc to describe
the items yacc expects to receive from lex. They are generated by
statements 73 to 77 of the yacc source which will be examined
shortly.
</p><p>From lines 17 to 31 of the lex listing are declarations which
amount to aliases for common items that we wish lex to recognize.
For example, we declare DIGIT to be any single numeric between 0
and 9 on line 21. Doing this allows us to declare INT (an integer)
to be one or more DIGIT's.</p><p>Lines 33 to 90 contain the rules by which lex interprets
incoming text items. For example, on line 34 we recognize an equal
sign (=) and return the token EQUAL to the caller. In y.tab.h,
EQUAL is defined to be 262.</p><p>As you can see, the lex rules simply recognize text items and
then advise the caller what was seen in the input stream.</p><p><a href="2227l3.html" target="_self">Listing 3</a></p><p><span   class="bold"><b>yacc</b></span> interprets the token
stream passed to it by lex with the following code, only a subset
of which is shown in Listing 3. The code for the yacc routine (with
the calling subroutine
<span   class="bold"><b>do_arithmetic</b></span> and its accessory
functions) was in excess of 900 lines. For those interested, it is
available for your perusal from SSC's public FTP site. Listing 3 is
a sample indicating what needed to be done.</p><p>Like the lex routine, yacc begins with lines to be included
in the output code. Programs written for graphical user interfaces
sit in a loop waiting for the user to click on something. When the
user's needs are so indicated, the GUI-based program calls a
function to perform the required action. These &ldquo;called functions&rdquo;
are popularly called <span   class="emphasis"><em>callbacks</em></span>. In this
program, one of the callbacks was
<span   class="bold"><b>do_arithmetic</b></span>, which in turn
called the yacc routine, which in its turn called the lex
routine.</p><p>In Listing 3, do_arithmetic is described in the first few
lines, and a portion of the code may be seen in lines 428 to 532.
They are shown only to give some indication of what was being
accomplished.</p><p><span   class="bold"><b>yacc</b></span> does the work with its
rules section beginning at line 79, and ending at line 426.
Although too long to be included completely, you can see that an
<span   class="emphasis"><em>equation</em></span> is defined to be something called an
<b  >lhs</b> (left hand side) <b  >EQUAL
rhs</b> (right hand side) at line 80. Looking down the
listing, you will see that an equation may also be described by an
<b  >expr</b> (expression). When either of these are
encountered, yacc pops a key from an internal stack created by a
function called <span   class="bold"><b>push</b></span> (see near
line 557) and then causes a log curve to be returned to the caller
by calling another function called
<span   class="bold"><b>get_curve</b></span> (not shown here, but
included with the yacc and lex code).</p><p>Between lines 118 and 139, you can see how some of the tokens
yacc expects are processed when recognized. The complete listing
has many more.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d17580.0x1e089e8"></a>Results</h2></div></div><p>The lex, yacc and supporting code was successfully employed
to allow the log analysts to process various log curves. To have
written the C code to accomplish the lexical analysis and parsing
logic would have taken much longer than the four weeks allowed. As
it turned out, this code was much easier to create and debug than
it was to introduce into the final Motif application, even though
it was written as a callback.</p><p>In fact, the number of lines of lex (152) and yacc (953) code
were far fewer than the number of lines generated by the two
(2765). Of course, one could take the time to write much tighter
code than these general purpose tools deliver.</p><p>Nevertheless, should you be faced with a similar problem, I
strongly recommend using lex and yacc. They are powerful, reliable
tools worth knowing.</p><p>All listings referred to in this article are available by
anonymous download in the file
ftp://ftp.linuxjournal.com/pub/lj/listings/issue51/2227.tgz.</p></div></div>
<div class="authorblurb"><p>
        <div       class="mediaobject"><img src="2227aa.jpg"></div>
        <span   class="bold"><b>Dean Provins</b></span>
        (<a href="mailto:provinsd@cuug.ab.ca">provinsd@cuug.ab.ca</a>)
        is a professional geophysicist and
        licensed amateur radio operator (VE6CTA) in Calgary, Alberta. He
        has used UNIX systems since the mid-1980s and Linux since January,
        1993. Dean uses Linux as a development system for geophysical
        software, and as a text processing system for a newsletter and
        other articles. He is currently enrolled as a graduate student in
        Geomatics Engineering at the University of Calgary
      </p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../051/toc051.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>