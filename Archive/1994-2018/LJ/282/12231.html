<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
At the Forge
</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;Threads can provide concurrency, even if they're not truly parallel.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x231e580.0x2415ac0"></a>
At the Forge
</h1></div><div><h3 class="subtitle"><i>
Threading in Python
</i></h3></div><div><div class="author"><h3 class="author">
Reuven
 M. 
Lerner
</h3></div><div class="issuemoyr">Issue #282, October 2017</div></div><div><p>
Threads can provide concurrency, even if they're not truly parallel.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x231e580.0x2416408"></a></h2></div></div><p>
In my last article, I took a short tour through the ways you can add
concurrency to your programs. In this article, I focus on one of those forms
that
has a reputation for being particularly frustrating for many
developers: threading. I explore the ways you can use threads in
Python and the limitations the language puts upon you when doing so.
</p><p>
The basic idea behind threading is a simple one: just as the computer can run
more than one process at a time, so too can your process run more than one
thread at a time. When you want your program to do something in the background,
you can launch a new thread. The main thread continues to run in the
foreground, allowing the program to do two (or more) things at once.
</p><p>
What's the difference between launching a new process and a new thread? A new
process is completely independent of your existing process, giving you more
stability (in that the processes cannot affect or corrupt one another) but
also less flexibility (in that data cannot easily flow from one thread to
another). Because multiple threads within a process share data, they can work
with one another more closely and easily.
</p><p>
For example, let's say you want to retrieve all of the data from a variety
of websites. My preferred Python package for retrieving data from the web is
the &ldquo;requests&rdquo; package, available from PyPI. Thus, I can use a
<tt  >for</tt> loop, as
follows:

<pre     class="programlisting">
length = {}

for one_url in urls:
    response = requests.get(one_url)
    length[one_url] = len(response.content)

for key, value in length.items():
    print("{0:30}: {1:8,}".format(key, value))
</pre>
</p><p>
How does this program work? It goes through a list of URLs (as strings), one
by
one, calculating the length of the content and then storing that
content inside a dictionary called <tt  >length</tt>. The keys in
<tt  >length</tt>
are URLs, and the values are the lengths of the requested URL content.
</p><p>
So far, so good; I've turned this into a complete program
(retrieve1.py), which is shown in Listing 1. I put nine URLs into a text
file called urls.txt (Listing 2), and then timed how long
retrieving each of them took. On my computer, the total time was
about 15 seconds, although there was clearly some variation in the
timing.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x231e580.0x2416930"></a></h2></div></div><div class="sidebar"><p class="title"><b>Listing 1. retrieve1.py</b></p><pre     class="programlisting">
#!/usr/bin/env python3

import requests
import time

urls = [one_line.strip()
        for one_line in open('urls.txt')]

length = {}

start_time = time.time()

for one_url in urls:
    response = requests.get(one_url)
    length[one_url] = len(response.content)

for key, value in length.items():
    print("{0:30}: {1:8,}".format(key, value))


end_time = time.time()

total_time = end_time - start_time

print("\nTotal time: {0:.3} seconds".format(total_time))
</pre></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x231e580.0x2416b40"></a></h2></div></div><div class="sidebar"><p class="title"><b>Listing 2. urls.txt</b></p><pre     class="programlisting">
http://lerner.co.il
http://LinuxJournal.com
http://en.wikipedia.org
http://news.ycombinator.com
http://NYTimes.com
http://Facebook.com
http://WashingtonPost.com
http://Haaretz.co.il
http://thetech.com
</pre></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x231e580.0x2416d50"></a>
Improving the Timing with Threads</h2></div></div><p>
How can I improve the timing? Well, Python provides threading. Many
people think of Python's threads as fatally flawed, because only one
thread actually can execute at a time, thanks to the GIL (global
interpreter lock). This is true if you're running a program that is
performing serious calculations, and in which you really want the
system to be using multiple CPUs in parallel.
</p><p>
However, I have a different sort of use case here. I'm interested
in retrieving data from different websites. Python knows that I/O
can take a long time, and so whenever a Python thread engages in I/O
(that is, the screen, disk or network), it gives up control and hands
use of the GIL over to a different thread.
</p><p>
In the case of my &ldquo;retrieve&rdquo; program, this is perfect. I can spawn a
separate thread to retrieve each of the URLs in the array. I then
can wait for the URLs to be retrieved in parallel, checking in with each
of the threads one at a time. In this way, I probably can save time.
</p><p>
Let's start with the core of my rewritten program. I'll want to
implement the retrieval as a function, and then invoke that function
along with one argument&mdash;the URL I want to retrieve. I then
can invoke that function by creating a new instance of
<tt  >threading.Thread</tt>,
telling the new instance not only which function I want to run in a
new thread, but also which argument(s) I want to pass. This is how
that code will look:

<pre     class="programlisting">
for one_url in urls:
    t = threading.Thread(target=get_length, args=(one_url,))
    t.start()
</pre>
</p><p>
But wait. How will the <tt  >get_length</tt> function communicate the content
length to the rest of the program? In a threaded
program, you really
must not have individual threads modify built-in data structures,
such as a list. This is because such data structures aren't
thread-safe, and doing something such as an &ldquo;append&rdquo; from one thread might
cause all sorts of problems.
</p><p>
However, you can use a &ldquo;queue&rdquo; data structure, which is thread-safe,
and thus guarantees a form of communication. The function can put
its results on the queue, and then, when all of the threads have
completed their run, you can read those results from the queue.
</p><p>
Here, then, is how the function might look:

<pre     class="programlisting">
from queue import Queue

queue = Queue()

def get_length(one_url):
    response = requests.get(one_url)
    queue.put((one_url, len(response.content)))
</pre>
</p><p>
As you can see, the function retrieves the content of
<tt  >one_url</tt> and
then places the URL itself, as well as the length of the content, in a
tuple. That tuple is then placed in the queue.
</p><p>
It's a nice little program. The main thread spawns a new
thread, each of which runs <tt  >get_length</tt>. In
<tt  >get_length</tt>, the
information gets stuck on the queue.
</p><p>
The thing is, now it needs to retrieve things from the queue. But if you
do this just after launching the threads, you run the risk of reading
from the queue before the threads have completed. So, you need to
&ldquo;join&rdquo; the threads, which means to wait until they have finished. Once
the threads have all been joined, you can read all of their information
from the queue.
</p><p>
There are a few different ways to join the threads. An
easy one is to create a list where you will store the threads and
then append each new thread object to that list as you create it:

<pre     class="programlisting">
threads = [ ]

for one_url in urls:
    t = threading.Thread(target=get_length, args=(one_url,))
    threads.append(t)
    t.start()
</pre>
</p><p>
You then can iterate over each of the thread objects, joining them:

<pre     class="programlisting">
for one_thread in threads:
    one_thread.join()
</pre>
</p><p>
Note that when you call <tt  >one_thread.join()</tt> in this way, the call
blocks. Perhaps that's not the most efficient way to do things, but in
my experiments, it still took about one second&mdash;15 times faster&mdash;to
retrieve all of the URLs.
</p><p>
In other words, Python threads are routinely seen as terrible and
useless. But in this case, you can see that they allowed me to parallelize
the program without too much trouble, having different sections
execute concurrently.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x231e580.0x24178a8"></a></h2></div></div><div class="sidebar"><p class="title"><b>Listing 3. retrieve2.py</b></p><pre     class="programlisting">
#!/usr/bin/env python3

import requests
import time
import threading
from queue import Queue

urls = [one_line.strip()
        for one_line in open('urls.txt')]

length = {}
queue = Queue()
start_time = time.time()
threads = [ ]

def get_length(one_url):
    response = requests.get(one_url)
    queue.put((one_url, len(response.content)))

# Launch our function in a thread
print("Launching")
for one_url in urls:
    t = threading.Thread(target=get_length, args=(one_url,))
    threads.append(t)
    t.start()

# Joining all
print("Joining")
for one_thread in threads:
    one_thread.join()

# Retrieving + printing
print("Retrieving + printing")
while not queue.empty():
    one_url, length = queue.get()
    print("{0:30}: {1:8,}".format(one_url, length))

end_time = time.time()

total_time = end_time - start_time

print("\nTotal time: {0:.3} seconds".format(total_time))
</pre></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x231e580.0x2417ab8"></a>
Considerations</h2></div></div><p>
The good news is that this demonstrates how using threads can be
effective when you're doing numerous, time-intensive I/O actions.
This is especially good news if you're writing a server in Python that
uses threads; you can open up a new thread for each incoming request
and/or allocate each new request to an existing, pre-created thread.
Again, if the threads don't really need to execute in a truly parallel
fashion, you're fine.
</p><p>
But, what if your system receives a very large number of requests? In
such a case, your threads might not be able to keep up. This is
particularly true if the code being executed in each thread is CPU-intensive.
</p><p>
In such a case, you don't want to use threads. A popular option&mdash;indeed,
<span   class="emphasis"><em>the</em></span> popular option&mdash;is to use processes. In my next
article, I plan to look at
how such processes can work and interact.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x231e580.0x280ff70"></a></h2></div></div><div class="sidebar"><p class="title"><b></b></p><p>Send comments or feedback via <a href="http://www.linuxjournal.com/contact" target="_self">www.linuxjournal.com/contact</a> or to
<a href="mailto:info@linuxjournal.com">info@linuxjournal.com</a>.
</p></div></div></div>
<div class="authorblurb"><p>
Reuven M. Lerner, a longtime web developer, offers training and consulting
services in Python, Git, PostgreSQL and data science. He has written
two programming ebooks (<span   class="emphasis"><em>Practice Makes Python</em></span> and
<span   class="emphasis"><em>Practice Makes
Regexp</em></span>) and publishes a free weekly newsletter for programmers,
at
<a href="http://lerner.co.il/newsletter" target="_self">lerner.co.il/newsletter</a>. Reuven tweets at
@reuvenmlerner and
lives in Modi'in, Israel, with his wife and three children.

</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../282/toc282.html">Issue Table of Contents</a>
    <a class="link3" href="../282/12231.html">Article</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>