<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
At the Forge
</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;Which of these data points doesn't belong? Machine learning can tell you.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x1516580.0x160dac0"></a>
At the Forge
</h1></div><div><h3 class="subtitle"><i>
Novelty and Outlier Detection
</i></h3></div><div><div class="author"><h3 class="author">
Reuven
 M. 
Lerner
</h3></div><div class="issuemoyr">Issue #277, May 2017</div></div><div><p>
Which of these data points doesn't belong? Machine learning can tell you.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1516580.0x160e408"></a></h2></div></div><p>
In my the last few articles, I've looked at a number of ways 
machine learning can help make predictions. The basic idea is
that you create a model using existing data and then ask that model to
predict an outcome based on new data.
</p><p>
So, it's not surprising that one of the most amazing ways machine
learning is being applied is in predicting the future. Just a few days
before writing this piece, it was announced that machine learning
models actually might be able to predict earthquakes&mdash;a goal that
has eluded scientists for many years and that has the potential to
save thousands, and maybe even millions, of lives.
</p><p>
But as you've also seen, machine learning can be used to
&ldquo;cluster&rdquo; data&mdash;that is, to find patterns that humans either can't or won't see,
and to try to put the data into various &ldquo;clusters&rdquo;, or machine-driven
categories. By asking the computer to divide data into distinct
groups, you gain the opportunity to find and make use of previously
undetected patterns.
</p><p>
Just as clustering can be used to divide data into a number of
coherent groups, it also can be used to decide which data points
belong inside a group and which don't. In &ldquo;novelty
detection&rdquo;, you
have a data set that contains only good data, and you're trying to
determine whether new observations fit within the existing data
set. In &ldquo;outlier detection&rdquo;, the data may contain outliers,
which you
want to identify.
</p><p>
Where could such detection be useful? Consider just a few
questions you could answer with such a system:
</p><div class="itemizedlist"><ul type="disc"><li><p>
Are there an unusual amount of login attempts from a particular IP
address?
</p></li><li><p>
Are any customers buying more than the typical number of products
at a given hour?
</p></li><li><p>
Which homes are consuming above-average amounts of water during a
drought?
</p></li><li><p>
Which judges convict an unusual number of defendants?
</p></li><li><p>
Should a patient's blood tests be considered normal, or are there
outliers that require further checks and examinations?
</p></li></ul></div><p>
In all of those cases, you could set thresholds for minimum and maximum
values and then tell the computer to use those thresholds in
determining what's suspicious. But machine learning changes that
around, letting the computer figure out what is considered
&ldquo;normal&rdquo;
and then identify the anomalies, which humans then
can investigate. This allows people to concentrate their energies on
understanding whether the outliers are indeed problematic, rather than
on identifying them in the first place.
</p><p>
So in this article, I look at a number of ways you can try to
identify outliers using the tools and libraries that Python provides
for working with data: NumPy, Pandas and scikit-learn. Just which
technique and tools will be appropriate for your data depend on what
you're doing, but the basic theory and practice presented here should
at least provide you with some food for thought.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1516580.0x160eda8"></a>
Finding Anomalies</h2></div></div><p>
Humans are excellent at finding patterns, and they're also quite good at
finding things that don't fit a pattern. But, what sort of algorithm
can look at a group of data sets and figure out which is unlike the
others?
</p><p>
One simple way to do this is to set a cutoff, often done at one or two
standard deviations. For those of you without a background in
statistics (or who have forgotten what a &ldquo;standard deviation&rdquo; is),
it's a measurement of how spread out the data is. For example:

<pre     class="programlisting">
&gt;&gt;&gt; a = np.array([10,10,10,10,10,10,10])
&gt;&gt;&gt; print("std = {}, mean = {}".format(a.std(), a.mean()))

std = 0.0, mean = 10.0
</pre>
</p><p>
In the above example, I have a NumPy array containing seven instances
of the number ten. People often think of the mean as describing the data,
and it does, but it's only when combined with the standard deviation
that you can know how much the numbers differ from one another. In
this case, they're all identical, so the standard deviation is 0.
</p><p>
In this example, the mean remains the same, but the standard deviation is
quite different:

<pre     class="programlisting">
&gt;&gt;&gt; a = np.array([5,15,0,20,-5,25,10])
&gt;&gt;&gt; print("std = {}, mean = {}".format(a.std(), a.mean()))

std = 10.0, mean = 10.0
</pre>
</p><p>
Here, the mean has not changed, but the standard deviation
has. You can see, from just those two numbers, that although the numbers
remain centered around 10, they also are spread out quite a bit.
</p><p>
One simple way to detect unusual data is to look for all of the values
that lie outside of two standard deviations from the mean, which
accounts for about 95% of the data. (You can go further out if you
want; 99.73% of data points are within three standard deviations, and
99.994% are within four.) If you're looking for outliers in an
existing data set, you can do something like this:

<pre     class="programlisting">

&gt;&gt;&gt; a = np.array([-5,15,0,20,-5,25,1000])
&gt;&gt;&gt; print(a.std())

347.19282415231044

&gt;&gt;&gt; min_cutoff = a.mean() - a.std()*2
&gt;&gt;&gt; max_cutoff = a.mean() + a.std()*2

&gt;&gt;&gt; print(a[(a&lt;min_cutoff) | (a&gt;max_cutoff)])

array([1000])

</pre>
</p><p>
Sure enough, that found an outlier in the data.
</p><p>
It's even easier if you have a bunch of new data and want to determine
whether those values would fit inside or outside your existing data set:

<pre     class="programlisting">

&gt;&gt;&gt; new_data = np.array([-5000, -3000, -1000, -500, 20, 60, 500, 800,
&gt;&gt;&gt; 900])
&gt;&gt;&gt; print(new_data[(new_data&lt;min_cutoff) | (new_data&gt;max_cutoff)])

array([-5000, -3000, -1000,   900])

</pre>
</p><p>
The good news is that this is simple&mdash;simple to understand, simple to
implement and simple to automate.
</p><p>
However, it's also too simple for most data. You're unlikely to be
looking at a single-dimensional vector. The baseline (mean) is likely
to shift over time. And besides, there must be other, better ways to
measure whether something is &ldquo;inside&rdquo; or
&ldquo;outside&rdquo;, right?
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1516580.0x160f488"></a>
Getting More Sophisticated</h2></div></div><p>
For real-world anomaly detection, you're going to need to improve on a
few fronts. You'll need to consider the data and determine what's
&ldquo;in&rdquo; and what's &ldquo;out&rdquo;. You'll also need to figure out ways to evaluate
your model.
</p><p>
Let's consider novelty detection: there is initial data, and you want to
know if a new piece of data would fit inside the existing data or
if it would be considered an outlier. For example, consider a patient
who comes in with values from a blood test. Do those tests indicate
that the patient is normal, because the data's values are similar to
the ones you've already seen? Or are those new values statistical
outliers, indicating that the patient needs additional attention?
</p><p>
In order to experiment with novelty and outlier detection, I
downloaded historic precipitation data for an area of Pennsylvania
(Wyncote), just outside Philadelphia, for every day in
2016. Because I'm a scientific kind of guy, I downloaded the data in
metric units. The data came from the US government, at
<a href="https://www.climate.gov/maps-data/dataset/past-weather-zip-code-data-table" target="_self">https://www.climate.gov/maps-data/dataset/past-weather-zip-code-data-table</a>.
</p><p>
That site contains clear instructions for downloading data from here:
<a href="https://www.ncdc.noaa.gov/cdo-web/datasets" target="_self">https://www.ncdc.noaa.gov/cdo-web/datasets</a>.
</p><p>
It's quite amazing what government data is freely available, and the
sorts of analysis you can do with it once you've retrieved it.
</p><p>
I downloaded the data as a CSV file and then used Pandas to read it
into a data frame:

<pre     class="programlisting">
&gt;&gt;&gt; df = pd.read_csv('/Users/reuven/downloads/914914.csv',
    usecols=['PRCP', 'DATE'])
</pre>
</p><p>
Notice that I was interested only in PRCP (precipitation) and DATE (the
date, in YYYYMMDD format). I then manipulated the data to break apart
the DATE column and then to remove it:

<pre     class="programlisting">
&gt;&gt;&gt; df['DATE'] = df['DATE'].astype(np.str)
&gt;&gt;&gt; df['MONTH'] = df['DATE'].str[4:6].astype(np.int8)
&gt;&gt;&gt; df['DAY'] = df['DATE'].str[6:8].astype(np.int8)
&gt;&gt;&gt; df.drop('DATE', inplace=True, axis=1)
</pre>
</p><p>
Why would I break the date apart? Because it'll likely be easier for
models to work with three separate numeric columns, rather than a
single date-time column. Besides, having these columns as part of my
model will make it easier to understand whether snow in July is
abnormal. I ignore the year, since it's the same for every
record, which means that it can't help me as a predictor in this
model.
</p><p>
My data frame now contains 353 rows&mdash;I'm not sure why it's not
365&mdash;of data from 2016, with columns indicating the amount of rain (in
mm), the date and the month.
</p><p>
Based on this, how can you build a model to indicate whether rainfall
on a given day is normal or an outlier?
</p><p>
In scikit-learn, you always use the same method: you import the
estimator class, create an instance of that class and then fit the
model. In the case of supervised learning, &ldquo;fitting&rdquo; means teaching
the model which inputs go with which outputs. In the case of
unsupervised learning, which I'm doing here, you use &ldquo;fit&rdquo; with just
a set of inputs, allowing the model to distinguish between inliers and
outliers.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1516580.0x160fc18"></a>
Creating a Model</h2></div></div><p>
In the case of this data, there are several types of models that I can
build. I experimented a bit and found that the
<tt  >IsolationForest</tt>
estimator gave me the best results. Here's how I create and train the
model:

<pre     class="programlisting">
&gt;&gt;&gt; from sklearn.ensemble import IsolationForest
&gt;&gt;&gt; model = IsolationForest()
&gt;&gt;&gt; model.fit(df)
</pre>
</p><p>
The model now has been trained, so I can find out whether a given amount
of rain, on a certain month and day, is considered normal.
</p><p>
To try things out, I check the model against its own inputs:

<pre     class="programlisting">
&gt;&gt;&gt; Series(model.predict(df)).value_counts()
</pre>
</p><p>
In the above code, I run <tt  >model.predict(df)</tt>. This gives the inputs to
the model and asks it to predict whether these are normal, expected
values (indicated by 1) or outlier values (indicated by &ndash;1). By
turning the result into a Pandas series and then calling
<tt  >value_counts</tt>,
I see:

<pre     class="programlisting">
 1    317
-1     36
</pre>
</p><p>
Although it falsely marked 36 days as outliers, maybe those days were
unusual. The model certainly would be improved if it had multiple
years' worth of data, rather than just one year's worth.
</p><p>
Now what? I can ask the system to make some predictions:

<pre     class="programlisting">
for i in range(1, 13):
    print(model.predict([[15, i, 16]]))
</pre>
</p><p>
This will tell whether it's normal to get 15 mm rain on the 16th of
each month. The conclusion of the model: yes, it's perfectly normal
in February&ndash;July, but not so in August&ndash;January. What about
if there's zero precipitation:

<pre     class="programlisting">
for i in range(1, 13):
    print(model.predict([[0, i, 16]]))
</pre>
</p><p>
It turns out that no matter what month, it's never an outlier to
have zero rain on the 16th of the month.
</p><p>
Of course, those are just crude tests. The real thing to do is use our
old friend <tt  >train_test_split</tt>:

<pre     class="programlisting">
&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; X_train, X_test = train_test_split(df)
&gt;&gt;&gt; model.fit(X_train)
&gt;&gt;&gt; Series(model.predict(X_test)).value_counts()
</pre>
</p><p>
The model did pretty well, given that I didn't even try to tune it:

<pre     class="programlisting">
 1    77
-1    12
dtype: int64
</pre>
</p><p>
In other words, given data that should all be classified as
inliers, you can see here that the overwhelming majority is indeed
classified correctly.
</p><p>
There are other types of estimators you can use as well. In
particular, the One-Class SVM estimator has had a good track record of
working with input data. That, combined with a larger data set, might
well improve the results shown above&mdash;although in trying
One-Class SVM for this article, I didn't see any such results. It's
possible that if I were to add several more years' worth of data, other
estimators would work better.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1516580.0x1a08700"></a>
Conclusion</h2></div></div><p>
Novelty and outlier detection is (yet another) large, exciting and
growing use for machine learning. As usual with machine learning, the
problem is not one of coding, but rather of massaging the data into a
format that you can use, and then tinkering with model definitions
until you find one that predicts or identifies outliers with a high
degree of confidence.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1516580.0x1a08808"></a></h2></div></div><div class="sidebar"><p class="title"><b>
Resources</b></p><p>
I used Python (<a href="http://python.org" target="_self">python.org</a>) and many parts of the SciPy
stack (NumPy, SciPy, Pandas, Matplotlib and scikit-learn) in this
article. All are available from PyPI (<a href="http://PyPI.python.org" target="_self">PyPI.python.org</a>) or from
SciPy.org (<a href="https://www.scipy.org" target="_self">https://www.scipy.org</a>).
</p><p>
The documentation for scikit-learn has some (but not a great deal of)
documentation on novelty/outlier detection:
<a href="http://scikit-learn.org/stable/modules/outlier_detection.html" target="_self">scikit-learn.org/stable/modules/outlier_detection.html</a>
</p><p>
A simple Python package for detecting anomalies, lsanomaly, is
available on PyPI and GitHub: <a href="https://github.com/lsanomaly/lsanomaly" target="_self">https://github.com/lsanomaly/lsanomaly</a>.
It might be worth consideration for simple data sets.
</p><p>
As I mentioned previously, the US government's NOAA (National Oceanic and
Atmospheric Administration) site contains a treasure trove of weather and
climate data, which you can download for free at
<a href="https://www.ncdc.noaa.gov/cdo-web/datasets" target="_self">https://www.ncdc.noaa.gov/cdo-web/datasets</a>.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1516580.0x1a08d30"></a></h2></div></div><div class="sidebar"><p class="title"><b></b></p><p>Send comments or feedback via <a href="http://www.linuxjournal.com/contact" target="_self">www.linuxjournal.com/contact</a> or to
<a href="mailto:info@linuxjournal.com">info@linuxjournal.com</a>.
</p></div></div></div>
<div class="authorblurb"><p>
Reuven M. Lerner, a longtime Web developer, offers training and consulting
services in Python, Git, PostgreSQL and data science. He has written
two programming ebooks (<span   class="emphasis"><em>Practice Makes Python</em></span> and
<span   class="emphasis"><em>Practice Makes
Regexp</em></span>) and publishes a free weekly newsletter for programmers,
at
<a href="http://lerner.co.il/newsletter" target="_self">lerner.co.il/newsletter</a>. Reuven tweets at
@reuvenmlerner and
lives in Modi'in, Israel, with his wife and three children.

</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../277/toc277.html">Issue Table of Contents</a>
    <a class="link3" href="../277/12171.html">Article</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>