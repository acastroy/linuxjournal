<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
SIDUS&mdash;the Solution
for Extreme Deduplication of an Operating System
</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;Probe corrupted computers without disassembling anything, and provide&#10;users with a full-featured environment in just a few seconds.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x1d6c580.0x1e63ac0"></a>
SIDUS&mdash;the Solution
for Extreme Deduplication of an Operating System
</h1></div><div><div class="authorgroup"><div class="author"><h3 class="author">
Emmanuel
 
Quemener
</h3></div><div class="author"><h3 class="author">
Marianne
 
Corvellec
</h3></div><div class="issuemoyr">Issue #235, November 2013</div></div></div><div><p>
Probe corrupted computers without disassembling anything, and provide
users with a full-featured environment in just a few seconds.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d6c580.0x1e644b8"></a></h2></div></div><p>
SIDUS (Single-Instance Distributing Universal System) was developed at
Centre Blaise Pascal (Ecole normale sup&eacute;rieure de Lyon,
Lyon, France), where one administrator alone is in charge of 180 stations.
Emmanuel Quemener started SIDUS in February 2010, and he significantly
cut his workload for administering this park of stations.
SIDUS is now in use at the supercomputing centre PSMN (P&ocirc;le Scientifique de
Mod&eacute;lisation Num&eacute;rique) of the Ecole normale sup&eacute;rieure de Lyon.
</p><p>
With SIDUS, you can provide a new user with a complete functional environment in
just a few seconds. You can probe corrupted computers without disassembling
anything. You can test new equipment without installing an OS on them. You
can make your life so much easier when managing hundreds of cluster nodes, of
workstations or of self-service stations. You drastically can reduce the
amount of storage needed for the OS on these machines.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d6c580.0x1e646c8"></a>
Disclaimer</h2></div></div><p>
SIDUS is not LTSP. LTSP is a solution for the simplified management of thin
terminals through X11 or RDP access to a server. Thus, all the processing load is
on the latter server. On the contrary, SIDUS makes full use (or partial use,
as the user wishes) of the station's resources. Only the OS is stored
remotely.
</p><p>
SIDUS is not FAI. FAI or Kickstart offer full simplified installs so that
administration can be reduced or dismissed altogether. On the contrary,
SIDUS offers a single system in a tree that integrates the base system as
well as all manually installed applications.
</p><p>
SIDUS is flexible. When organizing IT-training sessions, you might want to
give participants a specific virtual environment. But once they download it,
you cannot modify it for them. SIDUS offers users a single given environment
that is easily configurable at any moment.
</p><p>
SIDUS is not exotic. SIDUS makes use of services available with any
distribution (DHCP, PXE, TFTP, NFSroot, DebootStrap and AUFS). You can install
SIDUS knowing only these few keywords. Besides, SIDUS makes use of
distribution tricks from live CDs. SIDUS works on Debian, all the way from
version Etch.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d6c580.0x1e64930"></a>
How Good Is SIDUS?</h2></div></div><p>
SIDUS is:
</p><div class="itemizedlist"><ul type="disc"><li><p>
Universal: platform-independent, x86 or x86_64 architectures.
</p></li><li><p>
Efficient: installing takes a few minutes, and booting takes a few seconds.
</p></li><li><p>
Energy-saving: it takes only one core, 1GB of RAM, 40GB in disk space
and an Ethernet (Gbit) network.
</p></li><li><p>
Scalable: tested successfully on a hundred nodes.
</p></li><li><p>
Multipurpose: we chose to use Debian as it comes with broad integration
of open-source scientific software.
</p></li></ul></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d6c580.0x1e64e00"></a>
Installing SIDUS on Your System</h2></div></div><p>
It takes a little preparation for your system to host SIDUS. We have several
services at our disposal in order to deploy our clients: DHCP, TFTP and NFS
servers. Now, either you are on great terms with your own IT staff, or you
are able to access freely the well-defined LDAP and DNS servers: 
</p><div class="itemizedlist"><ul type="disc"><li><p>
DHCP service provides the client with one IP address but propagates two
complementary pieces of information: IP address of the TFTP server (variable
&ldquo;next-server&rdquo;) and the name of the PXE binary, often called pxelinux.0.
</p></li><li><p>
TFTP service then comes into play. Booting the system is enabled by TFTP,
through the binary pxelinux.0, the kernel and startup of the client's system. If
you need to give a client some parameters, you just build a dedicated file
whose name stems from the client's MAC address (prefixing with 01 and
replacing : with -). 
</p></li><li><p>
NFS service now enters the loop: it gives the system's root via its protocol
(NFSroot). Accordingly, you will install your client system in this
root&mdash;for example, /src/nfsroot/sidus.
</p></li></ul></div><p>
In our configuration, we have used isc-dhcp-server, tftpd-hpa and
nfs-kernel-server for the servers DHCP, TFTP and NFS, respectively.
Let's look into this configuration.
</p><p>
For DHCP, the configuration file (/etc/dhcp/dhcpd.conf) reads:

<pre     class="programlisting">
next-server 172.16.20.251;
filename "pxelinux.0";
allow booting;
</pre>
</p><p>
For TFTP, there are three files and one directory (pxelinux.cfg) in /srv/tftp:

<pre     class="programlisting">
./pxelinux.0 
./vmlinuz-Sidus
./initrd.img-Sidus
./pxelinux.cfg
</pre>
</p><p>
The pxelinux.0 file comes from the syslinux-common package. In
pxelinux.cfg, there is
the file called default.
</p><p>
To boot, you need the following: the kernel vmlinuz-Sidus, the system
initrd.img-Sidus and the server NFSroot 10.13.20.13 with the mountpoint
/srv/nfsroot/sidus.
</p><p>
Below is an example of a boot file. It takes two inputs: tmpfs and iscsi
(we'll come back to the iscsi input later on):

<pre     class="programlisting">
DEFAULT tmpfs

LABEL tmpfs
KERNEL vmlinuz-Sidus
APPEND console=tty1 root=/dev/nfs
    initrd=initrd.img-Sidus
    nfsroot=10.13.20.13:/srv/nfsroot/sidus,
    rsize=8192,wsize=8192,tcp ip=dhcp aufs=tmpfs

LABEL iscsi
KERNEL vmlinuz-Sidus
APPEND console=tty1 root=/dev/nfs
    initrd=initrd.img-Sidus
    nfsroot=10.13.20.13:/srv/nfsroot/wheezy64,
    rsize=8192,wsize=8192,tcp ip=dhcp aufs=iscsi
    ISCSI_TARGET_IP=10.13.20.14
    ISCSI_INITIATOR=iqn.2013-04.zone.sidus.target:
    default root=LABEL=ISCSI
</pre>
</p><p>
Regarding the NFS server, it takes one line in the file /etc/exports to configure
it:


<pre     class="programlisting">
/srv/nfsroot/sidus
10.13.20.0/255.255.255.0(ro,no_subtree_check,async,no_root_squash)
</pre>
</p><p>
Here, we open a read-only access to stations with IP between 10.13.20.1 and
10.13.20.254.
</p><p>
Once you have configured these three services (DHCP, TFTP and NFS), you can
install a full SIDUS. Note that you also will need a root for user accounts
(via NFSv4) and a process enabling their identification/authentication (via
LDAP or Kerberos). We have deployed SIDUS on environments where these
services are provided by third-party servers but also on standalone
environments. Installing an OpenLDAP server with SSL or a Kerberos server is
off-topic, so we simply show the client configuration files for our
infrastructure (again, LDAP for identification/authentication and NFSv4 for
user folders).
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d6c580.0x1e65698"></a>
Install the Debian Base with Debootstrap</h2></div></div><p>
With Debootstrap, you can install a system in an extra root location.
Debootstrap needs you to specify parameters, such as the install root, the
hardware architecture, the distribution and the FTP or HTTP Debian archive
to use for downloading on Debian worldwide mirror sites.
</p><p>
Warning: this is where we get Debian-specific.
Debootstrap is a familiar tool for all Debian-like distributions (typically,
it is available on Ubuntu). It is not too difficult to make it happen on
Red Hat-like distributions though. There is a clone for Fedora called
febootstrap;
we have not tested it though.
</p><p>
Debootstrap (<a href="http://wiki.debian.org/Debootstrap" target="_self">wiki.debian.org/Debootstrap</a>) also takes as input a list
of archives&mdash;as we all know, Debian is very particular about distinguishing
the main archive area from the contrib and non-free ones&mdash;a list of packages
to include and a list of packages to dismiss. We wish we could specify the
latter two lists, but you cannot handle everything with Debootstrap. We
install from the very beginning a set of tools we deem necessary (such as the
kernel, some firmware and auditing tools).
</p><p>
We define environment variables corresponding to the root of our SIDUS system.
We define a command that enables the execution of commands via chroot, with a
specific option for package install. The variable
<tt  >$MyInclude</tt> corresponds to the
(comma-separated) list of packages you want, and
<tt  >$MyExclude</tt> corresponds to
the list of packages you do not want:

<pre     class="programlisting">
export SIDUS=/srv/nfsroot/sidus
time debootstrap --arch amd64
    --components='main,contrib,non-free'
    --include=$MyInclude --exclude=$MyExclude
    wheezy $SIDUS http://ftp.debian.org/debian
</pre>
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d6c580.0x1e65a08"></a>
Precautions before Moving on with the Install</h2></div></div><p>
After running the last-mentioned command, you should be a little cautious.
A Debian package normally starts after install.
You need to define a hook to inhibit the booting of services.
After completion of the install, you can remove this hook:

<pre     class="programlisting">
printf '#!/bin/sh\nexit 101\n' &gt;
    ${SIDUS}/usr/sbin/policy-rc.d
chmod +x ${SIDUS}/usr/sbin/policy-rc.d
</pre>
</p><p>
Some packages require access to the list of processes, system, peripherals,
peripheral pointers and virtual memory.
Hence, you should bind the mounting of these host system folders to SIDUS:

<pre     class="programlisting">
alias sidus="DEBIAN_FRONTEND=noninteractive chroot
    ${SIDUS} $@"
sidus mount -t proc none /proc
sidus mount -t sysfs sys /sys
mount --bind /run/shm ${SIDUS}/run/shm
mount --bind /dev/pts ${SIDUS}/dev/pts
</pre>
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d6c580.0x1e65c18"></a>
Install Additional Packages (Scientific Libraries)</h2></div></div><p>
To make it simpler when installing packages of the same family, Debian ships
with meta-packages. In our case, we are interested in the scientific ones:
their names are prefixed by &ldquo;science&rdquo;. For example, we have
&ldquo;science-chemistry&rdquo;, including all chemistry packages. You install all
scientific packages with only one command:

<pre     class="programlisting">
time sidus apt-get install --install-suggests -f
    -m -y --force-yes science-*
</pre>
</p><p>
Because we are talking about a <span   class="emphasis"><em>full-featured</em></span> OS, we also install the
suggested packages: the option <tt  >--install-suggests</tt> is available from Wheezy onward
(released May 5, 2013).
</p><p>
When installing, the costliest phase is downloading packages and
configuring certain components (Perl and LaTeX).
In the best-case scenario, it takes 45 minutes for a 32GB full tree.
There is a price to pay for this install craze. Some packages do not install
well, and you will want to purge some, such as a M*tlab installer:

<pre     class="programlisting">
time sidus apt-get purge -y -f --force-yes matlab-*
</pre>
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d6c580.0x1e5c870"></a>
Local Environment</h2></div></div><p>
Usually, you will want to adapt the system to a local environment (authentication
and user sharing). The default is US, so you may want to configure:
</p><div class="itemizedlist"><ul type="disc"><li><p>
${SIDUS}/etc/locale.gen.
</p></li><li><p>
${SIDUS}/etc/timezone.
</p></li><li><p>
${SIDUS}/etc/default/keyboard.
</p></li></ul></div><p>
For LDAP authentication, you may want to configure:
${SIDUS}/etc/nsswitch.conf, ${SIDUS}/etc/libpam_ldap.conf,
${SIDUS}/etc/libnss-ldap.conf and ${SIDUS}/etc/ldap/ldap.conf.
</p><p>
As for the mounting of NFS user folders:
</p><div class="itemizedlist"><ul type="disc"><li><p>
${SIDUS}/etc/default/nfs-common, ${SIDUS}/etc/default/idmapd.conf and
${SIDUS}/etc/fstab (for NFSv4).
</p></li><li><p>
${SIDUS}/etc/fstab (for NFSv3).
</p></li></ul></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d6c580.0x1e5ce48"></a>
Set Up the Boot Sequence</h2></div></div><p>
How do you share SIDUS without duplicating it? We found the best solution to
be via live CD. The boot sequence includes the two layers you
need&mdash;that is, a
read-only layer (on media for live CD and on NFS in our case) and a read-write
layer (on TMPFS). The two layers are linked via AUFS (the successor of UnionFS).
Everything is taken care of by a single hook upon boot (the script called
rootaufs). It operates in five steps:
</p><div class="orderedlist"><ol type="1"><li><p>
Creates the temporary files /ro, /rw and /aufs.
</p></li><li><p>
Moves the root of NFSroot from the original mountpoint to /ro.
</p></li><li><p>
Mounts the local or remote partition.
</p></li><li><p>
Superimposes /ro and /rw into /aufs.
</p></li><li><p>
Moves /aufs into the original mountpoint.
rootaufs goes into ${SIDUS}/etc/initramfs-tools/scripts/init-bottom.
</p></li></ol></div><p>
The original script is inspired the by rootaufs project by Nicholas A. Schembri
(<a href="http://code.google.com/p/rootaufs" target="_self">code.google.com/p/rootaufs</a>). We adapted it to a large extent to
match our infrastructure. A version is available at <a href="http://www.cbp.ens-lyon.fr/sidus/rootaufs" target="_self">www.cbp.ens-lyon.fr/sidus/rootaufs</a>:

<pre     class="programlisting">
wget -O
    ${SIDUS}/etc/initramfs-tools/scripts/init-bottom
    http://www.cbp.ens-lyon.fr/sidus/rootaufs
</pre>
</p><p>
The system is not functional yet. You need to create an initrd specific to
your
NFS boot.
Add aufs in ${SIDUS}/etc/initramfs-tools/modules and
force eth0 as DEVICE in ${SIDUS}/etc/initramfs-tools/initramfs.conf:

<pre     class="programlisting">
sidus update-initramfs -k all -u
</pre>
</p><p>
Then, you just copy the kernel and bootloader in the definition:

<pre     class="programlisting">
cp ${SIDUS}/vmlinuz /srv/tftp/vmlinux-Sidus
cp ${SIDUS}/srv/nfsroot/boot/initrd
    /srv/tftp/initrd-Sidus
</pre>
</p><p>
How can you take advantage of SIDUS while keeping a given configuration from
one boot to the next? Mounting NFS on each node separately is very costly.
It is preferable to mount iSCSI on each node.
</p><p>
Originally, we investigated how to offer a second NFS share in read-write
mode to ensure persistence of client-related changes from one boot to the
next. This version, although functional, required an atomized NFS&mdash;one
for each client. This was not sustainable for the server.
</p><p>
Therefore, we decided on another solution to ensure persistence. We create an
iSCSI share for each client. The settings for mounting the iSCSI disk are
defined in the line command.
</p><p>
So we use a network drive from iSCSI technology. In the config file
/srv/tftp/pxelinux.cfg/default, we have the definition
<tt  >LABEL=iscsi</tt>.
Each SIDUS client needs its own iSCSI storage space to ensure persistence.
For reasons of simplicity, in the initrd booting sequence, the SIDUS clients
fetch the volumes that bear their respective IPs.
The rootaufs file contains a default login/password.
</p><p>
A few tricks:
</p><div class="itemizedlist"><ul type="disc"><li><p>
Erase /etc/hostname to set the hostname through DHCP.
</p></li><li><p>
Set /etc/resolv.conf with a hard-coded definition.
</p></li><li><p>
Define a loopback in /etc/network/interfaces.
</p></li><li><p>
Change the booting of GDM3 so it starts only after NSCD is launched.
</p></li><li><p>
Set /etc/security/limits.conf (essential in an HPC environment).
</p></li><li><p>
Set /etc/fstab with input from the NFS server of user accounts.
</p></li><li><p>
For VirtualBox-based virtual systems,
install VBoxLinuxAdditions.run in the SIDUS system.
</p></li><li><p>
For systems with an InfiniBand card,
force loading of modules in /etc/modules and regenerate initrd.
In /etc/rc.local, execute a script that gets the Ethernet IP address and
builds an IP address for the InfiniBand card.
</p></li><li><p>
For systems with an NVIDIA card:
with most NVIDIA cards, packages offered with Debian Wheezy let you install
the necessary proprietary drivers and the OpenGL, Cuda and OpenCL
libraries.
Be careful if you want to use the OpenCL ICD (Installable Client Loader) for
AMD to operate your processors and your graphics board simultaneously. To be
able to do so, we had to install the entire environment&mdash;drivers, Cuda and
OpenCL&mdash;from scratch. 
</p></li><li><p>
For systems with an AMD ATI card:
with most ATI cards, packages offered with Debian Wheezy let you install
the necessary proprietary drivers and the OpenGL, Cuda and OpenCL
libraries.
</p></li></ul></div><p>
At the present time at CBP, we use the technique &ldquo;NFSroot + iSCSI =
AUFS&rdquo;
on SIDUS stations that require persistence, such as DiStoNet nodes (<a href="http://forge.cbp.ens-lyon.fr/projects/distonet" target="_self">forge.cbp.ens-lyon.fr/projects/distonet</a>).
Otherwise, we use &ldquo;NFSroot + TMPFS = AUFS&rdquo;.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d6c580.0x1e5e130"></a>
Install Wrap-up</h2></div></div><p>
We unmount all system folders necessary for installation:

<pre     class="programlisting">
umount ${SIDUS}/run/shm
umount ${SIDUS}/dev/pts
sidus umount /proc/sys/fs/binfmt_misc
sidus umount /proc
sidus umount /sys
</pre>
</p><p>
We activate the startup d&aelig;mons:

<pre     class="programlisting">
rm -f ${SIDUS}/usr/bin/policy-rc.d
cp /usr/sbin/start-stop-daemon
    ${SIDUS}/usr/sbin/start-stop-daemon
</pre>
</p><p>
We remove all process references launched by the install process:

<pre     class="programlisting">
rm -r ${SIDUS}/run/* ${SIDUS}/tmp/*
</pre>
</p><p>
This purges all processes related to SIDUS.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d6c580.0x1e5e448"></a>
Adapting to Heterogeneity</h2></div></div><p>
The park of computers may consist of cluster nodes (with fast network
equipment), workstations (with embedded GPUs) or virtual machines (which
require data sharing and GPU acceleration). For a large park, you do not
want persistence. You should use boot scripts, a separate SIDUS
tree or install third-party components.
</p><p>
Administering the system is not as easy as installing it.
The gain you experience in installing the system more than makes up for
the pain you experience in administering the system though.
With SIDUS, every administration phase abides by the installation
mechanisms: protection against booting and mounting of
system folders.
</p><p>
Administration techniques are similar to those for the initial install. We
use a script so that commands executed in SIDUS are surrounded by pre/post
operations. We use this script either automatically (typically for updates)
or manually. At the end of the day, these additional commands represent a
negligible burden with respect to the benefits we get. We now have several
(many) stations that are bit-for-bit identical to a given base system.
Other benefits:
</p><div class="itemizedlist"><ul type="disc"><li><p>
SIDUS works on user stations. The individual workstations can be considered
shared. We started with a dozen Neoware light clients
that were memory-enhanced and overclocked. We now have about 20 of
those.
</p></li><li><p>
SIDUS works on cluster nodes. In March 2010, we had a proof of concept with
24 nodes. Nowadays, SIDUS serves 86 permanent nodes over four different
hardware architectures.
</p></li><li><p>
SIDUS works on virtual stations.
Every year since 2011, Universit&eacute; Joseph Fourier organizes a
summer school on scientific computing.
For ten busy days, students train hands-on. Thus, it's necessary to
offer them a homogeneous environment in no time.
Two virtual images are offered: a persistent one they can use after
the summer school and another one via SIDUS.
This way, teachers can adapt materials and activities day by day.
Since summer 2012, this solution has been used at the Laboratory of
Chemistry of ENS de Lyon as well.
</p></li><li><p>
SIDUS works on suspicious stations. Booting via the network enables the
investigation of the shutdown system mass storage.
There is no need for a live CD&mdash;always short of your ideal forensic tool.
</p></li><li><p>
SIDUS works on loan stations. Hardware manufacturers usually offer
assessment equipment. The install phase can be tedious on recent equipment.
Using SIDUS, the system boots just like on other (in use)
equipment&mdash;for example, it takes a few minutes for 20 nodes.
</p></li></ul></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d6c580.0x2170c98"></a>Conclusion</h2></div></div><p>
Who should use SIDUS and why?
</p><div class="itemizedlist"><ul type="disc"><li><p>
Users: you choose the resources on which you want to boot your station.
Therefore, workstations can be segmented at will.
The VirtualBox version of SIDUS has been tested successfully on Linux,
MS Windows and Mac OS. GPU acceleration and sharing with the host are available.
Users find themselves in the same environment as the nodes'. This makes code
integration tremendously easier. Performance-wise, losses due to
virtualization vary between 10% and 20% for VirtualBox and about 5% for KVM.
</p></li><li><p>
Administrators: a given operation propagates to the entire infrastructure,
as if simply syncing over the SIDUS tree. The install takes a few tens of
minutes for a full-featured system.
To work out minor differences between systems, simple scripts or puppets do
the job. In the case of more important differences, just build another SIDUS
tree. The SIDUS tree might even just be cloned instantaneously using snapshot
tools (LVM or, better, ZFSonLinux).
</p></li><li><p>
For the sake of experiments: the SIDUS environment offers scientists and
system engineers a framework for conducting reproducible experiments. Two
nodes booting on the same SIDUS base do run the exact same system. This way,
even if the stations are not actually identical, relevant tests still can be
carried out.
</p></li></ul></div><p>
How much does it cost in terms of resources? To get an idea, the clusters' server (also
gateway) at CBP hosts DHCP, DNS, TFTP and NFS services, as well as a batch
server OAR. When booting the entire infrastructure (88 nodes), the NFS server
takes in 900Mb/s.
</p><p>
To conclude, you will want to use SIDUS on a variety of environments, be
they HPC nodes, workstations or virtual machines. SIDUS gives unprecedented
flexibility to both users and administrators. It is so energy-efficient and
it propagates so rapidly, you won't want to live without it!
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1d6c580.0x21710b8"></a></h2></div></div><div class="sidebar"><p class="title"><b></b></p><p>Send comments or feedback via <a href="http://www.linuxjournal.com/contact" target="_self">www.linuxjournal.com/contact</a> or to
<a href="mailto:info@linuxjournal.com">info@linuxjournal.com</a>.
</p></div></div></div>
<div class="authorblurb"><p>
Emmanuel Quemener defines his job as an &ldquo;IT test pilot&rdquo;. His work at
the HPC &ldquo;Centre Blaise Pascal&rdquo; (Lyon, France) involves software
integration, storage, scientific computing with GPUs and technology
transfer in science. 
</p><p>
Marianne Corvellec is a physicist who gratefully was exposed to the
wonderful world of free/libre and open-source software. She wants to
make computation science a better place, promoting best practices and
interacting with software experts. 
</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../235/toc235.html">Issue Table of Contents</a>
    <a class="link3" href="../235/11479.html">Article</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>