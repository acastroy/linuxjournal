<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8"/>
<link href="https://fonts.googleapis.com/css?family=Lateef" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<title>From the Editor: Engineers vs. Re-engineering</title>
<link href="../../css/archive.css" type="text/css" rel="stylesheet"/>
<script type="text/javascript" src="../../js/archive.js"></script>
<script type="text/javascript" src="../../js/highlight.js"></script>
</head>

<body class="from_sigil">
  
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>


  <div class="tophrdiv">
  </div>

  
  <div id="top_search">
    <table class="page_search" summary="">
      <tr>
        <td valign="top" align="left">
          <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
        </td>
        <td valign="top" align="right">
          <form method="get" action="/zoom/search.cgi">
            <input type="hidden" name="zoom_sort" value="0" />
            <input type="hidden" name="zoom_xml" value="0" />
            <input type="hidden" name="zoom_per_page" value="10" />
            <input type="hidden" name="zoom_and" value="1" />
            Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
            <input type="submit" value="Submit" />
          </form>
        </td>
      </tr>
    </table>
  </div>

<h1 class="title">From the Editor: Engineers vs. Re-engineering</h1>

<h2 class="sigil_not_in_toc">In an age when people are being re-engineered into farm animals for AI
ranchers, it's the job of engineers to save humanity through true personal
agency. By Doc Searls</h2>
<div class="caption">
<img alt="Scenic road" src="12499c.jpg"/>

<p class="caption"></p>
</div>
<p>
A few months ago, I was driving through Los Angeles when the <a href="https://www.waze.com">Waze</a> app on my
phone told me to take the Stadium Way exit off the 110 freeway. About five
other cars peeled off with me, and we became a caravan, snaking through side
streets and back onto the freeway a few miles later. I knew Waze had to be in
charge of us, since Waze is the navigation app of choice in Los Angeles, and
it was beyond coincidence that all these cars took the same wild maze run
through streets only locals knew well.
</p>

<p>
What was Waze up to here, besides offering its users (or a subset of them) a
way around a jam? Was it optimizing traffic by taking some cars off the
highway and leaving others on? Running an experiment only some AI understood?
There was no way to tell. I doubt anyone at Waze could say exactly what was
going on either. Algorithms are like that. So are the large and constantly
changing data sets informing algorithms most of us with mobile devices depend
on every day.
</p>

<p>
In <em>Re-engineering Humanity</em>, Brett Frischmann and Evan Selinger have dug
deeply into what's going on behind the "cheap bliss" in our fully connected
world.
</p>

<p>
What they say is that we are all subjects of <em>techno-social
engineering</em>. In
other words, our algorithmic conveniences are re-making us, much as the
technologies and techniques of agriculture re-makes farm animals. And, as
with farming, there's an extraction business behind a lot of it.
</p>

<p>
They say "humanity's techno-social dilemma" is that "companies, institutions,
and designers regularly treat us as <em>programmable objects</em> through personalized
technologies that are attuned to our personal histories, present behavior and
feelings, and predicted futures."
</p>

<p>
And we are not innocent of complicity in this. "We outsource memory,
decision-making and even our interpersonal relations...we rely on the
techno-social engineers' tools to train ourselves, and in doing so, let
ourselves be trained."
</p>

<p>
There are obvious benefits to "delegating physical, cognitive, emotional and
ethical labor to a third party", such as Waze, but there are downsides, which
Brett and Evan number: 1) passivity, 2) decreased agency, 3) decreased
responsibility, 4) increased ignorance, 5) detachment and 6) decreased
independence. On the road to these diminished human states, we have
"fetishised computers and idealized computation".
</p>

<p>
Doing both means "we work on problems best solved by computation", which in
turn leads to "the imperialism of instrumental reason and the improper
assumption that all problems are comprehensible in the language of
computation and thus can be solved with the same set of social and
technological tools".
</p>

<p>
They see today's faith in computational technology as the latest expression
of belief in <a href="https://en.wikipedia.org/wiki/Frederick_Winslow_Taylor">Frederick
Taylor</a>'s <a href="https://en.wikipedia.org/wiki/Scientific_management">theory of
scientific management</a>. More than a
theory, Taylorism gave us norms for producing mass-market goods that have
been with us for more than a century and have hardly gone away. In <em>The
Cluetrain Manifesto</em> (which four of us wrote in 1999), Chris Locke <a href="http://www.cluetrain.com/book/apocalypso.html">explains</a>:
</p>

<blockquote>
<p>
Taylor's time-and-motion metrics sought to bring regularity and
predictability to bear on the increasingly detailed division of labor. Under
such a regimen, previously holistic craft expertise rapidly degraded into the
mindless execution of single repetitive tasks, with each worker performing
only one operation in the overall process. Because of its effect on workers'
knowledge, de-skilling is a term strongly associated with mass production.
And as skill disappeared, so did the unique voice of the craftsman. The
organization was elegantly simple, if not terribly humane.
</p>
</blockquote>

<p>
"At one level", write Brett and Evan, "Taylor's scientific management system
is a type of data-dependent technology. Taylorism is one of the best early
examples of data-driven innovation, a concept currently in vogue. Taylor's
systems included the techniques for both gathering data and putting such data
to use in managing people. Taylor's system thus encompassed the surveillance
techniques employed by the 'efficiency experts'" of Taylor's time—and of
ours.
</p>

<p>
Surveillance of people is now the norm for nearly every website and app that
harvests personal data for use by machines. Privacy, as we've understood it
in the physical world since the invention of the loincloth and the door
latch, doesn't yet exist. Instead, all we have are the "privacy policies" of
corporate entities participating in the data extraction marketplace, plus
terms and conditions they compel us to sign, either of which they can change
on a whim. Most of the time our only choice is to deny ourselves the
convenience of these companies' services or live our lives offline.
</p>

<p>
Worse is that these are proffered on the Taylorist model, meaning mass-produced.
</p>

<p>
In "Contracts of Adhesion—Some Thoughts about Freedom of Contract"
(<em>Columbia Law Review</em>, July 1943), Friedrich Kessler explained how these
shitty non-agreements came to be:
</p>

<blockquote>
<p>
The development of large scale enterprise with its mass production and
mass distribution made a new type of contract inevitable—the standardized
mass contract. A standardized contract, once its contents have been
formulated by a business firm, is used in every bargain dealing with the same
product or service. The individuality of the parties which so frequently gave
color to the old type of contract has disappeared. The stereotyped contract of
today reflects the impersonality of the market....Once the usefulness of
these contracts was discovered and perfected in the transportation,
insurance, and banking business, their use spread into all other fields of
large scale enterprise.
</p>
</blockquote>

<p>
Rather than obsolesce these kinds of contracts, digital technology and the
internet allowed companies to automate them. The effects are not good for the
human side of each contract. Brett and Evan explain, "Our current online
contracting regime is a compelling example of how our legal rules coupled
with a specific technological environment can lead us to behave like simple
stimulus-response machines—perfectly rational, but also perfectly
predictable and ultimately programmable."
</p>

<p>
In a chapter titled "On Extending Minds and Mind Control", Brett and Evan
visit the ways humans are diminished as well as enlarged when programmed by
their digital conveniences. To start getting what they mean, it helps to
remember that every personal technology we operate—shoes, bikes, pens,
books, cars, hammers, airplanes—extend our senses and enlarge our agency.
It is no mistake that drivers speak in first-person possessive pronouns about
the parts of the cars they operate: <em>my</em> tires, <em>my</em> engine,
<em>my</em> fenders. To drive
a car is to become one.
</p>

<p>
But what happens when our senses extend beyond the metal carapace we wear
when we drive a car—outward through the unseen systems guiding our selves
and every other car on the road? In this state we are not GPS satellites and
Google data centers, but rather puppets at the ends of digital strings pulled
by AI puppeteers.
</p>

<p>
We surely appreciate and rely on what they provide us, but we also yield
agency in the process of blurring between our automotive selves and a vast
system of dependencies, which even if they are doing good things for
us, make us less than human—or, in Brett and Evans' words, "simple
machines under the control and influence of those in control of
technologies". Inevitably, they also say, "traffic engineers will assume the
role of social planners." But the traffic engineers they're talking about are
not the human kind working for highway departments, but machines run by
companies making navigation apps, all of which have purposes beyond providing
personal and civic goods.
</p>

<p>
The challenge Brett and Evan pose in their concluding chapter is "how to
sustain the freedom to be off, to be free from techno-social engineering, to
live and develop within undetermined techno-social environment". Toward these
they set a buffet of possible approaches, three of which can be addressed by
the agency of <em>Linux Journal</em> readers, many of whom are engineers by trade:
</p>

<ol><li>
Challenge conventional wisdom, ideas and theories that perpetuate
existing logics and engineer complacency.</li>
<li>
Create gaps and seams between smart techno-social systems that constrain
techno-social engineering and techno-social engineering creep.</li>

<li>
Engineer transaction costs and inefficiencies to support human
flourishing through the exercise and development of human capabilities.</li>
</ol>

<p>
Then they give a nod to decentralization and go into possible reforms to
legal systems.
</p>

<p>
In the book's last two pages, they also give a nod toward my own work: "Doc
Searls and his colleagues at <a href="http://customercommons.org">Customer
Commons</a> have been working for years on
standardized terms for customers to use in managing their relationships with
websites and other vendors", noting that the <a href="https://en.wikipedia.org/wiki/General_Data_Protection_Regulation">General
Data Protection</a>
Regulation (GDPR) in Europe at least makes it possible "to imagine
alternative contracting practices and more nuanced contractual
relationships".
</p>

<p>
In the book's final paragraph, they say "Doc Searls' dream of customers
systematically using contract and related tools to manage their relationships
with vendors now seems feasible. It could be an important first step toward
flipping the scientific-management-of-consumers script we've become so
accustomed to."
</p>

<p>
The engineers among us have a hard job. But it should help to know how high
the stakes are, and how we're already embedded so deeply in a re-engineered
dystopia that we can't see how tragically ironic cheap bliss really is.
</p>

<h3 class="sigil_not_in_toc">About the Author</h3>
<div class="authorblurb">
<p>
Doc Searls is a veteran journalist, author and part-time academic who
spent more than two decades elsewhere on the <em>Linux Journal</em>
masthead before becoming Editor in Chief when the magazine was reborn
in January 2018. His two books are <em>The Cluetrain Manifesto</em>,
which he co-wrote for Basic Books in 2000 and updated in 2010, and
<em>The Intention Economy: When Customers Take Charge</em>, which he
wrote for Harvard Business Review Press in 2012. On the academic front,
Doc runs ProjectVRM, hosted at Harvard's Berkman Klein Center for Internet
and Society, where he served as a fellow from 2006–2010. He was
also a visiting scholar at NYU's graduate school of journalism from
2012–2014, and he has been a fellow at UC Santa Barbara's Center
for Information Technology and Society since 2006, studying the internet
as a form of infrastructure.
</p>
<img alt="Doc Searls" src="12499aa.jpg"/>
</div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../289/toc289.html">Issue Table of Contents</a>
    <a class="link3" href="../289/12499.html">Article</a>
  </div>
  <div class="bottomhrdiv"></div>

  <div id="bottom_search">
    <table class="page_search" summary="">
      <tr>
        <td valign="top" align="left">
          <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
        </td>
        <td valign="top" align="right">
          <form method="get" action="/zoom/search.cgi">
            <input type="hidden" name="zoom_sort" value="0" />
            <input type="hidden" name="zoom_xml" value="0" />
            <input type="hidden" name="zoom_per_page" value="10" />
            <input type="hidden" name="zoom_and" value="1" />
            Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
            <input type="submit" value="Submit" />
          </form>
        </td>
      </tr>
    </table>
  </div>
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>

  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
</body>
</html>