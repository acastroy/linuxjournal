<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
Simulators for Training Firefighters</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;The US Navy and the New York Fire Department are teaming up&#10;to create a safe, realistic 3-D training environment.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0xed3580.0xfcaab0"></a>
Simulators for Training Firefighters</h1></div><div><div class="author"><h3 class="author">
Douglas
 
Maxwell
</h3></div><div class="issuemoyr">Issue #122, June 2004</div></div><div><p>
The US Navy and the New York Fire Department are teaming up
to create a safe, realistic 3-D training environment.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xed3580.0xfcb240"></a></h2></div></div><p>
According to the Federal Emergency Management Agency (FEMA), there was a 31% decrease in the incidence of
structure fires throughout the United States between 1987&ndash;2001. A direct
result of this reduction means less firefighting experience for our
firefighters. As more-experienced firefighters retire, they are replaced
by comparatively less-experienced personnel. This situation mandates
optimal training techniques. Visualization and simulation technologies
are maturing at a rapid pace and offer great potential to augment current
training programs.
</p><p>
Using today's visualization technologies, a training simulator offers a
realistic representation of real-world environments. Models of real-world
facilities, buildings and areas can be rendered with great detail.
In addition, the computational improvements made to PCs and laptops
make them practical and inexpensive platforms to deploy. These training
techniques also can be adopted easily by the current and next generations
of firefighters who typically engage in video gaming for recreation.
Due to the inherent dangers of training for fire emergencies, it is hoped
that these emerging visualization technologies can augment current
training techniques and better prepare firefighters for emergencies.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xed3580.0xfcb3a0"></a>
Models</h2></div></div><p>
The New York Fire Department (NYFD) recently built a multimillion-dollar extension to its training facility at Randall's Island (RI),
near Manhattan. This facility is a one-block re-creation of typical
architectures found in the five boroughs. Among the buildings are
a brownstone, tenement, pizza shop and auto parts store.
In September 2003, a team from the Naval Undersea Warfare Center (NUWC)
was invited to tour this facility and photograph it so they later could create
textures for the models being developed for the NYFD.
</p><div       class="mediaobject"><a href="7384f1.large.jpg"><img src="7384f1.jpg"></a><div class="caption"><p>
Figure 1. The NYFD Training Facility at Randall's Island
</p></div></div><div       class="mediaobject"><a href="7384f2.large.jpg"><img src="7384f2.jpg"></a><div class="caption"><p>
Figure 2. Model of the RI Facility, Kitchen Fire in a Pizza Shop
</p></div></div><p>
The NYFD's architectural contractor provided architectural plans for the
buildings in the form of CAD drawings. The next
step was to model the buildings from plans using Multigen Paradigm's
Creator package. Lastly, the models were completed by texture mapping
the models using the digital photos. This process took about four weeks.
</p><p>
This methodology can be applied to any architecture, from buildings to
vehicles. Current plans for this technology include creating models of
targets of strategic importance for use in advanced training of first
responders. In addition, NUWC plans to apply this technology to the
testing and evaluation of function of command and control
centers for future naval architectures (Figure 3).
</p><div       class="mediaobject"><a href="7384f3.large.jpg"><img src="7384f3.jpg"></a><div class="caption"><p>
Figure 3. A corridor aboard ex-USS <span  class="emphasis"><em>Shadwell</em></span>, a decommissioned
US Navy ship used as a damage control research facility.
</p></div></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xed3580.0xfcbad8"></a>
Software</h2></div></div><p>
The underlying software used to control the environment was a modification
of work done for my thesis research while working at the Naval Research
Laboratory. With the help of Rob King, we created the gestural
interface needed to navigate through a true 3-D synthetic environment.
Using this methodology, the navigation is
accomplished by pointing in the direction the user wants to travel and
pressing a button to move. The navigational algorithm is accelerative,
which means the longer the user depresses the forward button,
the faster the user moves through the environment.
</p><p>
The graphics were handled by the SGI Performer 3.0.1 scene graph for Linux.
Performer is a well-established scene graph based on the OpenGL graphics
libraries, and it offers Linux users solid performance. It was important
to retain a wide variety of display options, because we wanted to be able to
deploy a prototype system that could be used in both stereoscopic and
monoscopic modes, as well as on multiple display devices.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xed3580.0xfcbc38"></a>
Hardware</h2></div></div><p>
The software is demonstrated using a modified Dell Precision 340.
The system is an Intel Pentium 4 processor running at 1.8GHz, with 512MB
of RAM and three video cards. The video subsystem includes one NVIDIA
NV20 (GeForce 3/64Mb) AGP video card and two NVIDIA NV17 (GeForce 4 MX
440/64Mb) PCI video cards. The system is running a stock installation
of Red Hat 9.
</p><p>
The software also is demonstrated on a Sony VAIO laptop powered by
an Intel Pentium 4 processor running at 2.6GHz, with 512MB of RAM and an ATI
RADEON IGP card. The purpose of this platform is to demonstrate the
flexibility of the graphics options.
</p><p>
In addition to the graphics and displays, we used a Polhemus magnetic
tracking system in the gestural interface as an alternative to a mouse
interface. A Logitech Wingman joystick was re-engineered for use as
a gestural input device. Figure 4 shows the inside of the joystick.
A tracking sensor is embedded in the grip of the joystick. Communication
with the computer is achieved by remapping standard serial mice and
wiring them to the buttons within the joystick. The computer interprets
the joystick button presses as mouse clicks.
</p><div       class="mediaobject"><a href="7384f4.large.jpg"><img src="7384f4.jpg"></a><div class="caption"><p>
Figure 4. A Logitech Wingman Joystick with Tracking Sensor
Added
</p></div></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xed3580.0xfcbfa8"></a>
Prototype</h2></div></div><p>
As testing progresses, we hope these visualization and simulation
technologies can help meet ever-expanding training needs for both
military and civilian emergency response teams. Applications for
this limited prototype include pretraining practice
runs for
rescue workers and navigational training for workers unfamiliar with
the environment.
</p><p>
Future plans and upgrades to this software are a bit more ambitious.
One use for the system is as a scenario-driven classroom/firehouse
trainer. It will include instructor-steered or preconfigured scenarios
in which the trainer reacts to trainee/student input and adjusts
the scenario accordingly. This will be supported by physics-based modeling
of fire/smoke/heat and so on. As with the prototype, future iterations of
this software will be available in various display configurations, from
large/multiple-screen classrooms to PCs and laptops.
</p><p>
In addition to the scenario-driven training, this software also is planned
to be a post-exercise debriefing tool. The location of trainees in a
training environment, such as Randall's Island or a burn building, can be
tracked at any time during the training exercise. Trainers could replay
the training event, showing participants' locations at given times. Planned
features include split-screen displays that could show participants'
individual viewpoints during the exercise as well as the bird's-eye view.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0xed3580.0xfcc160"></a>
Acknowledgements</h2></div></div><p>
The author would like to thank Mr Jim Pollock of the Naval Undersea
Warfare Center for funding this project, Dr Stephan Hitman of the NYFD for
providing logistical support and resources and Dr Larry Rosenblum of the
Naval Research Laboratory for permission to use the ex-USS
<span   class="emphasis"><em>Shadwell</em></span> model.
</p><p><span   class="bold"><b>Resources for this article:</b></span>
<a href="../122/7499.html" target="_self">/article/7499</a>.
</p></div></div>
<div class="authorblurb"><p>
Douglas Maxwell is a mechanical engineer and research scientist at the Naval
Undersea Warfare Center. His areas of expertise include design synthesis in
virtual environments and synthetic training applications. He lives with his
wife and dachshund in Newport, Rhode Island.
</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../122/toc122.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>