<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
EOF
</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;If silo builders control the edge, the distributed future can't happen.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x2a79580.0x2b70ac0"></a>
EOF
</h1></div><div><h3 class="subtitle"><i>
How to Fix the Edge
</i></h3></div><div><div class="author"><h3 class="author">Doc Searls</h3></div><div class="issuemoyr">Issue #276, April 2017</div></div><div><p>
If silo builders control the edge, the distributed future can't happen.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2a79580.0x2b71300"></a></h2></div></div><p>
In December 2016, Peter Levine (<a href="http://peter.a16z.com" target="_self">peter.a16z.com</a>)
of the venture firm Andreessen Horowitz published a post with a video
titled &ldquo;Return to the Edge and the End of Cloud Computing&rdquo; (<a href="http://a16z.com/2016/12/16/the-end-of-cloud-computing" target="_self">a16z.com/2016/12/16/the-end-of-cloud-computing</a>). In it, he
outlines a pendulum swing between centralized and distributed computing
that goes like this:
</p><div class="itemizedlist"><ul type="disc"><li><p>
Mainframe/Centralized/1960-1970 &harr;
Client-Server/Distributed/1980&ndash;2000
</p></li><li><p>
Mobile-Cloud/Centralized/2005-2020 &harr; Edge
Intelligence/Distributed/2020&ndash;
</p></li></ul></div><p>
He says the &ldquo;total addressable market&rdquo; in that next pendulum swing will
include the Internet of Things, with trillions of devices, starting with
today's cars and drones. He also says machine learning will be required
to &ldquo;decipher the nuances of the real world&rdquo;.
</p><p>
Thanks to bandwidth and latency issues, most of this will have to
happen at end points, on the edge, and not in central clouds. Important
information still will flow to those clouds and get processed there for
various purposes, but decisions will happen where the latency is lowest
and proximity highest: at the edges. Machines will make most of the data
they gather (and is gathered for them). That's because, he says, humans
are bad at many decisions that machines do better, such as in driving
a car. Peter has a Tesla and says &ldquo;My car is a much better driver than
I am.&rdquo; In driving for us, machine-learning systems in our things will
&ldquo;optimize for agility over power&rdquo;. Systems in today's fighter aircraft
already do this for pilots in dogfights. They are symbiotes of a kind,
operating as a kind of external nervous system for pilots, gathering data,
learning and reacting in real time, yet leaving the actual piloting up
to the human in the cockpit. (In dogfights, pilots also do not depend on
remote and centralized clouds, but they do fly through and around the
non-metaphorical kind.)
</p><p>
The learning curve for these systems consists of three verbs operating
in recursive loops. The verbs are <span   class="emphasis"><em>sense</em></span>,
<span   class="emphasis"><em>infer</em></span> and <span   class="emphasis"><em>act</em></span>. Here's how
those sort out.
</p><p><span   class="bold"><b>
Sense</b></span>
</p><p>
Data will enter these loops from sensors all over the place&mdash;cameras,
depth sensors, radar, accelerometers. Already, he says, &ldquo;a self-driving
car generates about ten gigabytes of data per mile&rdquo;, and &ldquo;a Lytro
(<a href="https://www.lytro.com" target="_self">https://www.lytro.com</a>) camera&mdash;a data center in a
camera&mdash;generates 300 gigabytes of data per second.&rdquo; Soon running shoes
will have sensors with machine-learning algorithms, he adds, and they will be
truly smart, so they can tell you, for example, how well you are doing
or ought to do.
</p><p><span   class="bold"><b>
Infer</b></span>
</p><p>
The data from our smart things will be mostly unstructured, requiring
more machine learning to extract relevance, do task-specific recognition,
train for &ldquo;deep learning&rdquo;, and to increase accuracy and automate what
needs to be automated. (This will leave the human stuff up to the
human&mdash;again like the fighter pilot doing what only he or she can do.)
</p><p><span   class="bold"><b>
Act</b></span>
</p><p>
As IoT devices become more sophisticated, we'll have more data accumulations
and processing decisions, and in many (or most) cases, machines will make
ever-more-educated choices about what to do. Again, people will get to
do what people do best. And, they'll do it based on better input from
the educated things that also do what machines do best on their own.
</p><p>
Meanwhile, the old centralized cloud will become what he calls a &ldquo;training
center&rdquo;. Since machine learning needs lots of data in order to learn,
and the most relevant data comes from many places, it only makes sense for
the cloud to store the important stuff, learn from everything everywhere,
and push relevant learnings back out to the edge. Think of what happens
(or ought to happen) when millions of cars, shoes, skis, toasters and
sunglasses send edge-curated data back to clouds for deep learning,
and the best and most relevant of that learning gets pushed back out to
the machines and humans at the edge. Everything gets smarter&mdash;presumably.
</p><p>
His predictions:
</p><div class="itemizedlist"><ul type="disc"><li><p>
Sensors will proliferate and produce huge volumes of geo-spacial data.
</p></li><li><p>
Existing infrastructure will back-haul relevant data while most
computing happens at edges, with on-site machine learning as well.
</p></li><li><p>
We will return to peer-to-peer networks, where edge devices lessen the
load on core networks and share data locally. 
</p></li><li><p>
We will have less code and more math, or &ldquo;data-centric
computing&rdquo;&mdash;not just
the logical kind.
</p></li><li><p>
The next generation of programmers won't be doing just logic: IF, THEN,
ELSE and the rest.
</p></li><li><p>
We'll have more mathematicians, at least in terms of talent required.
</p></li><li><p>
Also expect new programming languages addressing edge use cases.
</p></li><li><p>
The processing power of the edge will increase while prices decrease,
which happens with every generation of technology. 
</p></li><li><p>
Trillions of devices in the supply chain will commoditize processing
power and sensors. The first LIDAR for a Google car was $7,000. The new
ones are $500. They'll come down to 50 cents.
</p></li><li><p>
The entire world becomes the domain of IT. &ldquo;Who will run the fleet of
drones to inspect houses?&rdquo; When we have remote surgery using robots,
we also will need allied forms of human expertise, just to keep the
whole thing running. 
</p></li><li><p>
We'll have &ldquo;consumer-oriented applications with enterprise
manageability.&rdquo;
</p></li></ul></div><p>
His conclusion: &ldquo;There's a big disruption on the horizon. It's going
to impact networking, storage, compute, programming languages and, of
course, management.&rdquo;
</p><p>
All that is good as far as it goes, which is toward what companies will
do. But what about the human beings who own and use this self-educating
and self-actualizing machinery? Experts on that machinery will have
new work, sure. And all of us will to some degree become experts on our
own, just as most of us are already experts with our laptops and mobile
devices. But the IoT domain knowledge we already have is confined to
silos. Worse, silo-ization of smart things is accepted as the status quo.
</p><p>
Take for example &ldquo;Google Home vs. Amazon
Echo&mdash;a Face-Off of Smart Speakers&rdquo; by
Brian X. Chen in <span   class="emphasis"><em>The New York Times</em></span> (<a href="https://www.nytimes.com/2016/11/04/technology/personaltech/google-home-vs-amazon-echo-a-face-off-of-smart-speakers.html?_r=1" target="_self">https://www.nytimes.com/2016/11/04/technology/personaltech/google-home-vs-amazon-echo-a-face-off-of-smart-speakers.html?_r=1</a>).
Both Google Home and Amazon Echo are competitors in the &ldquo;virtual
assistant&rdquo; space that also includes Apple's Siri and Microsoft's
Cortana. All are powered by artificial intelligence and brained
in the server farms of the companies that sell them. None
are compatible with each other, meaning substitutable. And
all are examples of what Phil Windley called The Compuserve of
Things in a blog post by that title exactly three years ago (<a href="http://www.windley.com/archives/2014/04/the_compuserve_of_things.shtml" target="_self">www.windley.com/archives/2014/04/the_compuserve_of_things.shtml</a>).
His summary:
</p><div class="blockquote"><blockquote class="blockquote"><p>
On the Net today we face a choice between freedom and captivity,
independence and dependence. How we build the Internet of Things has
far-reaching consequences for the humans who will use&mdash;or be used
by&mdash;it. Will we push forward, connecting things using forests of silos
that are reminiscent of the online services of the 1980s, or will we
learn the lessons of the internet and build a true Internet of Things?
</p></blockquote></div><p>
If progress continues on its current course, the distributed future Peter
Levine projects will be built on the forest-of-silos Compuserve-of-things
model we already have. Amazon, Apple, Google and Microsoft are all
silo-building Compuserves that have clearly not learned the first
lesson of the internet&mdash;that it was designed to work for everybody and
everything, and not just so controlling giants can fence off territories
where supply chains and customers can be held captive. For all their
expertise in using the internet, these companies are blindered to the
negative externalities of operating exclusively in their self interest,
oblivious to how the internet is a tide that lifts all their economic and
technological boats. In that respect, they are like coal and oil companies:
expert at geology, extraction and bringing goods to market, while paying
the least respect to the absolute finitude of the goods they extract from
the Earth and to the harms that burning those goods cause in the world.
</p><p>
But none of that will matter, because the true Internet of Things is
the only choice we have. If all the decisions that matter most, in real
time (or close enough), need to be made at the edge, and people there
need to be able to use those things expertly and casually, just like
today's fighter pilots, they'll need to work for us and not just their
makers. They'll be like today's cars, toasters, refrigerators and other
appliances in two fundamental ways: they'll work in roughly the same
ways for everybody, so the learning curve isn't steep; and they'll be
substitutable. If the Apple one fails, you can get a Google one and
move on.
</p><p>
For an example, consider rental cars. They're all a bit different,
but you know how to drive all of them. Sure, there are glitches. Every
Toyota I rent plays Edith Piaf (from somewhere in my music collection)
as soon as I plug in my phone to the car's USB jack. Other car brands
have their own dashboard quirks. (Last month, my visiting sister rented
a Chrysler 200, which had the stupidest and least useful climate control
system I've ever seen, but it was easy for both of us to drive.)
</p><p>
Also, as the ever-more distributed world gets saturated by smart things
on Peter Levine's model, we will have more need to solve existing problems
that get worse every day in present time. Some examples:
</p><div class="itemizedlist"><ul type="disc"><li><p>
Too many login and password combinations, plus the fact that we still need
logins and passwords at all. Geez, it's 2017. We can do better than that.
</p></li><li><p>
Too many ways to message each other. Last I counted, Apple's App Store
had something like 170 different messaging apps, and Google Play had more
than
a hundred. The only standard we ever had for bridging them all was XMPP,
originally called Jabber, which I advocated mightily in <span   class="emphasis"><em>Linux
Journal</em></span>,
back around the turn of the millennium. (See &ldquo;The Message&rdquo; at
<a href="http://www.linuxjournal.com/article/4112" target="_self">www.linuxjournal.com/article/4112</a>, &ldquo;Talking
Jabber&rdquo; at <a href="http://www.linuxjournal.com/article/4113" target="_self">www.linuxjournal.com/article/4113</a>
and &ldquo;Jabber Asks the Tough Question&rdquo; at <a href="http://www.linuxjournal.com/article/5631" target="_self">www.linuxjournal.com/article/5631</a>.) For whatever reason,
XMPP stalled. (Never mind why. Make another standard protocol everyone
can adopt.) 
</p></li><li><p>
Too many contacts and too few ways of connecting them to login/password
management, to-do lists, calendars or other ways of keeping records.
</p></li><li><p>
Calendar and contact apps silo'd into the bowels of Apple,
Microsoft, Google and others, with too few compatibilities.
</p></li></ul></div><p>
To solve all these problems, you need to start with the individual:
the individual device, the individual file, the individual human being.
</p><p>
If you start with central authority and central systems, you make
people and things subordinate dependents, and see problems only silos
can solve. All your things and people will be captive, by design. No
way around it.
</p><p>
Why do I pose this challenge here? Two reasons: 1) because Linux answered
the same challenge in the first place, and it can again; and 2) because
Linux geeks have the best chance of both grokking the challenge and
doing something about it.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2a79580.0x2f6b808"></a></h2></div></div><div class="sidebar"><p class="title"><b></b></p><p>Send comments or feedback via <a href="http://www.linuxjournal.com/contact" target="_self">www.linuxjournal.com/contact</a> or to
<a href="mailto:info@linuxjournal.com">info@linuxjournal.com</a>.
</p></div></div></div>
<div class="authorblurb"><p>
Doc Searls is Senior Editor of <span   class="emphasis"><em>Linux Journal</em></span>. He is
also a fellow with the
Berkman Center for Internet and Society at Harvard University and the
Center
for Information Technology and Society at UC Santa Barbara.

</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../276/toc276.html">Issue Table of Contents</a>
    <a class="link3" href="../276/12169.html">Article</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>