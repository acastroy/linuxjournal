<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>Performance Monitoring Tools for Linux</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;    Mr. Gavin provides tools for systems data collection and display and&#10;    discusses what information is needed and why.&#10;    "><meta name="keywords" content="system, data, tool"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x1e5a580.0x1f51ab0"></a>Performance Monitoring Tools for Linux</h1></div><div><div class="author"><h3 class="author">David Gavin</h3></div><div class="issuemoyr">Issue #56, December 1998</div></div><div><p>
    Mr. Gavin provides tools for systems data collection and display and
    discusses what information is needed and why.
    </p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e5a580.0x1f52500"></a></h2></div></div><p>For the last few years, I have been
supporting users on various flavors of UNIX systems and have found
the System Accounting Reports data invaluable for performance
analysis. When I began using Linux for my personal workstation, the
lack of a similar performance data collection and reporting tool
set was a real problem. It's hard to get management to upgrade your
system when you have no data to back up your claims of &ldquo;I need
more POWER!&rdquo;. Thus, I started looking for a package to get the
information I needed, and found out there wasn't any. I fell back
on the last resort&mdash;I wrote my own, using as many existing tools as
possible. I came up with scripts that collect data and display it
graphically in an X11 window or hard copy.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e5a580.0x1f52608"></a>What Do We Want to Know?</h2></div></div><p>To get a good idea of how a system is performing, watch key
system resources over a period of time to see how their usage and
availability changes depending upon what's running on the system.
The following categories of system resources are ones I wished to
track.</p><p><span   class="bold"><b>CPU Utilization</b></span>: The central
processing unit, as viewed from Linux, is always in one of the
following states:</p><div class="itemizedlist"><ul type="disc"><li><p><span   class="emphasis"><em>idle</em></span>: available for work,
waiting</p></li><li><p><span   class="emphasis"><em>user</em></span>: high-level functions,
data movement, math, etc.</p></li><li><p><span   class="emphasis"><em>system</em></span>: performing kernel
functions, I/O and other hardware interaction</p></li><li><p><span   class="emphasis"><em>nice</em></span>: like user, a job with
low priority will yield the CPU to another task with a higher
priority</p></li></ul></div><p>By noting the percentage of time spent in each state, we can
discover overloading of one state or another. Too much idle means
nothing is being done; too much system time indicates a need for
faster I/O or additional devices to spread the load. Each system
will have its own profile when running its workload, and by
watching these numbers over time, we can determine what's normal
for that system. Once a baseline is established, we can easily
detect changes in the profile.
</p><p><span   class="bold"><b>Interrupts</b></span>: Most I/O devices
use interrupts to signal the CPU when there is work for it to do.
For example, SCSI controllers will raise an interrupt to signal
that a requested disk block has been read and is available in
memory. A serial port with a mouse on it will generate an interrupt
each time a button is pressed/released or when the mouse is moved.
Watching the count of each interrupt can give you a rough idea of
how much load the associated device is handling.</p><p><span   class="bold"><b>Context Switching</b></span>: Time
slicing is the term often used to describe how computers can appear
to be doing multiple jobs at once. Each task is given control of
the system for a certain &ldquo;slice&rdquo; of time, and when that time is
up, the system saves the state of the running process and gives
control of the system to another process, making sure that the
necessary resources are available. This administrative process is
called context switching. In some operating systems, the cost of
this switching can be fairly expensive, sometimes using more
resources than the processes it is switching. Linux is very good in
this respect, but by watching the amount of this activity, you will
learn to recognize when a system has a lot of tasks actively
consuming resources.</p><p><span   class="bold"><b>Memory</b></span>: When many processes
are running and using up available memory, the system will slow
down as processes get paged or swapped out to make room for other
processes to run. When the time slice is exhausted, that task may
have to be written out to the paging device to make way for the
next process. Memory-utilization graphs help point out memory
problems.</p><p><span   class="bold"><b>Paging</b></span>: As mentioned above,
when available memory begins to get scarce, the virtual memory
system will start writing pages of real memory out to the swap
device, freeing up space for active processes. Disk drives are
fast, but when paging gets beyond a certain point, the system can
spend all of its time shuttling pages in and out. Paging on a Linux
system can also be increased by the loading of programs, as Linux
&ldquo;demand pages&rdquo; each portion of an executable as needed.</p><p><span   class="bold"><b>Swapping</b></span>: Swapping is much
like paging. However, it migrates entire process images, consisting
of many pages of memory, from real memory to the swap devices
rather than the usual page-by-page mechanism normally used for
paging.</p><p><span   class="bold"><b>Disk I/O</b></span>: Linux keeps
statistics on the first four disks; total I/O, reads, writes, block
reads and block writes. These numbers can show uneven loading of
multiple disks and show the balance of reads versus writes.</p><p><span   class="bold"><b>Network I/O</b></span>: Network I/O can
be used to diagnose problems and examine loading of the network
interface(s). The statistics show traffic in and out, collisions,
and errors encountered in both directions.</p><p>These charts can also help in the following instances:</p><div class="itemizedlist"><ul type="disc"><li><p>The system is running jobs you aren't aware of
during hours when you are not present.</p></li><li><p>Someone is logging on or remotely running commands
on the system without your knowledge.</p></li></ul></div><p>This sort of information will often show up as a spike in the
charts at times when the system should have been idle. Sudden
increases in activity can also be due to jobs run by
<span   class="bold"><b>crontab</b></span>.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e5a580.0x1f53420"></a>Collecting the Data</h2></div></div><p>The file /proc/stat contains current counters for most of the
data I wanted, and it is in a readable format. In order to keep the
collector script as quick and simple as possible, I saved the data
in a readable format rather than as binary data.</p><p>Breaking down and reorganizing the data for storage was a
good job for <span   class="bold"><b>awk</b></span>, writing the data
out to different files depending on the type of data. The /proc
files are formatted nicely for this; each record has an identifying
name in the first field. Here's a sample of /proc/stat from my 486
system:</p><pre     class="programlisting">
cpu 1228835 394 629667 23922418
disk 43056 111530 0 0
disk_rio 18701 20505 0 0
disk_wio 24355 91025 0 0
disk_rblk 37408 40690 0 0
disk_wblk 48710 182050 0 0
page 94533 204827
swap 1 0
intr 27433973 25781314 58961 0 1059544 368102 1 2\
0 0 0 11133 154916 0 0 0 0
ctxt 18176677
btime 863065361
processes 18180
</pre><p>I dug into the kernel source for the /proc file system to
figure out what the various fields were, as the man pages seem to
date back to 1.x.
<div class="itemizedlist"><ul type="disc"><li><p><b  >cpu</b>: contains the following
information: jiffies (1/100 of a second) spent in
user/nice/system/idle states. I wasn't too concerned about the
actual measurement, as I was just planning on looking at each state
as a percentage of the total.</p></li><li><p><b  >disk</b>: summarizes all I/O to each
of the four disks, while <b  >disk_rio</b>,
<b  >disk_wio</b>, <b  >disk_rblk</b> and
<b  >disk_wblk</b> break down the total into read, write,
blocks read and blocks written.</p></li><li><p><b  >page</b>: page in and out
counters</p></li><li><p><b  >swap</b>: counts of pages swapped in
and out. The swap data in /proc/meminfo is expressed as total
pages, used and free. Combine both sets of data to get a clear
picture of swap activity.</p></li><li><p><b  >intr</b>: total interrupts since
boot time, followed by counts for each interrupt.</p></li><li><p><b  >ctxt</b>: the number of context
switches since boot time. This counts the number of times one
process was &ldquo;put to sleep&rdquo; and another was &ldquo;awakened&rdquo;.</p></li><li><p><b  >btime</b>: I haven't found much use
for this&mdash;it is the number of seconds after January 1, 1970 that
the system was booted.</p></li><li><p><b  >processes</b>: the most recent
process identification number. This is a good way to see how many
processes have been spawned since the last check, so by subtracting
the old value from the current one and dividing by the time
difference (in seconds) between the two observations, the number of
new processes per second is known and can be used to measure how
busy the system is.</p></li></ul></div>

Network activity counters are found in the /proc/net/dev file; an
example of this file is shown in <a href="2396t1.html" target="_self">Table
1</a>.
</p><p>The lines we want here are the
<b  >eth<i><tt>x</tt></i></b> and
<b  >ppp<i><tt>x</tt></i></b> records. In the
collector script, the data is written out to a file using the full
interface name. This way, the script is generalized for most any
configuration.</p><p>Memory utilization can be tracked in the /proc/meminfo file
as shown in <a href="2396t2.html" target="_self">Table 2</a>.</p><p>The memory counters are expressed twice in this file, so we
need to save only the <b  >Mem:</b> and
<b  >Swap:</b> records to get the whole picture. The
script matches the keywords at the start of the line and writes the
data out to individual files rather than to one large database to
allow more flexibility as new fields or data types are added. This
makes for a cluttered directory but simpler script writing.</p><p>The script that collects the data is shown in
<a href="2396l1.html" target="_self">Listing 1</a>. Here are some things
that are going on in a few key parts, plus comments:</p><div class="itemizedlist"><ul type="disc"><li><p>Line 13: move to the directory where the data is to
be stored using <span   class="bold"><b>cd</b></span>.</p></li><li><p>Line 14: get the timestamp for the data records in
format HHMM.</p></li><li><p>Line 15: get the date for the output data file
names in format MonDD.YY</p></li><li><p>Lines 19 - 25: select the memory and swap counter
lines from /proc/meminfo and write the timestamp and data portion
of the record to Mem.MonDD.YY and Swap.MonDD.YY.</p></li><li><p>Lines 29 - 36: extract the counters for any network
interfaces from /proc/net/dev and write them out to files including
the interface numbers, i.e., eth0 data is written out to
eth0.MonDD.YY.</p></li><li><p>Lines 39 - 79: clip counters for cpu, disk, paging,
swap page usage, interrupts, context switching and process numbers
from /proc/stat and write them out to appropriate files.</p></li></ul></div><p>The following line in my crontab file runs the collection
script every five minutes every hour of every day:
<pre     class="programlisting">
0,5,10,15,20,25,30,35,40,45,50,55 * * * *\
/var/log/sar/sa 0 0 * * * exec /usr/bin/find\
/var/log/sar/data/ -mtime +14
-exec /bin/rm -f {} \;
</pre>


The data accumulates over the course of the day to provide the data
points for analysis. A cleanup script invoked by the second line
removes each file after two weeks to keep the disk space
requirements down. A possible enhancement might be to compress each
file after it is complete, but space hasn't been much of an issue
yet.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e5a580.0x234ccc8"></a>What Do We Do with the Data?</h2></div></div><p>I now had the data, but since columns of figures are boring,
I needed a way to look at the data and make sense of it. I had used
<span   class="bold"><b>gnuplot</b></span> for similar tools on other
systems, so it seemed to be a good choice. I started with a script
to display CPU utilization, charting the percentages of time spent
in idle, user, system and nice states.</p><p>The cpu data file has five columns that look like
this:</p><pre     class="programlisting">
0000 4690259 69915 661038 7937582
0005 4690408 69964 661286 7966975
</pre><p>Column 1: seconds in idle state since last bootedColumn 2:
seconds in system state since last bootedColumn 3: seconds in nice
state since last bootedColumn 4: seconds in user state since last
bootedColumn 5: time-stamp of observation (HHMM)
</p><p>My reporting scheme was to get the amount of seconds spent in
each state since the last observation, add up the different states
and express each one as a percentage of the total. I ran into an
interesting issue right away&mdash;what about a reboot? Booting the
system zeroes out the counters and subtracting the old from the new
generates negative values, so I had to handle it properly to
provide useful information. I decided to watch for a counter value
that was lower than the last observation's value and, if found,
reset the prior values to zero. To make the chart more informative,
a data point was set to 100 for a reboot and -1 for a normal
record. The -1 value causes the data point to be outside the chart
and thus not displayed.</p><p>Sometimes a hard copy is preferred when presentations or
reports are needed. The gnuplot authors provide for a variety of
output formats, and the script will switch between X11 display and
PostScript output depending upon which option switches are
set.</p><div       class="mediaobject"><img src="2396f1.jpg"><div class="caption"><p>
Figure 1. Sample Chart

</p></div></div><p>Figure 1 is a sample chart produced by the graphing script
shown in <a href="2396l2.html" target="_self">Listing 2</a>. A breakdown of
the major parts of this script is included in the archive file on
SSC's FTP site,
<a href="../listings/056/2396.tgz" target="_self">ftp.linuxjournal.com/pub/lj/listings/issue56/2396.tgz</a>.
Also included are the collection script, graphing scripts, a sample
crontab entry for running the collector script and the following
charting scripts:</p><div class="itemizedlist"><ul type="disc"><li><p><span   class="bold"><b>cpu</b></span>: charting cpu
information as described above</p></li><li><p><span   class="bold"><b>ctxt</b></span>: charting
context switching per second</p></li><li><p><span   class="bold"><b>disk</b></span>: disk
utilization: total I/O, read/writes and block read/writes per
second</p></li><li><p><span   class="bold"><b>eth</b></span>: Ethernet
packets sent and received per second and both incoming and outgoing
errors</p></li><li><p><span   class="bold"><b>intr</b></span>: interrupts
by interrupt number and charted per second</p></li><li><p><span   class="bold"><b>mem</b></span>: memory
utilization and buffer/cache/shared memory allocations</p></li><li><p><span   class="bold"><b>page</b></span>: page in and
out activity</p></li><li><p><span   class="bold"><b>ppp</b></span>:
Point-to-Point Protocol packets sent/received per second and
errors</p></li><li><p><span   class="bold"><b>proc</b></span>: new process
creation per second</p></li><li><p><span   class="bold"><b>swap</b></span>: swap
activity and swap space availability</p></li></ul></div><p>I'm currently converting this toolkit to Perl and building a
web interface to allow these charts to be viewed as HTML pages with
the charts as GIF files.
</p><p>All listings referred to in this article are available by
anonymous download in the file
<a href="../listings/056/2396.tgz" target="_self">ftp.linuxjournal.com/pub/lj/listings/issue56/2396.tgz</a>.</p></div></div>
<div class="authorblurb"><p>
        <div       class="mediaobject"><img src="2396aa.jpg"></div>
            <span   class="bold"><b>David Gavin</b></span>
            (<a href="mailto:dgavin@unifi.com">dgavin@unifi.com</a>)
            has worked in various support
            environments since 1977, when after COBOL training, he had the good
            fortune to be assigned to the TSO (Time Sharing Option) support
            group. From there he moved to MVS technical support, to VM and to
            UNIX. He has worked with UNIX from mainframes to desktops,
            baby-sitting Microsoft systems only when he couldn't avoid it. He
            started using Linux back when it meant downloading twenty-five
            disks over a 2400 BAUD dial-up line.
          </p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../056/toc056.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>