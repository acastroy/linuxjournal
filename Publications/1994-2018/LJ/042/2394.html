<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>Linux and the Alpha</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;    This is the first of a 2 part series, an introduction to the&#10;    Alpha family of computers in preparation for giving us the&#10;    techniques for optimizing code on this high-performance&#10;    platform in Part 2.&#10;    "><meta name="keywords" content="Alpha, programs, speed"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x1619580.0x1710ab0"></a>Linux and the Alpha</h1></div><div><div class="author"><h3 class="author">David Mosberger</h3></div><div class="issuemoyr">Issue #42, October 1997</div></div><div><p>
    This is the first of a 2 part series, an introduction to the
    Alpha family of computers in preparation for giving us the
    techniques for optimizing code on this high-performance
    platform in Part 2.
    </p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1619580.0x1711348"></a></h2></div></div><p>Ever since its announcement in the Fall
of 1991, the Alpha architecture (see Reference 3) has been the
foundation of the world's fastest systems. In fact, except for one
or two brief blips, Alpha systems have been the highest-performing
systems based on single-CPU SPECmark performance. With this
outstanding performance record comes marketing hype and, sometimes,
unrealistic expectations. It is not all that uncommon to find
e-mail messages or USENET articles saying things like: &ldquo;I heard
the Alpha is so fast, but now I find that my dusty deck is just 10%
faster on the Alpha than on the other system.&rdquo; So what's the
truth? The honest answer is that it depends on what you're doing.
Alpha systems are without a doubt fast machines, but it is
unreasonable to expect that taking a dusty deck and running it on
an Alpha will result in the best possible performance. This is
particularly true for programs that were written with the mind-set
of the eighties, when CPU cycles were at a premium and memory
bandwidth was abundant. Reality looks quite different today: CPU
clock-rates above 150MHz are the rule and even laptops can run at
200MHz or more. The result is that, today, the memory system&mdash;and
not the CPU&mdash;is often the first-order bottleneck.
</p><p>In part 2 of this article, we will demonstrate a few simple
techniques that help avoid the memory system bottleneck. Except for
one case, the focus is on integer-intensive applications. The topic
of optimizing floating-point intensive applications is certainly
just as important but, unfortunately, well beyond the scope of this
series. The techniques presented can result in tremendous
performance improvements. While the techniques will be helpful for
all modern systems, they normally extract the biggest benefits on
Alpha-based machines. There are a couple of reasons for this
bias.</p><p>One, the Alpha architecture has been designed with longevity
in mind. Specifically, the Alpha architecture should be good for
the next 15-25 years, which corresponds roughly to a 1000-fold
increase in overall performance. For this reason, some
design-tradeoffs were made in favor of long-term viability rather
than short-term benefits. For example, the Alpha was right from the
start a 64-bit architecture, even though, at the time of its
announcement, 32-bit address spaces were considered comfortably
large.</p><p>Two, the current Alpha implementations are designed to
achieve high performance by pushing clock frequency to the limit.
This means the CPU-to-memory-system performance gap is the largest
for Alpha-based systems. For example, suppose a memory access takes
100ns. On a 500MHz Alpha CPU, this corresponds to 50 clock cycles.
In contrast, on a 250MHz CPU, this is only 25 cycles. So the
relative performance penalty of accessing memory is much higher on
a CPU with higher clock speeds. This may sound like a bad thing,
but since the absolute performance is the same, what this really
means is that a fast-clock CPU system that is running a
memory-bound application will be about as fast as a slower-clock
system, but when running a memory-wise application, it will be much
faster.</p><p>In this part of the series, I present a brief overview of
existing and upcoming Alpha implementations. While it is not
usually necessary to optimize for a specific CPU, it is helpful to
know what the characteristics of current CPUs and systems are. I
also discuss a couple of simple performance analysis tools that are
available under Linux. When porting legacy code to modern systems,
such tools are invaluable, since they avoid wasting time trying to
optimize rarely executed code.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1619580.0x17115b0"></a>Overview of Alpha Family</h2></div></div><p>So far, the Alpha CPU family tree spans three generations; it
all began with the 21064 chip. At the time of its introduction, it
was the highest performing CPU, and it still makes for a nice
workstation, though it's no longer competitive with the latest
generation CPUs. This chip branched off into a version that was
called the &ldquo;Low-Cost Alpha&rdquo; (LCA), also known as 21066 or 21068.
The chip core was identical to the 21064 but it had an integrated
memory and PCI-bus controller. This high integration made it
possible to build Alpha-based systems at relatively low cost and
for the embedded systems market. Unfortunately, the design had a
major weakness&mdash;the memory system was seriously under-powered. This
created the paradoxical situation in which a system based on this
chip performed on some applications on average, no better than a
100MHz Pentium, but outperformed a P6 running at 200MHz. As a
result, the reaction to this chip varied greatly, and probably
resulted in quite a few disappointed customers for Digital. On the
other hand, there is no doubt that the low-cost at which
21066-based systems eventually were sold caused a quantum leap in
the number of Linux/Alpha users.</p><p>Around June 1994, the 21164 chip was announced. It had
dramatically improved performance over the 21064 and was the first,
and so far only, Alpha CPU to feature a three-level cache
hierarchy. The first and second-level caches were both on-chip and
only the third-level cache was on the motherboard. This chip, in
slightly improved versions, is still going strong. At the Fall 1996
Comdex in Las Vegas, such a chip, coupled with a liquid cooling
system, was demonstrated running at 767MHz. Another version, called
21164PC, is scheduled to become available around Spring 1997. It
omits the relatively expensive second-level, on-chip cache but adds
multi-media extensions and other performance-enhancing features. As
the name indicates, this chip is designed to be price-competitive
with PC processors, specifically the forthcoming Intel Klamath (an
improved P6). While price-competitive, the 21164PC is supposed to
deliver over 50% better performance than the Klamath. For this
second-generation, low-cost Alpha implementation, it certainly
looks like Digital and its co-designer Mitsubishi are not going to
repeat the mistakes of the past. The 21164PC promises to be cheap
and fast.</p><p>If you happen to have a deep pocket or want to take a glance
at what PC processors might look like in two or three years, the
21264 might be of interest. It is scheduled to become available in
high-end machine during the second half of 1997. With this chip,
CPU performance is expected to take another giant leap. Current
estimates call for a performance level that is three to four times
faster than the fastest CPUs available today.</p><p>Between each major chip generation, there are typically
&ldquo;half-generation&rdquo; CPUs which have improvements that derive
primarily from a shrink of the chip manufacturing process. For
example, the 21064 chip was followed by the 21064A, and similarly,
the 21164 was followed by the 21164A. In the former case, the core
of the chip remained virtually identical to the 21064, but the
primary caches doubled in size from 8KB to 16KB. In the latter
case, instructions for byte and word accesses were added and the
maximum clock frequency increased from 333 to 500MHz.</p><p>A summary of the performance attributes of the current Alpha
chip family is presented in Table 1.</p><p>2394s1.ps (min=50, max=52)</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1619580.0x1711870"></a>Table 1. Summary of Alpha Chip Family</h2></div></div><p></p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1619580.0x1711978"></a>Linux Performance Analysis Tools</h2></div></div><p>The state of Linux performance analysis tools is in rather
dire straits (this is true for freeware in general, not just
Linux). Commercial products currently have an edge in this area.
For example, Digital Unix comes with an excellent tool (or rather
tool generator) called ATOM (see Reference 2). ATOM is basically a
tool that can rewrite any executable. While rewriting, it can add
arbitrary instrumentation code to each function or basic block.
Digital Unix comes with a bunch of tools built with ATOM: 3rd
degree (a memory-leaks and bounds checker like the well-known
purify) and a number of tools that give very detailed information
on the performance behavior of a program (such as cache miss
frequency, issue rates and so on). At present, the freeware
community can only dream of such versatile tools.</p><p>While bleak, the situation is by no means hopeless. The few
tools that are available make for powerful companions when properly
used. Even good old GNU <span   class="bold"><b>gprof</b></span> has
a few features of which you may not be aware (more on this later).
Let's start with the most basic performance
measurement&mdash;time.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1619580.0x1711b30"></a>Accurately Measuring Time</h2></div></div><p>The Unix way of measuring time is by calling
<span   class="bold"><b>gettimeofday()</b></span>. This returns the
current real time at a resolution of typically one timer tick
(about 1ms on the Alpha). The advantage of this function is that
it's completely portable across all Linux platforms. The
disadvantage is its relatively poor resolution (1ms corresponds to
500,000 CPU cycles on a 500MHz CPU) and, more severely, it involves
a system call. A system call is relatively slow and has the
tendency to mess up your memory system. For example, the cache gets
loaded with kernel code so that when your program resumes
execution, it sees many cache misses that it wouldn't see without
the call to gettimeofday(). This is all right for measuring times
on the order of seconds or minutes, but for finer-grained
measurements, something better is needed.</p><p>Fortunately, most modern CPUs provide a register that is
incremented either at the clock frequency of the CPU or an integer
fraction thereof. The Alpha architecture provides the
<span   class="bold"><b>rpcc</b></span> (read processor cycle count)
instruction. It gives access to a 64-bit register that contains a
32-bit counter in the lower half of the register. This counter is
incremented once every N clock cycles. All current chips use N = 1,
so the register gets incremented at the full clock frequency.
(There may be future Alpha processors where N &gt; 1). The top half
of the value returned by rpcc is operating system -dependent. Linux
and Digital UNIX return a correction value that makes it easy to
implement a cycle counter that runs only when the calling process
is executing (i.e., this allows you to measure the process's
virtual cycle count). With <span   class="bold"><b>gcc</b></span>,
it's very easy to write <span   class="bold"><b>inline</b></span>
functions that provide access to the cycle counters. For
example:</p><pre     class="programlisting">
static inline u_int realcc (void) {
    u_long cc;
    /* read the 64 bit process cycle
        counter into variable cc: */
    asm volatile("rpcc %0" : "=r"(cc)
                : : "memory");
    return cc; /* return the lower 32 bits */
    }
       static inline unsigned int virtcc (void) {
          u_long cc;
          asm volatile("rpcc %0" : "=r"(cc)
                        : : "memory");
          /* add process offset and count */
          return (cc + (cc&lt;&lt;32)) &gt;&gt; 32;
       }
</pre><p>With this code in place, function
<span   class="bold"><b>realcc()</b></span> returns the 32-bit
real-time cycle count, whereas function
<span   class="bold"><b>virtcc()</b></span> returns the 32-bit
virtual cycle count (which is like the real-time count except that
counting stops when the process isn't running).
</p><p>Calling these functions involves very small overhead. The
slowdown is on the order of 1-2 cycles per call and adds only one
or two instructions (which is less than the overhead for a function
call). A good way of using these functions is to create an
execution-time histogram. For example, the function below measures
individual execution times of calls to
<span   class="bold"><b>sqrt</b></span> (2.0) and prints the results
to standard output (as usual, care must be taken to ensure that the
compiler doesn't optimize away the actual computation). Printing
the individual execution times makes it easy to create a histogram
with a little post-processing.</p><pre     class="programlisting">
void measure_sqrt (void) {
          u_int start, stop, time[10];
          int i;
          double x = 2.0;
          for (i = 0; i &lt; 10; ++i) {
             start = realcc();
             sqrt(x);
             stop = realcc();
             time[i] = stop - start;
          }
         for (i = 0; i &lt; 10; ++i)
             printf(" %u", time[i]);
             printf(""n");
       }
</pre><p>Note that the results are printed in a separate loop; this is
important since <span   class="bold"><b>printf</b></span> is a rather
big and complicated function that may even result in a system call
or two. If printf were part of the main loop, the results would be
much less reliable. A sample run of the above code might produce
output like this:
<pre     class="programlisting">
120  101  101  101  101  101  101  101  101  101
</pre>


Since this output was obtained on a 333MHz Alpha, 120 cycles
corresponds to 36ns and 101 cycles corresponds to 30ns. The output
shows nicely how the first call is quite a bit slower since the
memory system (instruction cache in particular) is cold at that
point. Since the square root function is small enough to easily fit
in the first-level instruction cache, all but the first calls
execute at exactly the same time.
</p><p>You may wonder why the above code uses realcc() instead of
virtcc(). The reason for this is simple&mdash;we want to know the
results that were affected by a context switch. By using realcc(),
a call that suffers a context switch will be much slower than any
of the other calls. This makes it easy to identify and discard such
unwanted outlying statistics.</p><p>The cycle counter provides a very low-overhead method of
measuring individual clock cycles. On the downside, it cannot
measure very long intervals. On an Alpha chip running at 500MHz, a
32-bit cycle counter overflows after just eight and a half seconds.
This is not normally a problem when making fine-grained
measurements, but it is important to keep the limit in mind.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1619580.0x1712210"></a>Performance Counters</h2></div></div><p>The Alpha chips, like most other modern CPUs, provide a
variety of performance counters. These allow measuring various
event counts or rates, such as the number of cache misses,
instruction issue rate, branch mispredicts or instruction
frequency. Unfortunately, I am not aware of any Linux API that
would provide access to these counters. This is particularly
unfortunate since both the Pentium and the Pentium Pro chips
provide similar counters. Digital UNIX gives access to these
counters via the <span   class="bold"><b>uprofile</b></span> and
<span   class="bold"><b>kprofile</b></span> programs, and an
ioctl-based interface documented in the pfm(7) man page. Hopefully,
something similar (but more general) will eventually become
available for Linux. With the proper tools, these counters can
provide a wealth of information.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1619580.0x17123c8"></a>GNU gprof</h2></div></div><p>Most readers are probably familiar with the original gprof
(see Reference 3). It's a handy tool to determine the primary
performance bottlenecks at the function level. However, with the
help of gcc, GNU gprof can also look inside a function. We
illustrate this with a truly trivial function that computes the
factorial. Assume we've typed up the factorial function and a
simple test program in file <b  >fact.c</b>. We can then
compile that program like this (assuming GNU libc version 2.0 or
later is installed):</p><pre     class="programlisting">
gcc -g -O -a fact.c -lc
</pre><p>Invoking the resulting a.out binary once produces a gmon.out
file that contains the execution counts for each basic block in the
program. We can look at these counts by invoking gprof, specifying
the <b  >-l</b> and <b  >--annotate</b>
options. This command generates a source-code listing that shows
how many times a basic block in each line of source code has been
executed.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1619580.0x1712688"></a>Listing 1. Basic-block Execution Counts</h2></div></div><p>Our factorial example results in the listing shown in Listing
1. The basic block starting at the printf line in function
<span   class="bold"><b>main()</b></span> was executed once, so it
has been annotated with a 1. For the factorial function, the
function prologue and epilogue were executed 20 times each, so the
first and last line of function
<span   class="bold"><b>fact</b></span> are annotated with 20. Of
these 20 calls, 19 resulted in a recursive call to
<span   class="bold"><b>fact</b></span>, and the remaining call
simply returned 1. Correspondingly, the <b  >then</b>
branch of the <b  >if</b> statement has been annotated
with 19, whereas the <b  >else</b> statement has an
annotation of 1. It's that simple.</p><p>There certainly are no surprises in the behavior of function
<b  >fact()</b>, but in realistic, more complicated
functions or in code that was written by somebody else, this
knowledge can be very helpful to avoid wasting time optimizing
rarely executed code.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1619580.0x1712a50"></a>Optimization Techniques: Making Your
Applications Fly</h2></div></div><p>Next month, we'll look into the techniques that can greatly
improve the performance of a given piece of code. Most of them are
not novel. Some of them have been around for so long that it would
be difficult, if not impossible, to give proper credit. Others are
&ldquo;obvious&rdquo; (once you know them). The key point is that it is the
characteristics of modern, particularly Alpha-based, systems which
make these techniques so important and worthwhile.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1619580.0x1712b58"></a>Acknowledgments</h2></div></div><p>The author would like to thank Richard Henderson of Texas
A&amp;M University and Erik Troan of Red Hat Software for reviewing
this paper on short notice. Their feedback greatly improved its
quality. Errors and omissions are the sole responsibility of the
author.</p></div></div>
<div class="authorblurb"><p>David is a graduate student in the Ph.D. program
      of the Computer Science department at the University of Arizona. He
      plans on graduating in August 1997 and to finally get a &ldquo;Real
      Job&rdquo;. After a short intermezzo with Linux involving Reed-Solomon
      codes and the floppy-tape driver, he forgot about Linux until the
      need arose for a low-cost, high-performance system based on
      Digital's Alpha processor. As a result, he got involved in the
      Linux/Alpha port and has been sticking around in the free software
      community ever since. When not playing with computers, he enjoys
      the outdoors with his lovely wife. He can be reached via e-mail at
      David.Mosberger@acm.org.</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../042/toc042.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>