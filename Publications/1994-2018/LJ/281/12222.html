<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
At the Forge
</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;How do modern network applications handle multiple connections? Reuven&#10;explains the three main paradigms in use today.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x2779580.0x2870ac0"></a>
At the Forge
</h1></div><div><h3 class="subtitle"><i>
Thinking Concurrently
</i></h3></div><div><div class="author"><h3 class="author">
Reuven
 M. 
Lerner
</h3></div><div class="issuemoyr">Issue #281, September 2017</div></div><div><p>
How do modern network applications handle multiple connections? Reuven
explains the three main paradigms in use today.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2779580.0x2871408"></a></h2></div></div><p>
When I first started consulting, and my clients were small
organizations just getting started on the web, they inevitably
would ask me what kind of high-powered server they would need. My clients
were all convinced that they were going to be incredibly popular and
important, and that they would have lots of visitors coming to their
websites&mdash;and it was important that their sites would be able to stand up
under this load.
</p><p>
I would remind them that each day has 86,400 seconds. This means that
if one new person visits their site each second, the server will need
to handle 86,400 requests per day&mdash;a trivial number, for most modern
computers, especially if you're just serving up static files.
</p><p>
I would then ask, do they really expect to get more than 86,000
visitors per day? The client would almost inevitably answer, somewhat
sheepishly, &ldquo;No, definitely not.&rdquo;
</p><p>
Now, I knew that my clients didn't need to worry about the size or
speed of their servers; I really did have their best interests at
heart, and I was trying to convince them, in a somewhat dramatic way,
that they didn't need to spend money on a new server. But I did take
certain liberties with the truth when I presented those numbers&mdash;for
example:
</p><div class="itemizedlist"><ul type="disc"><li><p>
There's a difference between 86,400 visitors in one day, spread out
evenly across the entire day, and a spike during lunch hour, when
many people do their shopping and leisure reading.
</p></li><li><p>
Web pages that contain CSS, JavaScript and images&mdash;which is all
of them, in the modern era&mdash;require more than one HTTP request for
each page load. Even if you have 10,000 visitors, you might well
have more than 100,000 HTTP requests to your server.
</p></li><li><p>
When a simple web site becomes a web application, you need to start
worrying about the speed of back-end databases and third-party
services, as well as the time it takes to compute certain things.
</p></li></ul></div><p>
So, what do you in such cases? If you can handle precisely one
request per second, what happens if more than one person visits
your site at the same time? You could make one of them wait until the
other is finished and then service the next one, but if you have 10
or 15 simultaneous requests, that tactic eventually will backfire on
you.
</p><p>
In most modern systems, the solution has been to take advantage of
multiprocessing: have the computer do more than one thing at a time.
If a computer can do two things each second, and if your visitors are
spread out precisely over the course of a day, then you can handle
172,800 visitors. And if you can do three things at a time, you 
suddenly can handle 259,200 visitors&mdash;and so forth.
</p><p>
How can a computer do more than one thing at a time? With a single
CPU, each process gets a &ldquo;time slice&rdquo;, meaning one fraction of the
time that the CPU is working. If you have ten processes, and each gets
an equal time slice, then each will run once per second for 0.1
seconds. As you increase the number of processes, the time allocated
to each process goes down.
</p><p>
Modern computers come with multiple CPUs (aka &ldquo;cores&rdquo;), which means
that they actually can do things in parallel, rather than simply
give each process a time slice on the system's single processor. In
theory, a dual-core system with ten processes will run each process
once per second for 0.2 seconds, divided across the processors.
</p><p>
Scaling is never perfectly linear, so you can't really predict things
in that way, but it's not a bad way to think about this.
</p><p>
Processes, as described here, are a great way for the computer to do
more than one thing at a time. And yet, many applications have other
ways of dealing with concurrency. Two of the most popular
alternatives to processes are threads and the reactor pattern,
especially popular and well known in node.js and the nginx HTTP
server.
</p><p>
So in this article, I explore the different types of multiprocessing that
exist,
looking at the advantages and disadvantages of each one. Even
if you're not interested in switching, it's useful to know what is out
there.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2779580.0x2871cf8"></a>
Processes</h2></div></div><p>
The idea behind a process is fairly simple. A running program consists
of not only executing code, but also data and some context. Because
the code, data and context all exist in memory, the operating system
can switch from one process to another very quickly. This combination
of code + data + context is known as a &ldquo;process&rdquo;, and it's the basis
for how Linux systems work.
</p><p>
When you start your Linux box, it has a single process. That process
then &ldquo;forks&rdquo; itself, such that two identical processes are running.
The second (&ldquo;child&rdquo;) process reads new code, data and context
(&ldquo;exec&rdquo;), and thus starts running a new process. This continues
throughout the time that a system is running. When you execute a new
program on the command line with &amp; at the end of the line, you're
forking the shell process and then exec'ing your desired program in its
place.
</p><p>
The Apache httpd server, which is extremely popular and standard on
many Linux systems, works by default on a process model. You might
think that when a new request comes in, Apache will start up a new
process to handle it. But starting it up takes some time, and no one
wants to wait for it to happen. The solution is, thus, to
&ldquo;prefork&rdquo; a
bunch of servers. This way, when a new request arrives, Apache can
hand off that request to a process. When Apache sees that you're
running low on processes, it will add a bunch to the pool, ensuring
that there are always enough spare servers. If you reach the limit,
things start to cause problems for users,
</p><p>
In many cases, the process model is great. Linux is great at launching
processes; it's a fairly low-cost operation, and one that a typical
system does hundreds or even thousands of times every hour. Moreover,
the kernel developers have learned through the years how to do things
intelligently, such that a forked process uses (and writes to)
its own memory only when it needs to; until that time, it continues to use
memory from its parent process.
</p><p>
Moreover, processes are extremely stable and secure. Memory owned by
one process is typically not visible to other processes, let alone
writable by other processes. And if a process goes down, it shouldn't
take the entire system down with it.
</p><p>
So, what's not to like? Processes are great, no?
</p><p>
Yes, but they also require a fair amount of overhead. If all you're
doing is serving up some files, or doing a tiny amount of processing,
using a full process for that might seem excessive.
</p><p>
Moreover, if you're doing a number of related tasks that are using the
same memory, the fact that every process keeps data separate might
make things safe, but also more of a memory hog.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2779580.0x2872278"></a>
Threads</h2></div></div><p>
People coming from a Windows or Java background often scoff at the
UNIX tradition of using processes. They say that processes are too
heavy for most things, and that you would be better off using threads
instead. A thread is similar to a process, except that it exists
inside a process.
</p><p>
Just as a computer splits its time across different processes, giving
each one a time slice, a process splits its time across different
threads, giving each one a time slice.
</p><p>
Because threads exist within an existing process, their startup time
is much faster. And because threads share memory with other threads in
the process, they consume less memory and are more efficient.
</p><p>
The fact that threads share memory can lead to all sorts of
problematic situations. How do you ensure that two different threads
aren't modifying the same data at the same time? How do you ensure that
your threads execute in the appropriate order&mdash;or, how do you make
sure that the order isn't actually that important? There are all
sorts of issues associated with threading, and people who work with
threads know them all too well. The benefits of threads are obvious,
but ensuring that they work, and work correctly, can be quite
frustrating. Indeed, people who grew up using processes find threads
to be fraught with danger and complexity, and they do whatever they can to
avoid them.
</p><p>
As a general rule, people with a Microsoft technology background use
threads all of the time, starting up a new process only when
necessary. By contrast, starting a new process in the Microsoft world
takes a long time. People with a UNIX background, meanwhile, think
that starting a new process is the easiest and safest thing to do, and
they tend to shy away from threads.
</p><p>
Which is the right answer? It all depends. You probably can squeeze
more performance out of your computer if you use threads, but at the
same time, you can be sure that the code is written in a way that
takes advantage of the threads, and it doesn't fall into any of the
common traps.
</p><p>
What if you want to use threads, rather than processes, with your
Apache server? Years ago, the Apache httpd developers realized that
it was foolish for them to push a single model upon their users. For
some, and especially for people using Windows, threads were
preferable. For many, the traditional processes were preferable. And
in some cases, it wasn't obvious which would be better without first
doing some benchmarking.
</p><p>
The solution was something known as an MPM (multi-processing
module). You can choose the traditional &ldquo;pre-fork&rdquo; MPM, typically
used on UNIX. You can use the &ldquo;worker&rdquo; MPM, which is a combination of
processes and threads. If you're on Windows, there's a special
&ldquo;mpm_winnt&rdquo; MPM, which uses a single process and many threads.
</p><p>
The &ldquo;worker&rdquo; MPM is perhaps the most interesting of the bunch, in that
it allows you to control the maximum number of processes (with the
<tt  >MaxClients</tt> directive), but also a number of threads per process (with
the <tt  >ThreadsPerChild</tt> directive). You then can experiment with the
optimal configuration for your server, deciding which mixture of
processes and threads is going to give you the best performance.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2779580.0x28728a8"></a>
An Old-New Idea</h2></div></div><p>
During the last few years, a number of network applications have
re-discovered a way of writing code that seems counter to all of these
ideas. Instead of having multiple processes, or multiple threads, just
have a single process, without any threads. That process then
can handle all of the incoming network traffic.
</p><p>
At first blush, that sounds a bit crazy. Why keep everything together
in a single process?
</p><p>
But, then consider the fact that even on a highly optimized Linux
system, there is still some overhead to the &ldquo;context switch&rdquo;, moving
from one process to another. This overhead is repeated at a smaller
level within a process, when you switch from thread to thread.
</p><p>
If you handle all of the incoming network requests within a single
process, you avoid all of those context switches. You can do that
by having an event loop, and then by hanging functions on that event
loop. If your event loop contains functions A, B and C, the
system gives A a chance to run, then B, then C and then A again.
With each opportunity provided by the event loop, you find that A, B
and C each progress forward a bit each time.
</p><p>
This actually works quite well, and it has been demonstrated to scale
better than processes and threads. What's the problem then?
</p><p>
First of all, the code needs to be written in such a way that it can
be divided into functions and put into an event loop. Thinking this
way, and writing this style of code, is different from what people
typically are used to in the procedural and object-oriented worlds. In
many ways, it's like creating a callback function, in that you don't
know quite when it'll run.
</p><p>
Among other things, you need to be super careful when working with I/O
in this kind of function. That's because disks and networks are
extremely slow, and if function B is reading from the disk, then it's
waiting idly while neither A nor C has a chance to run. Working with
I/O thus requires special handling.
</p><p>
This is part of a bigger issue, namely that modern operating systems
use &ldquo;pre-emptive multitasking&rdquo;, telling each process when its time
slice has expired. The reactor pattern uses &ldquo;cooperative
multitasking&rdquo;, in that a rogue function can hog the CPU simply
by failing to abide by the rules.
</p><p>
This paradigm is known as the &ldquo;reactor pattern&rdquo; and underlies the
nginx HTTP server, node.js, Twisted Python and the new asyncio
libraries in Python. It has proven itself, but it does require that
developers think in new and different ways.
</p><p>
Not to be outdone by nginx, Apache now has an &ldquo;event&rdquo; MPM, which
handles things using this method. So if you're a fan of Apache and
want to try out the reactor pattern without switching to nginx, you
can do so. If you're simply using the server and connecting to an
external application, rather than writing code that will be embedded
within Apache, the MPM will affect performance, but not how you write your
application.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2779580.0x2c6b128"></a>
Conclusion</h2></div></div><p>
So, where does this leave you? First of all, it means you have a
number of options. It also means that when you start to worry about
performance&mdash;and only then&mdash;you can start to run experiments to
compare the different paradigms and how they work.
</p><p>
But it also means that in today's highly networked world, you might
want to consider one or more of these options right away. At the very
least, you should be familiar with them and how they work, and the
trade-offs associated with them. In particular, while the reactor
pattern can be hard to understand, such understanding will make it
easier to design architectures that will scale&mdash;especially when you
truly need it.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2779580.0x2c6b288"></a></h2></div></div><div class="sidebar"><p class="title"><b></b></p><p>Send comments or feedback via <a href="http://www.linuxjournal.com/contact" target="_self">www.linuxjournal.com/contact</a> or to
<a href="mailto:info@linuxjournal.com">info@linuxjournal.com</a>.
</p></div></div></div>
<div class="authorblurb"><p>
Reuven M. Lerner, a longtime web developer, offers training and consulting
services in Python, Git, PostgreSQL and data science. He has written
two programming ebooks (<span   class="emphasis"><em>Practice Makes Python</em></span> and
<span   class="emphasis"><em>Practice Makes
Regexp</em></span>) and publishes a free weekly newsletter for programmers,
at
<a href="http://lerner.co.il/newsletter" target="_self">lerner.co.il/newsletter</a>. Reuven tweets at
@reuvenmlerner and
lives in Modi'in, Israel, with his wife and three children.

</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../281/toc281.html">Issue Table of Contents</a>
    <a class="link3" href="../281/12222.html">Article</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>