<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
Docker: Lightweight Linux Containers for Consistent Development and Deployment
</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;Take on dependency hell with Docker containers, the lightweight and nimble cousin&#10;of VMs. Learn how Docker makes applications portable and isolated by packaging them&#10;in containers based on LXC technology.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x1f5e580.0x2055ac0"></a>
Docker: Lightweight Linux Containers for Consistent Development and Deployment
</h1></div><div><div class="author"><h3 class="author">
Dirk
 
Merkel
</h3></div><div class="issuemoyr">Issue #239, March 2014</div></div><div><p>
Take on &ldquo;dependency hell&rdquo; with Docker containers, the lightweight and nimble cousin
of VMs. Learn how Docker makes applications portable and isolated by packaging them
in containers based on LXC technology.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1f5e580.0x2056250"></a></h2></div></div><p>
Imagine being able to package an application along with all of
its dependencies easily and then run it smoothly in disparate development, test
and production environments. That is the goal of the open-source Docker
project. Although it is still not officially production-ready, the latest
release (0.7.x at the time of this writing) brought Docker another step closer to realizing this
ambitious goal.
</p><p>
Docker tries to solve the problem of &ldquo;dependency hell&rdquo;. Modern
applications often are assembled from existing components and rely on
other services and applications. For example, your Python application
might use PostgreSQL as a data store, Redis for caching and Apache
as a Web server. Each of these components comes with its own set of
dependencies that may conflict with those of other components. By
packaging each component and its dependencies, Docker solves the
following problems:
</p><div class="itemizedlist"><ul type="disc"><li><p>
Conflicting dependencies: need to run one Web site on PHP 4.3 and
another on PHP 5.5? No problem if you run each version of PHP in a
separate Docker container.
</p></li><li><p>
Missing dependencies: installing applications in a new environment is
a snap with Docker, because all dependencies are packaged along with the
application in a container.
</p></li><li><p>
Platform differences: moving from one distro to another is no longer
a problem. If both systems run Docker, the same container will execute
without issues.
</p></li></ul></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1f5e580.0x2056720"></a>
Docker: a Little Background</h2></div></div><p>
Docker started life as an open-source project at dotCloud, a cloud-centric
platform-as-a-service company, in early 2013. Initially, Docker was a
natural extension of the technology the company had developed to run its
cloud business on thousands of servers. It is written in Go, a statically
typed programming language developed by Google with syntax loosely based
on C. Fast-forward six to nine months, and the company has hired a new
CEO, joined the Linux Foundation, changed its name to Docker Inc., and
announced that it is shifting its focus to the development of Docker and
the Docker ecosystem. As further indication of Docker's popularity, at
the time of this writing, it has been starred on GitHub 8,985 times and
has been forked 1,304 times. Figure 1 illustrates Docker's rising
popularity in Google searches. I predict that the shape of the past 12
months will be dwarfed by the next 12 months as Docker Inc. delivers
the first version blessed for production deployments of containers and
the community at large becomes aware of Docker's usefulness.
</p><div       class="mediaobject"><a href="11600f1.large.jpg"><img src="11600f1.jpg"></a><div class="caption"><p>
Figure 1. Google Trends Graph for &ldquo;Docker Software&rdquo; for Past
12 Months
</p></div></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1f5e580.0x2056a90"></a>
Under the Hood</h2></div></div><p>
Docker harnesses some powerful kernel-level technology and puts it
at our fingertips. The concept of a container in virtualization has
been around for several years, but by providing a simple tool set and
a unified API for managing some kernel-level technologies, such as LXCs
(LinuX Containers), cgroups and a copy-on-write filesystem, Docker has
created a tool that is greater than the sum of its parts. The result is a
potential game-changer for DevOps, system administrators and developers.
</p><p>
Docker provides tools to make creating and working with containers as easy
as possible. Containers sandbox processes from each other. For now, you
can think of a container as a lightweight equivalent of a virtual machine.
</p><p>
Linux Containers and LXC, a user-space control package for Linux
Containers, constitute the core of Docker. LXC uses kernel-level
namespaces to isolate the container from the host. The user namespace
separates the container's and the host's user database, thus ensuring
that the container's root user does not have root privileges on the
host. The process namespace is responsible for displaying and managing
only processes running in the container, not the host. And, the network
namespace provides the container with its own network device and virtual
IP address.
</p><p>
Another component of Docker provided by LXC are Control Groups
(cgroups). While namespaces are responsible for isolation between
host and container, control groups implement resource accounting and
limiting. While allowing Docker to limit the resources being consumed by
a container, such as memory, disk space and I/O, cgroups also output
lots of metrics about these resources. These metrics allow Docker to
monitor the resource consumption of the various processes within the
containers and make sure that each gets only its fair share of the
available resources.
</p><p>
In addition to the above components, Docker has been using AuFS
(Advanced Multi-Layered Unification Filesystem) as a filesystem for
containers. AuFS is a layered filesystem that can transparently overlay
one or more existing filesystems. When a process needs to modify a file,
AuFS creates a copy of that file. AuFS is capable of merging multiple
layers into a single representation of a filesystem. This process is
called copy-on-write.
</p><p>
The really cool thing is that AuFS allows Docker to use certain images as
the basis for containers. For example, you might have a CentOS Linux
image that can be used as the basis for many different containers. Thanks
to AuFS, only one copy of the CentOS image is required, which results
in savings of storage and memory, as well as faster deployments of
containers.
</p><p>
An added benefit of using AuFS is Docker's ability to version container
images. Each new version is simply a diff of changes from the previous
version, effectively keeping image files to a minimum. But, it also means
that you always have a complete audit trail of what has changed from one
version of a container to another.
</p><p>
Traditionally, Docker has depended on AuFS to provide a copy-on-write
storage mechanism. However, the recent addition of a storage driver API
is likely to lessen that dependence. Initially, there are three storage
drivers available: AuFS, VFS and Device-Mapper, which is the result of
a collaboration with Red Hat.
</p><p>
As of version 0.7, Docker works with all Linux distributions. However, it
does not work with most non-Linux operating systems, such as Windows and
OS X. The recommended way of using Docker on those OSes is to provision
a virtual machine on VirtualBox using Vagrant.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1f5e580.0x2056eb0"></a>
Containers vs. Other Types of Virtualization</h2></div></div><p>
So what exactly is a container and how is it different from
hypervisor-based virtualization? To put it simply, containers virtualize
at the operating system level, whereas hypervisor-based solutions
virtualize at the hardware level. While the effect is similar, the
differences are important and significant, which is why I'll spend
a little time exploring the differences and the resulting differences
and trade-offs.
</p><p><span   class="bold"><b>
Virtualization:</b></span>
</p><p>
Both containers and VMs are virtualization tools. On the VM side, a
hypervisor makes siloed slices of hardware available. There are generally
two types of hypervisors: &ldquo;Type 1&rdquo; runs directly on the bare metal of the
hardware, while &ldquo;Type 2&rdquo; runs as an additional layer of software within
a guest OS. While the open-source Xen and VMware's ESX are examples
of Type 1 hypervisors, examples of Type 2 include Oracle's open-source
VirtualBox and VMware Server. Although Type 1 is a better candidate for
comparison to Docker containers, I don't make a distinction between
the two types for the rest of this article.
</p><p>
Containers, in contrast, make available protected portions of the
operating system&mdash;they effectively virtualize the operating system. Two
containers running on the same operating system don't know that they are
sharing resources because each has its own abstracted networking layer,
processes and so on.
</p><p><span   class="bold"><b>
Operating Systems and Resources:</b></span>
</p><p>
Since hypervisor-based virtualization provides access to hardware only,
you still need to install an operating system. As a result, there
are multiple full-fledged operating systems running, one in each VM,
which quickly gobbles up resources on the server, such as RAM, CPU
and bandwidth.
</p><p>
Containers piggyback on an already running operating system as their host
environment. They merely execute in spaces that are isolated from each
other and from certain parts of the host OS. This has two significant
benefits. First, resource utilization is much more efficient. If a
container is not executing anything, it is not using up resources, and
containers can call upon their host OS to satisfy some or all of their
dependencies. Second, containers are cheap and therefore fast to create
and destroy. There is no need to boot and shut down a whole OS. Instead,
a container merely has to terminate the processes running in its isolated
space. Consequently, starting and stopping a container is more akin to
starting and quitting an application, and is just as fast.
</p><p>
Both types of virtualization and containers are illustrated in Figure 2.
</p><div       class="mediaobject"><a href="11600f1.large.jpg"><img src="11600f1.jpg"></a><div class="caption"><p>
Figure 2. VMs vs. Containers
</p></div></div><p><span   class="bold"><b>
Isolation for Performance and Security:</b></span>
</p><p>
Processes executing in a Docker container are isolated from processes
running on the host OS or in other Docker containers. Nevertheless,
all processes are executing in the same kernel. Docker leverages LXC to
provide separate namespaces for containers, a technology that has been
present in Linux kernels for 5+ years and is considered fairly mature. It
also uses Control Groups, which have been in the Linux kernel even longer,
to implement resource auditing and limiting.
</p><p>
The Docker d&aelig;mon itself also poses a potential attack vector because
it currently runs with root privileges. Improvements to both LXC and
Docker should allow containers to run without root privileges and to
execute the Docker d&aelig;mon under a different system user.
</p><p>
Although the type of isolation provided is overall quite strong,
it is arguably not as strong as what can be enforced by virtual
machines at the hypervisor level. If the kernel goes down, so do all
the containers. The other area where VMs have the advantage is their
maturity and widespread adoption in production environments. VMs have
been hardened and proven themselves in many different high-availability
environments. In comparison, Docker and its supporting technologies have
not seen nearly as much action. Docker in particular is undergoing massive
changes every day, and we all know that change is the enemy of security.
</p><p><span   class="bold"><b>
Docker and VMs&mdash;Frenemies:</b></span>
</p><p>
Now that I've spent all this time comparing Docker and VMs, it's time
to acknowledge that these two technologies can actually complement each
other. Docker runs just fine on already-virtualized environments. You
obviously don't want to incur the cost of encapsulating each application
or component in a separate VM, but given a Linux VM, you can easily
deploy Docker containers on it. That is why it should not come as a
surprise that the officially supported way of using Docker on non-Linux
systems, such as OS X and Windows, is to install a Precise64 base Ubuntu
virtual machine with the help of Vagrant. Simple detailed instructions
are provided on the <a href="http://www.docker.io" target="_self">www.docker.io</a> site.
</p><p>
The bottom line is that virtualization and containers exhibit
some similarities. Initially, it helps to think of containers as
very lightweight virtualization. However, as you spend more time
with containers, you come to understand the subtle but important
differences. Docker does a nice job of harnessing the benefits of
containerization for a focused purpose, namely the lightweight packaging
and deployment of applications.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1f5e580.0x20578a8"></a>
Docker Repositories</h2></div></div><p>
One of Docker's killer features is the ability to find, download
and start container images that were created by other developers quickly. The
place where images are stored is called a registry, and Docker Inc. offers
a public registry also called the Central Index. You can think of the
registry along with the Docker client as the equivalent of Node's NPM,
Perl's CPAN or Ruby's RubyGems.
</p><p>
In addition to various base images, which you can use to create your
own Docker containers, the public Docker Registry features images
of ready-to-run software, including databases, content management
systems, development environments, Web servers and so on. While the Docker
command-line client searches the public Registry by default, it is
also possible to maintain private registries. This is a great option
for distributing images with proprietary code or components internally
to your company. Pushing images to the registry is just as easy as
downloading. It requires you to create an account, but that is free
as well. Lastly, Docker Inc.'s registry has a Web-based interface for
searching for, reading about, commenting on and recommending (aka
&ldquo;starring&rdquo;) images. It is ridiculously easy to use, and I encourage you
to click the link in the Resources section of this article and start exploring.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1f5e580.0x2057ab8"></a>
Hands-On with Docker</h2></div></div><p>
Docker consists of a single binary that can be run in one of
three different ways. First, it can run as a d&aelig;mon to manage the
containers. The d&aelig;mon exposes a REST-based API that can be accessed
locally or remotely. A growing number of client libraries are available
to interact with the d&aelig;mon's API, including Ruby, Python, JavaScript
(Angular and Node), Erlang, Go and PHP.
</p><p>
The client libraries are great for accessing the d&aelig;mon programmatically,
but the more common use case is to issue instructions from the command
line, which is the second way the Docker binary can be used, namely as
a command-line client to the REST-based d&aelig;mon.
</p><p>
Third, the Docker binary functions as a client to remote repositories
of images. Tagged images that make up the filesystem for a container
are called repositories. Users can pull images provided by others and
share their own images by pushing them to the registry. Registries are
used to collect, list and organize repositories.
</p><p>
Let's see all three ways of running the docker executable in action. In
this example, you'll search the Docker repository for a MySQL image. Once
you find an image you like, you'll download it, and tell the Docker
d&aelig;mon
to run the command (MySQL). You'll do all of this from the command line.
</p><div       class="mediaobject"><a href="11600f3.large.jpg"><img src="11600f3.jpg"></a><div class="caption"><p>
Figure 3. Pulling a Docker Image and Launching a Container
</p></div></div><p>
Start by issuing the <tt  >docker search mysql</tt> command, which then displays
a list of images in the public Docker registry that match the keyword
&ldquo;mysql&rdquo;. For no particular reason other than I know it works, let's
download the &ldquo;brice/mysql&rdquo; image, which you do with the
<tt  >docker pull
brice/mysql</tt> command. You can see that Docker downloaded not only the
specified image, but also the images it was built on. With the <tt  >docker
images</tt> command, you list the images currently available locally, which
includes the &ldquo;brice/mysql&rdquo; image. Launching the container with the
<tt  >-d</tt>
option to detach from the currently running container, you now have MySQL
running in a container. You can verify that with the <tt  >docker
ps</tt> command,
which lists containers, rather than images. In the output, you also see
the port on which MySQL is listening, which is the default of 3306.
</p><p>
But, how do you connect to MySQL, knowing that it is running inside
a container? Remember that Docker containers get their own network
interface. You need to find the IP address and port at which the mysqld
server process is listening. The <tt  >docker inspect
&lt;imageId&gt;</tt> provides a
lot of info, but since all you need is the IP address, you can just grep for
that when inspecting the container by providing its hash <tt  >docker inspect
5a9005441bb5 | grep IPAddress</tt>. Now you can connect with the standard MySQL
CLI client by specifying the host and port options. When you're done with
the MySQL server, you can shut it down with <tt  >docker stop
5a9005441bb5</tt>.
</p><p>
It took seven commands to find, download and launch a Docker container
to get a MySQL server running and shut it down after you're done. In
the process, you didn't have to worry about conflicts with installed
software, perhaps a different version of MySQL, or dependencies. You
used seven different Docker commands: search, pull, images, run, ps,
inspect and stop, but the Docker client actually offers 33 different
commands. You can see the full list by running <tt  >docker
help</tt> from the
command line or by consulting the on-line manual.
</p><p>
Before exercising Docker in the above example, I mentioned that
the client communicates with the d&aelig;mon and the Docker Registry via
REST-based Web services. That implies that you can use a local Docker
client to interact with a remote d&aelig;mon, effectively administering
your containers on a remote machine. The APIs for the Docker d&aelig;mon,
Registry and Index are nicely documented, illustrated with examples
and available on the Docker site (see Resources).
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1f5e580.0x2450650"></a>
Docker Workflow</h2></div></div><p>
There are various ways in which Docker can be integrated into the
development and deployment process. Let's take a look at a sample workflow
illustrated in Figure 4. A developer in our hypothetical company
might be running Ubuntu with Docker installed. He might push/pull Docker
images to/from the public registry to use as the base for installing his
own code and the company's proprietary software and produce images that
he pushes to the company's private registry.
</p><p>
The company's QA environment in this example is running CentOS and
Docker. It pulls images from the public and private registries and starts
various containers whenever the environment is updated.
</p><p>
Finally, the company hosts its production environment in the cloud,
namely on Amazon Web Services, for scalability and elasticity. Amazon
Linux is also running Docker, which is managing various containers.
</p><p>
Note that all three environments are running different versions of Linux,
all of which are compatible with Docker. Moreover, the environments are
running various combinations of containers. However, since each container
compartmentalizes its own dependencies, there are no conflicts, and all
the containers happily coexist.
</p><div       class="mediaobject"><a href="11600f4.large.jpg"><img src="11600f4.jpg"></a><div class="caption"><p>
Figure 4. Sample Software Development Workflow Using Docker
</p></div></div><p>
It is crucial to understand that Docker promotes an application-centric
container model. That is to say, containers should run individual
applications or services, rather than a whole slew of them. Remember that
containers are fast and resource-cheap to create and run. Following the
single-responsibility principle and running one main process per container
results in loose coupling of the components of your system. With that in
mind, let's create your own image from which to launch a container.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1f5e580.0x2450a70"></a>
Creating a New Docker Image</h2></div></div><p>
In the previous example, you interacted with Docker from the command
line. However, when creating images, it is far more common to create a
&ldquo;Dockerfile&rdquo; to automate the build process. Dockerfiles are simple text
files that describe the build process. You can put a Dockerfile under
version control and have a perfectly repeatable way of creating an image.
</p><p>
For the next example, please refer to the &ldquo;PHP Box&rdquo; Dockerfile
(Listing 1).

</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1f5e580.0x2450cd8"></a></h2></div></div><div class="sidebar"><p class="title"><b>Listing 1. PHP Box</b></p><pre     class="programlisting">
# PHP Box
#
# VERSION 1.0

# use centos base image
FROM centos:6.4

# specify the maintainer
MAINTAINER Dirk Merkel, dmerkel@vivantech.com

# update available repos
RUN wget http://dl.fedoraproject.org/pub/epel/6/x86_64/
&#8618;epel-release-6-8.noarch.rpm; rpm -Uvh epel-release-6-8.noarch.rpm

# install some dependencies
RUN yum install -y curl git wget unzip

# install Apache httpd and dependencies
RUN yum install -y httpd

# install PHP and dependencies
RUN yum install -y php php-mysql

# general yum cleanup
RUN yum install -y yum-utils
RUN package-cleanup --dupes; package-cleanup --cleandupes; 
 &#8618;yum clean -y all

# expose mysqld port
EXPOSE 80

# the command to run
CMD ["/usr/sbin/apachectl", "-D", "FOREGROUND"]
</pre></div><p>
Let's take a closer look at what's going on in this Dockerfile. The syntax
of a Dockerfile is a command keyword followed by that command's
argument(s). By convention, command keywords are capitalized. Comments
start with a pound character.
</p><p>
The FROM keyword indicates which image to use as a base. This must be
the first instruction in the file. In this case, you will build on top of
the latest CentOS base image. The <tt  >MAINTAINER</tt> instruction obviously lists
the person who maintains the Dockerfile. The <tt  >RUN</tt> instruction executes a
command and commits the resulting image, thus creating a new layer. The
<tt  >RUN</tt> commands in the Dockerfile fetch configuration files for additional
repositories and then use Yum to install curl, git, wget, unzip, httpd,
php-mysql and yum-utils. I could have combined the <tt  >yum
install</tt>
commands into a single <tt  >RUN</tt> instruction to avoid successive commits.
</p><p>
The <tt  >EXPOSE</tt> instruction then exposes port 80, which is the port on which
Apache will be listening when you start the container.
</p><p>
Finally, the <tt  >CMD</tt> instruction will provide the default command to run when
the container is being launched. Associating a single process with the
launch of the container allows you to treat a container as a command.
</p><p>
Typing <tt  >docker build -t php_box .</tt> on the command line will now tell
Docker to start the build process using the Dockerfile in the current
working directory. The resulting image will be tagged
&ldquo;php_box&rdquo;, which
will make it easier to refer to and identify the image later.
</p><p>
The build process downloads the base image and then installs Apache
httpd along with all dependencies. Upon completion, it returns a hash
identifying the newly created image. Similar to the MySQL container you
launched earlier, you can run the Apache and PHP image using the
&ldquo;php_box&rdquo;
tag with the following command line: <tt  >docker run -d -t
php_box</tt>.
</p><p>
Let's finish with a quick example that illustrates how easy it is to
layer on top of an existing image to create a new one:

<pre     class="programlisting">
# MyApp
#
# VERSION       1.0

# use php_box base image
FROM php_box

# specify the maintainer
MAINTAINER Dirk Merkel, dmerkel@vivantech.com

# put my local web site in myApp folder to /var/www
ADD myApp /var/www
</pre>
</p><p>
This second Dockerfile is shorter than the first and really contains
only two interesting instructions. First, you specify the
&ldquo;php_box&rdquo; image as
a starting point using the <tt  >FROM</tt> instruction. Second,
you copy a local
directory to the image with the <tt  >ADD</tt> instruction. In this case, it is
a PHP project that is being copied to Apache's DOCUMENT_ROOT folder on
the images. The result is that the site will be served by default when
you launch the image.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1f5e580.0x24516d0"></a>
Conclusion</h2></div></div><p>
Docker's prospect of lightweight packaging and deploying of applications
and dependencies is an exciting one, and it is quickly being
adopted by the Linux community and is making its way into production
environments. For example, Red Hat announced in December support for
Docker in the upcoming Red Hat Enterprise Linux 7. However, Docker is
still a young project and is growing at breakneck speed. It is going to
be exciting to watch as the project approaches its 1.0 release, which is
supposed to be the first version officially sanctioned for production
environments. Docker relies on established technologies, some of which
have been around for more than a decade, but that doesn't make it any less
revolutionary. Hopefully this article provided you with enough information
and inspiration to download Docker and experiment with it yourself.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1f5e580.0x24517d8"></a></h2></div></div><div class="sidebar"><p class="title"><b>Docker Update</b></p><p>
As this article was being published, the Docker team announced the release
of version 0.8. This latest deliverable adds support for Mac OS X
consisting of two components. While the client runs natively on OS X, the
Docker d&aelig;mon runs inside a lightweight VirtualBox-based VM that is
easily managed with boot2docker, the included command-line client. This
approach is necessary because the underlying technologies, such as LXC and
name spaces, simply are not supported by OS X. I think we can expect a
similar solution for other platforms, including Windows.
</p><p>
Version 0.8 also introduces several new builder features and experimental
support for BTRFS (B-Tree File System). BTRFS is another copy-on-write
filesystem, and the BTRFS storage driver is positioned as an alternative to
the AuFS driver.
</p><p>
Most notably, Docker 0.8 brings with it many bug fixes and performance
enhancements. This overall commitment to quality signals an effort by the
Docker team to produce a version 1.0 that is ready to be used in production
environments. With the team committing to a monthly release cycle, we can
look forward to the 1.0 release in the April to May timeframe. 
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1f5e580.0x2451a98"></a></h2></div></div><div class="sidebar"><p class="title"><b>
Resources</b></p><p>
Main Docker Site: <a href="https://www.docker.io" target="_self">https://www.docker.io</a>
</p><p>
Docker Registry: <a href="https://index.docker.io" target="_self">https://index.docker.io</a>
</p><p>
Docker Registry API: <a href="http://docs.docker.io/en/latest/api/registry_api" target="_self">docs.docker.io/en/latest/api/registry_api</a>
</p><p>
Docker Index API: <a href="http://docs.docker.io/en/latest/api/index_api" target="_self">docs.docker.io/en/latest/api/index_api</a>
</p><p>
Docker Remote API: <a href="http://docs.docker.io/en/latest/api/docker_remote_api" target="_self">docs.docker.io/en/latest/api/docker_remote_api</a>
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1f5e580.0x2451fc0"></a></h2></div></div><div class="sidebar"><p class="title"><b></b></p><p>Send comments or feedback via <a href="http://www.linuxjournal.com/contact" target="_self">www.linuxjournal.com/contact</a> or to
<a href="mailto:info@linuxjournal.com">info@linuxjournal.com</a>.
</p></div></div></div>
<div class="authorblurb"><p>
Dirk Merkel has experience architecting solutions and managing the
software development process in large and small organizations. His focus
is on open source and often Web-centric technologies, including Java,
PHP, Perl, Ruby, MySQL, Apache and so on. He is the CTO for Vivantech Inc.
</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../239/toc239.html">Issue Table of Contents</a>
    <a class="link3" href="../239/11600.html">Article</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>