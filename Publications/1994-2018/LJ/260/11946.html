<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
Work the Shell
</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;Introducing FIX-CSV, a script to analyze and fix errors in comma-separated values (CSV)&#10;files, so Dave finally can do his taxes. No, really. Read on!&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x206a580.0x2161ac0"></a>
Work the Shell
</h1></div><div><h3 class="subtitle"><i>
Analyzing Comma-Separated Values (CSV) Files
</i></h3></div><div><div class="author"><h3 class="author">
Dave
 
Taylor
</h3></div><div class="issuemoyr">Issue #260, December 2015</div></div><div><p>
Introducing FIX-CSV, a script to analyze and fix errors in comma-separated values (CSV)
files, so Dave finally can do his taxes. No, really. Read on!
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x206a580.0x2162358"></a></h2></div></div><p>
Ugh. I've been working on my taxes. I know, it's a bit weird to be doing
my taxes in the autumn, but if you defer and file an extension with the IRS every
year, well, then you're used to tax time being September/October, not April
15th. 
</p><p>
I have a very old-school, geeky way of preparing for my own taxes, and it involves
using an Excel spreadsheet to enter all my line item expenses then normalizing
and cleaning up the data. When that's all done, which typically involves a
lot of sorting and re-sorting of the data, I then export it all as a comma-separated
values data file and pull out a Linux shell script to analyze and summarize
expenses by category.
</p><p>
I suppose I could do that in the spreadsheet program itself, but it either
would involve me having to learn the spreadsheet's programming language (for example,
Visual Basic in Microsoft Excel 2016) or manually click-dragging series of cells
to summarize their values. Both are tedious, and however peculiar my solution, the
idea of actually learning Visual Basic just boggles my mind, so that's just
not an option.
</p><p>
But, there's a lurking problem in the CSV format I
use, and to understand it, I need to dig in to exactly what's being
formatted.
</p><p>
A typical expense entry has four fields: date, category, amount and any detailed
notes or comments. For example:

<pre     class="programlisting">
4/10/15   subscriptions   19.99    Linux Journal
</pre>
</p><p>
All of it's neatly organized in columns and data cells, as befits a
spreadsheet, of course.
</p><p>
<span   class="emphasis"><em>Random aside: did you know that it was a spreadsheet that proved the viability of
the personal computer back in the day? VisiCalc was the groundbreaking app with
its sophisticated interface (for the day, at least) and ability for accountants
and business folk to create sophisticated mathematical tables and regular people
to...balance their checkbooks. Yes, one of the killer apps for
the very first generation of PC was checkbook balancing. We've come a long
way!</em></span>
</p><p>
With a spreadsheet populated with these four fields, the easiest way to create a
dataset for further work is to export it as comma-separated values, the
&ldquo;CSV&rdquo; format. Here's how that particular line will be exported:

<pre     class="programlisting">
4/10/14,subscriptions,19.99,Linux Journal
</pre>
</p><p>
Not too bad, and it's easily managed by changing the field separator to a comma. For
example, to extract just the numeric value: <tt  >cut -d, -f3</tt>.
</p><p>
In fact, once the output is sorted by category, it's a simple awk script to
read the CSV file line by line, testing each category against the previous and
summing up values as it goes:

<pre     class="programlisting">
BEGIN { sum=0; category=""; FS="," }
{ if ( $2 != category ) {
    if ( sum &gt; 0 ) { print category," == ",sum; }
    sum=$3
  }
  else { 
    sum+=$3 
  }
  category=$2
}
END { print category, " == ", sum }
</pre>
</p><p>
Awk scripts are blocks of code that match specified regular expressions, although
all three of the above blocks are somewhat special cases. The first,
<tt  >BEGIN</tt> is executed before the first line of input is read in, so it
just initializes variables. The last, <tt  >END</tt>, is run after the last line
is processed. 
</p><p>
And the middle section? It's a regular expression that matches every line (by
being omitted entirely). Since the field separated is set to a comma, it
means that within the main awk block, $1 is the date, $2 is the category, $3 is
the amount and $4 is the comment.
</p><p>
For the sample input line, it'd be:

<pre     class="programlisting">
$1 = 4/10/14
$2 = subscriptions
$3 = 19.99
$4 = Linux Journal
</pre>
</p><p>
That's easy enough, and easy to understand, I expect. The code's also quite readable,
so you can see what's going on.
</p><p>
The problem? The problem arose when I encountered lines where one of the fields
had a comma. For example, if I had the comment field on this line be &ldquo;Linux
Journal, annually&rdquo;, the CSV output would be:

<pre     class="programlisting">
4/10/14,subscriptions,19.99,"Linux Journal, annual"
</pre>
</p><p>
If you're thinking about the field separator, it's immediately obvious
what's going to cause trouble. Instead of actually escaping the comma, Excel
has just quoted the field that has the comma in the output.
</p><p>
In this particular instance, it's not that big of a problem. All that happens is
that instead of having &ldquo;Linux Journal, annual&rdquo; as field 4, you'd end
up with &ldquo;Linux Journal&rdquo; in field 4 and &ldquo;annual&rdquo; in field 5.
</p><p>
Where this does turn out to be a problem is with the expense itself. In
particular, Excel displays four-digit values with a comma if they're a
currency: 1,300.00
</p><p>
<span   class="emphasis"><em>With. A. Comma.</em></span>
</p><p>
And, that comma survives the export to CSV format, which is a bit mind-boggling.
Suffice it to say, it turns out to be tricky, as you can see here:

<pre     class="programlisting">
4/10/14,subscriptions,"1,300.99",Linux Journal
</pre>
</p><p>
The easy way to solve the problem is to choose a different cell format style that
excludes the predilection of the spreadsheet to export with commas. But hey, you
read my column so you're probably used to taking the long, circuitous route.
So, let's do it again!
</p><p>
A bit of analysis reveals that if you simply split out the lines that contain
quotes from those that don't, you quickly can identify those that need fixing
or tweaking. Let's start with the raw file that contains two lines: one with
the embedded comma problem, one without:

<pre     class="programlisting">
4/7/14,subscriptions,199.99,Ask Dave Taylor Monthly
4/10/14,subscriptions,"1,300.99",Linux Journal
</pre>
</p><p>
There are lots of ways to identify the line with the problem, including picking
lines with more than the expected four fields, but let's do something easier:

<pre     class="programlisting">
$ grep \" expenses.csv
4/10/14,subscriptions,"1,300.99",Linux Journal
</pre>
</p><p>
The <tt  >cut</tt> command now can be used to extract just the quoted field&mdash;<tt  >cut
-d\" -f2</tt>&mdash;and then any comma removed with
<tt  >sed</tt>.
</p><p>
In other words, use a script block like this, if the line in question is stored in
the variable <tt  >inline</tt>:

<pre     class="programlisting">
f1=$(echo $inline | cut -d\" -f1)
f2=$(echo $inline | cut -d\" -f2)
f3=$(echo $inline | cut -d\" -f3)
</pre>
</p><p>
Let's examine what these three <tt  >cut</tt> statements do:
<tt  >f1</tt> is everything prior to
the first quote mark; <tt  >f2</tt> is everything that's been quoted,
and <tt  >f3</tt> is
everything after the quoted passage. In the case of the Linux Journal
subscription, it'd look like this:
  
<pre     class="programlisting">
f1=4/10/14,subscriptions,
f2=1,300.99
f3=,Linux Journal
</pre>
</p><p>
That's just about all of the hard work done because now you safely can strip
the commas from <tt  >f2</tt> without affecting the rest of the line,
safely stored in <tt  >f1</tt>
and <tt  >f3</tt>.
</p><p>
Then it all can be reassembled in a single line:

<pre     class="programlisting">
echo $f1`echo $f2|sed 's/,//g'`$f3
</pre>
</p><p>
Remember here that the backticks denote a sequence that's going to be passed
to a subshell and its output substituted. With the Linux Journal line, the output
is exactly as desired:

<pre     class="programlisting">
4/10/14,subscriptions,1300.99,Linux Journal
</pre>
</p><p>
It turns out that's the solution, and you now have all the basic pieces of the
script itself. Actually, there's no need to separate out files with quoted
lines versus those that don't have quotes because that can be done within the
script itself.
</p><p>
And so, here's the succinct script that can fix the CSV file quickly and
easily:

<pre     class="programlisting">
#!/bin/sh
# fix CSV files with embedded commas
while read inline
do
  if [ ! -z "$(echo $inline | grep \")" ] 
  then
    f1=$(echo $inline | cut -d\" -f1)
    f2=$(echo $inline | cut -d\" -f2)
    f3=$(echo $inline | cut -d\" -f3)
    echo $f1`echo $f2|sed 's/,//g'`$f3
  else
    echo $inline
  fi
done
exit 0
</pre>
</p><p>
Does it work? Let's give it a whirl:

<pre     class="programlisting">

$ sh fix-csv-commas.sh &lt; expenses.csv 
4/7/14,subscriptions,199.99,Ask Dave Taylor Monthly
4/10/14,subscriptions,1300.99,Linux Journal

</pre>
</p><p>
And there you go. As for me, well, it's back to finishing up my taxes now
that I've managed to burn a few hours creating this useful &ldquo;CSV-Fixer&rdquo; script.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x206a580.0x215a5b0"></a></h2></div></div><div class="sidebar"><p class="title"><b></b></p><p>Send comments or feedback via <a href="http://www.linuxjournal.com/contact" target="_self">www.linuxjournal.com/contact</a> or to
<a href="mailto:info@linuxjournal.com">info@linuxjournal.com</a>.
</p></div></div></div>
<div class="authorblurb"><p>
Dave Taylor has been hacking shell scripts since the dawn of the computer
era. Well, not really, but still, 30 years is a long time! He's the
author of the popular <span   class="emphasis"><em>Wicked Cool Shell Scripts</em></span> (10th
anniversary
update coming very soon from O'Reilly and NoStarch Press) and can be
found on Twitter as @DaveTaylor and more generally at his tech site
<a href="http://www.AskDaveTaylor.com" target="_self">www.AskDaveTaylor.com</a>.

</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../260/toc260.html">Issue Table of Contents</a>
    <a class="link3" href="../260/11946.html">Article</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>