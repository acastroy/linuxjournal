<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
An Ajax-Enhanced Web-Based Ethernet Analyzer</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;Combine Ruby, Ajax and bash with CGI scripts to monitor server-bound&#10;processes.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x1e0d580.0x1f04ab0"></a>
An Ajax-Enhanced Web-Based Ethernet Analyzer</h1></div><div><div class="author"><h3 class="author">
Paul
 
Barry
</h3></div><div class="issuemoyr">Issue #157, May 2007</div></div><div><p>
Combine Ruby, Ajax and bash with CGI scripts to monitor server-bound
processes.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e0d580.0x1f052f0"></a></h2></div></div><p>
I've spent the past six months or so playing with Ruby. I blame the July
2006 issue of <span   class="emphasis"><em>Linux Journal</em></span> for this hiatus from my programming
language of choice, Perl, as that issue opened my eyes to
the possibilities of using Ruby as a serious tool. I still love, use
and teach Perl, but I'm spending more and more time programming in Ruby.
</p><p>
I follow the same process when learning any new programming technology:
I identify a good book and work through it, and then start to use the language
to build some of the things I love to build with Perl. Identifying the
book was easy. The second edition of <span   class="emphasis"><em>Programming
Ruby</em></span> by Dave
Thomas (known as <span   class="emphasis"><em>The PickAxe</em></span>) is as good an introduction as you
are likely to find for any programming language, not just Ruby. Once I'd
worked my way through <span   class="emphasis"><em>The PickAxe</em></span>&mdash;creating a Ruby tutorial as I went
along (see Resources)&mdash;I was itching to write some real
code. I started with a type of tool that I enjoy building with Perl:
a custom Ethernet analyzer.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e0d580.0x1f055b0"></a>
Does the World Really Need Another Ethernet Analyzer?</h2></div></div><p>
At this point, probably more than a few readers are saying to
themselves: why bother creating an Ethernet analyzer when tcpdump and
Ethereal/Wireshark already exist? Those solutions are excellent
tools&mdash;which I use a lot&mdash;but, I'm often looking to build something
that involves additional processing plus the capturing and
decoding of Ethernet packets, and this customization invariably involves
resorting to custom code. Luckily, it turns out that the technology
that underpins both tcpdump and Ethereal/Wireshark&mdash;as well as the
hugely popular Snort IDS&mdash;is available as a library and that a number
of language bindings exist for it. The packet capturing library, called
libpcap, is available from the same project that brought the world
tcpdump and can be downloaded with ease from the Web. In fact, it may well
be included within your distribution's package management system; it
is if you are running a recent release of Ubuntu (as I am). Obviously,
the intrepid programmer can use C with libpcap, but&mdash;let's be honest
here&mdash;life's far too short to work at the C level of abstraction when
something more agile is needed. Thankfully, Perl provides an excellent
set of modules that work with libpcap, and I devote one-sixth of my
first book to discussing the Perl technology in detail. To my delight,
and after a little digging around, I also found a set of Ruby classes
that interface to libpcap (see Resources).
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e0d580.0x1f056b8"></a>
Creating a Custom Ethernet Analyzer with Ruby</h2></div></div><p>
In order to test the libpcap technology for real, I decided to
use Ruby to redevelop a tool I created with Perl a number of years
ago, which I wrote about within the pages of <span   class="emphasis"><em>The Perl
Review</em></span>
(see Resources). My Perl tool, called wdw (short for
who's doing what?), analyzes requests made to a LAN's DNS service and
reports on the site names for which the clients are requesting DNS
resolutions. In less than 100 lines of Perl code, I'd written a functioning and
useful DNS Ethernet analyzer. I wondered how using Ruby would
compare.
</p><p>
Now, I present the 20 or so lines of Ruby I used to re-create
wdw (for the entire program, see Listing 1). Do not interpret
my numbers as any attempt to claim that Ruby can do what Perl does in
one-fifth the number of lines of code. It cannot. It is important to note,
however, that Ruby's interface to libpcap is significantly more abstract
than the one offered by Perl, so Ruby does more in a single call than Perl
does, but that has more to do with the choices made by the creators of
each language's libpcap binding, as opposed to any fundamental language
difference.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e0d580.0x1f058c8"></a></h2></div></div><div class="sidebar"><p class="title"><b>
Listing 1. The dns-watcher.rb Source Code</b></p><pre     class="programlisting">#! /usr/bin/ruby -w

require 'pcap'
require 'net/dns/packet'

dev     = Pcap.lookupdev
capture = Pcap::Capture.open_live( dev, 1500 )

capture.setfilter( 'udp port 53' )

NUMPACKETS  = 50

puts "#{Time.now} - BEGIN run."

capture.loop( NUMPACKETS ) do |packet|

  dns_data = Net::DNS::Packet.parse(packet.udp_data)

  dns_header = dns_data.header

  if dns_header.query? then

    print "Device #{packet.ip_src} "
    print "(to #{packet.ip_dst}) looking for "
    question = dns_data.question
    question.inspect =~ /^\[(.+)\s+IN/
    puts $1
    STDOUT.flush

  end

end

capture.close

puts "#{Time.now} - END run."</pre></div><p>
Before executing this code, download and
install Ruby's libpcap library. Pop on over to the Ruby libpcap Web site
(see Resources), and grab the tarball. Or, if you are using
Ubuntu, use the Synaptic Package Manager to download and install the
libpcap-ruby1.8 package. If a distribution package isn't available,
install the tarball in the usual way.
</p><p>
You also need a Ruby library to decode DNS messages. Fortunately,
Marco Ceresa has been working hard at porting Perl's excellent Net::DNS
module to Ruby, and he recently released his alpha code to RubyForge, so
you need that too (see Resources). Despite being alpha,
Marco's code is very usable, and Marco is good at releasing a patched
library quickly after any problems are brought to his attention. Once
downloaded, install Marco's Net::DNS library into your Ruby environment
with the following commands:</p><pre     class="programlisting">tar zxvf net-dns-0.3.tgz
cd net-dns-0.3
sudo ruby setup.rb</pre><p>
My Ruby DNS analyzer is called dns-watcher.rb, and it starts by
pulling in the required Ruby libraries: one for working with libpcap
and the other for decoding DNS messages:</p><pre     class="programlisting">#! /usr/bin/ruby -w

require 'pcap'
require 'net/dns/packet'</pre><p>
I can tell my program which network connection to use for capturing
traffic, or I can let libpcap-ruby work out this for me. The following
line of code lets Ruby do the work:</p><pre     class="programlisting">dev = Pcap.lookupdev</pre><p>
With the device identified (and stored in dev), we need to enable
Ethernet's promiscuous mode, which is essential if we are to capture
all the traffic traveling on our LAN. Here's the Ruby code to do this:</p><pre     class="programlisting">capture = Pcap::Capture.open_live( dev, 1500 )</pre><p>
The open_live call takes two parameters: the device to work
with and a value that indicates how much of each captured packet to
process. Setting the latter to 1500 ensures that the entire Ethernet
packet is grabbed from the network every time capturing occurs. The call to open_live will succeed only if the program has the
ability to turn on promiscuous mode&mdash;that is, it must be run as root or
with sudo. With the network card identified and ready to capture traffic,
the next line of code applies a packet capturing filter:</p><pre     class="programlisting">capture.setfilter( 'udp port 53' )</pre><p>
I'm asking the libpcap library to concern itself only with capturing
packets that match the filter, which in this case is Ethernet packets
that contain UDP datagrams with a source or destination protocol port
value of 53. As all Net-heads know, 53 is the protocol port reserved for
use with the DNS system. All other traffic is ignored. What's cool about
the setfilter method is that it can take any filter specification
as understood by the tcpdump technology. Motivated readers can learn
more about writing filters from the tcpdump man page.
</p><p>
A constant is then defined to set how many captured packets I am
interested in, and then a timestamped message is sent to STDOUT to indicate
that the analyzer is up and running:</p><pre     class="programlisting">NUMPACKETS = 50
puts "#{Time.now} - BEGIN run."</pre><p>
The libpcap-ruby library contains the loop iterator, which provides a
convenient API to the packet capturing technology, and it takes a single
parameter, which is the number of packets to capture. Each captured
packet is delivered into the iterator's body as a named parameter,
which I refer to as packet in my code:</p><pre     class="programlisting">capture.loop( NUMPACKETS ) do |packet|</pre><p>
Within the iterator, the first order of business is to decode the
captured packet as a DNS message. The Packet.parse method from
Marco's Net::DNS library does exactly that:</p><pre     class="programlisting">dns_data = Net::DNS::Packet.parse( packet.udp_data )</pre><p>
With the DNS message decoded, we can pull out the DNS header information
with a call to the header method:</p><pre     class="programlisting">dns_header = dns_data.header</pre><p>
For my purposes, I am interested only in queries going to the DNS server,
so I can ignore everything else by checking to see whether the query?
method returns true or false:</p><pre     class="programlisting">if dns_header.query? then</pre><p>
Within the body of this if statement, I print out the IP source and
destination addresses, before extracting the IP name from the query,
which is returned by calling the dns_data.question method. Note
the use of a regular expression to extract the IP name from the query:</p><pre     class="programlisting">print "Device #{packet.ip_src}
 &#8618;(to #{packet.ip_dst}) looking for "
question = dns_data.question
question.inspect =~ /^\[(.+)\s+IN/
puts $1
STDOUT.flush</pre><p>
The program code concludes with the required end block terminators, and then
the capture object is closed, and another timestamp is sent to STDOUT:
</p><pre     class="programlisting">    end
end
capture.close
puts "#{Time.now} - END run."</pre></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e0d580.0x1f063c8"></a>
Running dns-watcher.rb</h2></div></div><p>
It's time to give dns-watcher.rb a spin:</p><pre     class="programlisting">sudo ruby dns-watcher.rb</pre><p>
The output from one such invocation is shown in Figure 1. Note that
there are not 50 lines of output, as might be expected. Remember, the
program's if statement checks to see whether the captured DNS message is a
query going to the server and processes the message only if it is. All
other DNS messages are ignored by the program, even though they still
contribute to the overall count of DNS packets processed.
</p><div       class="mediaobject"><a href="9614f1.large.jpg"><img src="9614f1.jpg"></a><div class="caption"><p>
Figure 1. Running dns-watcher.rb from the Command Line
</p></div></div><p>
To run the analyzer for a longer amount of time, change the NUMPACKETS constant
to some value greater than 50. As shown in Figure 1, it took
the analyzer just more than 40 seconds to process 50 DNS messages (on my PC,
on my network segment&mdash;your mileage will vary). It is not unreasonable
to assume that changing the constant value to something like 250 could
result in several minutes of processing. Obviously, piping the output
to a disk file or to less allows you to review any results at
your leisure.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e0d580.0x1f06790"></a>
Creating a Web-Based Ethernet Analyzer</h2></div></div><p>
With my little analyzer up and running, I started thinking it
would be cool if I could provide a Web-based interface to it. As every
Web developer knows, long-running, server-bound processes and the Web
tend not to go together, as there's nothing worse than waiting at a
browser for long periods of time while such a process executes. During the
years, a number of solutions to this problem have been proposed, which
involve techniques that employ redirection, cookies, sessions and the
like. Although such techniques work, I've always thought they were
rather clunky, and I've been on the lookout for something more elegant. Having
just completed Reuven M. Lerner's excellent series of
<span   class="emphasis"><em>LJ</em></span> articles on
Ajax programming [see the October, November and December 2006 issues of
<span   class="emphasis"><em>LJ</em></span>], I wondered if I could combine my analyzer with an Ajax-enabled Web page, updating a part of the Web page with the output from
the analyzer as and when it was generated.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e0d580.0x1f06948"></a></h2></div></div><div class="sidebar"><p class="title"><b>
Listing 2. A Simple HTML Web Page That Starts the Analyzer</b></p><pre     class="programlisting">
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Start a new DNS Analysis&lt;/title&gt;
  &lt;/head&gt;

  &lt;body&gt;
    Click to
    &lt;a href="/cgi-bin/startwatch.cgi"&gt;start&lt;/a&gt;.
  &lt;/body&gt;
&lt;/html&gt;
</pre></div><p>
My strategy is simple enough. I provide a starter Web page that starts
the network analysis on the Web server as a backgrounded CGI process,
and then redirects to another Web page that displays the results in an HTML
text-area widget, updating the text area with the results from the
network analysis. The little HTML Web page in Listing 2 gets things
moving. All this Web page really does is provide a link that, when
clicked, calls the startwatch.cgi script. The latter is itself
straightforward CGI, written as a bash script. Here's the entire script:</p><pre     class="programlisting">
#! /bin/sh

echo "Content-type: text/html"
echo ""

sudo /usr/bin/ruby /var/www/watcher/dns-watcher.rb \
         &gt; /var/www/watcher/dns-watcher.log &amp;

echo '&lt;html&gt;&lt;head&gt;'
echo '&lt;title&gt;Fetching results ... &lt;/title&gt;'
echo '&lt;meta http-equiv="Refresh" content="1;'
echo 'URL=/watcher.html"&gt;'
echo '&lt;/head&gt;&lt;body&gt;Fetching results ... &lt;/body&gt;'
echo '&lt;html&gt;'
</pre><p>
The key line of script is the one that invokes Ruby and feeds the
interpreter the dns-watcher.rb program, redirecting the latter's
standard output to a file called dns-watcher.log. Note the
trailing ampersand at the end of this command, which runs the analyzer
as a background process. The script continues by sending a sort HTML
Web page to the browser that redirects to the analysis results page,
called watcher.html, which is shown in Listing 3.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e0d580.0x1f06c60"></a></h2></div></div><div class="sidebar"><p class="title"><b>
Listing 3. The Network Analysis Results Web Page</b></p><pre     class="programlisting">
&lt;html&gt;

&lt;head&gt;
  &lt;title&gt;Web-based DNS Watcher&lt;/title&gt;

  &lt;script language=javascript src="/js/dns-watcher.js"&gt;
  &lt;/script&gt;
&lt;/head&gt;

&lt;body&gt;

&lt;h1&gt;Web-based DNS Watcher&lt;/h1&gt;

Here are the results of your DNS analysis:
&lt;p&gt;
&lt;textarea name="watcherarea" cols="100"
          rows="20" id="watcherarea"&gt;
Waiting for results ...
&lt;/textarea&gt;

&lt;script&gt;
startWatcher();
&lt;/script&gt;

&lt;p&gt;Start
&lt;a href="/startwatcher.html"&gt;another analysis&lt;/a&gt;
(which stops this one).

&lt;/body&gt;
&lt;/html&gt;
</pre></div><p>
The results Web page loads in some JavaScript code (dns-watcher.js)
within its header section, and then creates a simple HTML results page
that
contains an initially empty text-area widget called watcherarea. A
call to the startWatcher JavaScript method occurs as soon as the browser
loads the
body section of the results Web page.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e0d580.0x1efd758"></a></h2></div></div><div class="sidebar"><p class="title"><b>
Listing 4. The Ajax-Enabled JavaScript Code</b></p><pre     class="programlisting">var capturing = false;
var matchEnd = new RegExp( "END run" );
var r = new getXMLHttpRequest();

function startWatcher() {
  setInterval( "updateCaptureData()", 1500 );
  capturing = true;
}

function getXMLHttpRequest() {
  try {
    return new ActiveXObject("Msxml2.XMLHTTP");}
  catch(e) {};
  try {
    return new ActiveXObject("Microsoft.XMLHTTP");}
  catch(e) {}
  try {
    return new XMLHttpRequest(); }
  catch(e) {};

  return null;
}

function updateCaptureData() {

  if (capturing) {
    r.open( "GET",
            "/cgi-bin/get_watcher_data.cgi",
            false );
    r.send( null );

    displayCaptureData();
  }
}

function displayCaptureData() {
  var te = document.getElementById("watcherarea");

  if ( r.readyState == 4 ) {
    if ( r.status == 200 ) {

      te.value = r.responseText;
      te.scrollTop = te.scrollHeight;

      if ( matchEnd.test( te.value ) ) {
        capturing = false;
      }
    }
    else
    {
      te.value =
        "Web-based DNS Analysis unavailable.";
    }
  }
}</pre></div><p>
Listing 4 contains the dns-watcher.js code. A lot of what happens
here has been covered by Reuven's excellent Ajax articles. The code
starts by declaring some global variables that are used throughout the
remainder of the code:</p><pre     class="programlisting">var capturing = false;
var matchEnd = new RegExp( "END run" );
var r = new getXMLHttpRequest();</pre><p>
The capturing boolean is set to true while the analyzer is capturing
traffic, and to false otherwise. A regular expression is created to match against
a string containing the words &ldquo;END run&rdquo;. Finally, an Ajax request object
is created with a call to the getXMLHttpRequest method, which is
taken directly from Reuven's examples.
</p><p>
The startWatcher method starts the heavy lifting by calling
the updateCaptureData method every 1.5 seconds and setting
capturing to true:</p><pre     class="programlisting">function startWatcher() {
  setInterval( "updateCaptureData()", 1500 );
  capturing = true;
}</pre><p>
It is within the updateCaptureData method that the Ajax call
occurs, with the request object being used to execute another CGI
script that accesses the dns-watcher.log disk file and returns
its contents. (Listing 5 contains the get_watcher_data.cgi script,
which is written in Ruby.) Once the CGI script has been invoked on the
Web server, a call to displayCapture occurs:</p><pre     class="programlisting">function updateCaptureData() {

  if (capturing) {
    r.open( "GET",
            "/cgi-bin/get_watcher_data.cgi",
            false );
    r.send( null );

    displayCaptureData();
  }
}</pre></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e0d580.0x1efdc28"></a></h2></div></div><div class="sidebar"><p class="title"><b>
Listing 5. A Simple CGI to Retrieve the Captured Data</b></p><pre     class="programlisting">#! /usr/bin/ruby -w

puts "Content-type: text/plain\n\n"

IO.foreach("/var/www/watcher/dns-watcher.log") do |l|
  puts l
end</pre></div><p>
The displayCaptureData method is adapted from Reuven's code and
processes the results of the Ajax call, which are available from the
request object. These are used to update the watcherarea text-area
widget within the results Web page:</p><pre     class="programlisting">te.value = r.responseText;</pre><p>
Note the use of the following line of JavaScript to scroll the text area
to the bottom of the results:</p><pre     class="programlisting">te.scrollTop = te.scrollHeight;</pre><p>
And, finally, note that the displayCaptureData method sets the
capturing boolean to false as soon as a line that matches the
regular expression appears within the data coming from the Ajax request
(see Figures 1 and 2 to convince yourself that this in fact matches
at the end of the network capture):</p><pre     class="programlisting">if ( matchEnd.test( te.value ) ) {
  capturing = false;
}</pre><p>
This check is very important. Without it, the Web browser continues
to send an Ajax request to the server every 1.5 seconds for as long as
the watcher.html results page is displayed within the browser,
even after the analyzer has finished and isn't generating any more
data. With this check in the code, the Ajax behavior is switched off,
reducing the load on the Web server (and keeping the Apache2 access log
from quickly growing large).
</p><p>
To deploy my solution, I created a simple shell script to copy the
required components into the appropriate directory locations on my
Web server (which is Apache2 on Ubuntu):</p><pre     class="programlisting">sudo cp watcher.html /var/www/
sudo cp startwatcher.html /var/www/
sudo cp dns-watcher.js /var/www/js/
sudo cp dns-watcher.rb /var/www/watcher/
sudo cp get_watcher_data.cgi /usr/lib/cgi-bin/
sudo cp startwatch.cgi /usr/lib/cgi-bin/</pre><p>
These directory locations may not match those of your Apache2
installation, so adjust accordingly. You also may need to create the
js and watcher directories. And, of course, make sure the
CGIs have their executable bit set.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e0d580.0x1efe1a8"></a>
Running the Web-Based Network Analyzer</h2></div></div><p>
One final wrinkle is that the dns-watcher.rb program needs to
be executed with root privilege, in order to switch the Web server's
NIC into promiscuous mode. As would be expected, Apache2 does not, by
default, execute CGI scripts as a root privilege, and for good reason. To
get my Web-based analyzer to work, I added the following line to my
/etc/sudoers file:</p><pre     class="programlisting">%www-data ALL=(root) NOPASSWD: /usr/bin/ruby</pre><p>
This allows the www-data user, which executes Apache2, to execute
Ruby with root privilege, as it is the Ruby interpreter that executes
the dns-watcher.rb code on behalf of Apache2. Such a situation
may not be acceptable to you&mdash;due to the security concerns
raised&mdash;and I'd be interested to know if any reader has a solution that allows
me to execute the analyzer with root privilege more safely.
</p><div       class="mediaobject"><a href="9614f2.large.jpg"><img src="9614f2.jpg"></a><div class="caption"><p>
Figure 2. Running dns-watcher.rb from the Web
</p></div></div><p>
Figure 2 shows the results of a Web-based network analysis. The
long-running, server-bound process is started by the Web server, runs
in the background and&mdash;as results are generated&mdash;any and all output
appears within the Web-based front end. Thanks to Ajax, the user's
experience closely matches that of the command-line execution of the
same program&mdash;as soon as data is ready, it's displayed. Adapting
my solution to other uses is not difficult; all that's required is a
mechanism to redirect some long-running, server-bound process' output
to a file, and then access the file's contents via a CGI script that executes
as a result of a single Ajax call. As I hope I've demonstrated, Ruby and
Ajax make for a clean solution to this particular Web development pattern.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1e0d580.0x1efe570"></a></h2></div></div><div class="sidebar"><p class="title"><b>
Resources</b></p><p>
Paul's Ruby Tutorial: <a href="http://glasnost.itcarlow.ie/~barryp/ruby-tut.html" target="_self">glasnost.itcarlow.ie/~barryp/ruby-tut.html</a>
</p><p>
tcpdump/libpcap: <a href="http://www.tcpdump.org" target="_self">www.tcpdump.org</a>
</p><p>
Ruby's libpcap Library: <a href="http://raa.ruby-lang.org/project/pcap" target="_self">raa.ruby-lang.org/project/pcap</a>
</p><p>
Ruby Net::DNS Page on RubyForge: <a href="http://rubyforge.org/projects/net-dns" target="_self">rubyforge.org/projects/net-dns</a>
</p><p>
Ethereal: <a href="http://www.ethereal.com" target="_self">www.ethereal.com</a>
</p><p>
Wireshark: <a href="http://www.wireshark.org" target="_self">www.wireshark.org</a>
</p><p>
The &ldquo;who is doing what?&rdquo; Perl Script: <a href="http://www.theperlreview.com/Issues/v0i6.shtml" target="_self">www.theperlreview.com/Issues/v0i6.shtml</a>
</p><p>
Source Code for This Article: <a href="ftp://ftp.linuxjournal.com/pub/lj/issue157/9614.tgz" target="_self">ftp.linuxjournal.com/pub/lj/issue157/9614.tgz</a>
</p></div></div></div>
<div class="authorblurb"><p>
Paul Barry (<a href="mailto:paul.barry@itcarlow.ie">paul.barry@itcarlow.ie</a>) lectures at the Institute of
Technology, Carlow in Ireland. Find out more about the stuff he does at
<a href="http://glasnost.itcarlow.ie/~barryp" target="_self">glasnost.itcarlow.ie/~barryp</a>.
</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../157/toc157.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>