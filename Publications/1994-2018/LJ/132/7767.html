<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
Linux on a Small Satellite</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;With less than a year to design and build a satellite, this team&#10;used existing sensor hardware, industry-standard parts, shell scripts&#10;and our favorite OS to make the project come together.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x1c2a580.0x1d21ab0"></a>
Linux on a Small Satellite</h1></div><div><div class="author"><h3 class="author">
Christopher
 
Huffine
</h3></div><div class="issuemoyr">Issue #132, April 2005</div></div><div><p>
With less than a year to design and build a satellite, this team
used existing sensor hardware, industry-standard parts, shell scripts
and our favorite OS to make the project come together.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d22298"></a></h2></div></div><p>
The Department of Defense (DoD) Office of Force Transformation (OFT)
approached the Naval Research Laboratory (NRL) with an opportunity to build and
launch a micro-satellite, of the 100-kilogram class, to provide a platform for a
host of technology and operational experiments. A key challenge posed to
the Laboratory by OFT was to build this capability in less than one year.
Bringing this first TacSat vision together required the development of new
partnerships and methods as well as the leveraging of existing hardware, software
and facilities.
</p><div       class="mediaobject"><a href="7767f1.large.jpg"><img src="7767f1.jpg"></a><div class="caption"><p>
Figure 1. TacSat-1 Spacecraft, Solar Arrays Deployed, Nadir (Earth-Facing)
Side Facing Up
</p></div></div><p>
Copperfield-2, a sensor system developed
by the author's team for the Navy, became the
cornerstone of the TacSat-1 payload infrastructure.
The Copperfield-2 sensor system (Figure 2)
originally was designed for use on unmanned aerial
vehicles (UAVs)&mdash;a good match for adaptation to a
space mission, as many of the design requirements
are similar.
</p><p>
A satellite bus can be thought of
as the spacecraft vehicle. It provides the physical
and electrical infrastructure to support the payload.
The satellite payload is the sensor or experiment
being carried by the bus. TacSat-1 used
a bus originally designed for use in the ORBCOMM
constellation of small communications satellites.
If Copperfield-2 was flown on an aircraft or UAV,
that platform would serve as a bus, providing
infrastructure to the payload.
</p><div       class="mediaobject"><a href="7767f2.large.jpg"><img src="7767f2.jpg"></a><div class="caption"><p>
Figure 2. TacSat-1 Copperfield-2 Payload Block Diagram
</p></div></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d227c0"></a>
Modular Payload Hardware Design</h2></div></div><p>
The first hardware version of the Copperfield payload
was designed from legacy hardware systems and was
adapted to allow the original hardware to operate
through an Ethernet-connected TCP/IP interface.
When trades were made before designing the second-generation experimental capability, various bus
standards, commercial off-the-shelf (COTS) emerging
capabilities and other factors were considered.
We decided to pursue a 3U CompactPCI architecture to
allow maximum flexibility of the physical form factor
(Figure 3). However, we decided to use a custom PCI
motherboard so the CompactPCI user-defined P2
connector pins could be used for our own purposes.
This results in a motherboard with slots that support
our custom-designed hardware, slots that support
COTS Ethernet switch cards and slots that can
accommodate cards built to the PXI standard. The
resulting architecture blends standard CompactPCI with
Ethernet connectivity available by way of the P2 backplane.
</p><div       class="mediaobject"><img src="7767f3.jpg"><div class="caption"><p>
Figure 3. TacSat-1 Copperfield-2 CompactPCI Cardset and Chassis
</p></div></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d22a80"></a>
Modular Standards-Based Payload Architecture</h2></div></div><p>
Few satellite programs have the latitude or the
ability to take the risks that the TacSat-1 experiment
has. The TacSat-1 experiment allows innovative
leveraging of both government off-the-shelf (GOTS) and
COTS hardware components, as well as novel approaches
to creating payload software that provide maximum
flexibility and standards-based operation. The risk
philosophy allowed the utilization of a modular
payload hardware. Identically, a modular software
and communication system was expanded for TacSat-1,
extending the role of standards-based open-source
software such that it provides reusable software
infrastructure suitable for flexible command and
control of the TacSat-1 payload.
</p><p>
The Copperfield-2 payload architecture was intended
to provide as much flexibility as possible. It is a
testament to the flexibility of the architecture that
extension of the UAV payload to a space application
was possible. Because the payload software components
are not space-flight critical, meaning the health and safety
of the spacecraft does not depend on its reliability,
much of the software can be leveraged across air and
space platforms.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d22be0"></a>
Linux Kernel as the Foundation </h2></div></div><p>
From the beginning of Copperfield-2 development, it was our desire to
capitalize on the momentum, capability and availability of Linux source code. With the development of the processor
card with its PowerPC PowerQuicc II, the hardware infrastructure was
in place to support a robust embedded system. The accessibility of
source was a paramount feature that allowed us to recover from various
situations we encountered, including board layout errors. Although the board
design was made to look similar to the Motorola reference design&mdash;MPC8620ADS-PCI,
which no longer is available&mdash;some ambiguities, hardware limitations and
other issues necessitated changes to the kernel.
</p><p>
When TacSat-1 development began, many seasoned veterans questioned
the choice of Linux as host to the payload control software.
Proprietary real-time operating systems typically have been used for space
systems developed at NRL. During the architectural design process, no
hard real-time requirements were discovered, revalidating the original
choice of Linux for Copperfield-2 and, thus, also for TacSat-1.
</p><p>
Beyond the tweaks necessary to get Linux working correctly
with our hardware, only three device drivers were
written&mdash;one to support the sensor data format; one
to interface with the Xilinx SystemAce, a CompactFlash
interface device that can be used to load FPGAs and
also be used for OS storage; and one on the PowerPC
823 HSI interface box communicating with the FPGA.
Due to the large Xilinx Virtex-II mapped to the
memory space of our PowerPC processor, some innovation
was required to handle device driver development in
the face of changing FPGA designs. Don Kremer at
Aeronix developed a series of utilities that can read
Verilog source files and create myriad macros,
C code and even HTML documentation that allow the
Verilog hardware specification essentially to write
the majority of the necessary drivers.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d22d98"></a>
Networking Architecture of COTS Processors</h2></div></div><p>
The core Copperfield-2 payload processor provides two key functions
for the mission. First, it is a sensor system that receives
sensed data, processes the data and interacts with onboard
communications equipment to transmit the results to other sensors and
ground stations. Secondly, it serves as a general-purpose computer
system that provides the infrastructure for storage and data handling.
In fact, multiple general-purpose processors are part of the
Copperfield-2 payload, each communicating by way of an Ethernet
network. A COTS Ethernet switch serves as the center of
the star Ethernet architecture.
</p><div class="table"><a name="N0x1c2a580.0x1d22ea0"></a><p class="title"><b>
Table 1. TacSat-1 Copperfield-2 Ethernet-Connected Embedded
Systems</b></p><table     summary="&#10;Table 1. TacSat-1 Copperfield-2 Ethernet-Connected Embedded&#10;Systems" border="1"><colgroup><col><col><col><col></colgroup><thead><tr><th>Component</th><th>Vendor</th><th>OS</th><th>Processor</th></tr></thead><tbody><tr><td>
High-Speed
Interface (HSI)</td><td>Bright Star Engineering (custom adapter board)</td><td>Linux 2.4 custom distribution</td><td>PowerPC MPC823</td></tr><tr><td>
IDM UHF Modem</td><td>Innovative Concepts</td><td>Proprietary</td><td>PowerPC 860</td></tr><tr><td>
Copperfield-2
MR.DIG Card</td><td>Aeronix/NRL</td><td>Linux 2.4 custom distribution (DENX ELDK-based)</td><td>
PowerPC PowerQuicc II 8260</td></tr><tr><td>RF Front End
Controller</td><td>Bright Star Engineering (custom adapter board)</td><td>Linux 2.4 custom distribution</td><td>StrongARM SA1110</td></tr></tbody></table></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d238f0"></a>
Gateway to the Bus Legacy Equipment</h2></div></div><p>
To capitalize on the Ethernet, TCP/IP, standards-based architecture
of the UAV payload while remaining compatible with the satellite bus'
legacy OX.25 interfaces&mdash;which provide a means for downlinking science
data and state-of-health telemetry&mdash;a different embedded computer module
was designed specifically to serve as the bridge. This module is called
the high-speed interface (HSI) and provides a 2MB synchronous serial
bus connected to the spacecraft communication controller. The HSI
hardware is implemented as a combination of FPGA hardware and a BSE
ipEngine general-purpose PowerPC 823 embedded processor.
</p><p>
In the HSI, the FPGA provides
the hardware necessary to meet timing requirements for the data link,
decoupling the processor from the synchronous data link. The PowerPC
runs a Linux 2.4-based kernel, and the HSI FPGA interface is implemented
as a standard Linux device driver. No special real-time extensions are
used, and a Linux-based application provides the interface between the
TCP/IP networking stack, using standard protocols and the device driver
implementation. The HSI system allows multiple processes and Ethernet-connected
computers to access the data stream sent to the spacecraft.
The PowerPC communications controller on the Copperfield-2 processor
easily could have handled the HSI tasks on TacSat-1. However,
due to the extremely limited availability of hardware and the desire
to increase parallel development opportunities, this interface was
developed independently.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d23a50"></a>
Rapid Payload Software Development with Existing Tools</h2></div></div><p>
The most &ldquo;custom&rdquo; part in any satellite program often is the payload
control software. Because many of the Copperfield-2 payload components with
processors run Linux, interesting software options
are available. Much of the payload software was implemented as
bash (Bourne again shell) scripts. During the rapid
development of the payload software, the philosophy was to attempt to
divide the software development into two parts, custom and reused
software modules. This philosophy called for minimizing custom code
to limited functions and programs with specific purposes.
Occasionally, we did find that existing utilities did not quite fit
the requirements, and these were modified or replacements were written.
</p><p>
These specific custom programs and drivers allowed for control of payload
elements through small command-line utilities that could be tested completely
and easily in their limited functionality. These programs were
developed with the UNIX command-line functionality in mind, along with data input
through standard in (STDIN) and data output through standard
out (STDOUT). Developing software utilities with interfaces such as these in mind
has been the standard for many legacy operating system concepts from the
earliest UNIX developments. We intended to continue that strategy and
build upon it, as it provides an amazingly flexible way of constructing
thorough capabilities with simple although powerful utilities.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d23c08"></a>
GNU and Open-Source Utilities</h2></div></div><p>
The first step in designing the software architecture was to examine what
tools already were available to the developers&mdash;in this case, parts of
the Linux distribution and other GNU and open-source utilities
with well-defined pedigrees that provided needed capabilities.
Time and time again, as we were developing the payload control software,
we were amazed at the flexibility and amazing number of options that
various commands provide.
</p><p>
One example is the GNU compression utility gzip. During a ground
contact event, the payload streams data in real time through a series of
software pipes. It originates in a file located on the Flash filesystem
and then makes its way through various utilities, including a compression stage,
and into the satellite bus. We found that it was necessary to tune gzip
to select a compression ratio/performance curve that would
ensure that the 1MB downlink was filled completely with data packets.
gzip inserted into the downlink stream was a relatively late addition,
and it allows us to make maximum use of the available downlink
bandwidth. The design of command-line utilities using STDIN/STDOUT interfaces
allows capabilities such as this to be integrated transparently into the data stream,
within the performance capability of our computer system.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d1a5f8"></a></h2></div></div><div class="sidebar"><p class="title"><b>
Listing 1. Downlink Pipeline Demonstrating tar, gzip and netcat
</b></p><pre     class="programlisting">

# Configure the file download pipeline
tar -cf - ${downloadFileList} | gzip -c -l | \
    file_downloader -tqid ${target_qid} -rlp \
                          ${return_link_path} \
                     -dri ${dump_request_id} \
                     -fmt ${dataFormat} | \
    netcat localhost ${!returnLinkService}

</pre></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d1a7b0"></a>
Payload Control Subsystem&mdash;with bash</h2></div></div><p>
Choosing a scripting language is a difficult task&mdash;indeed, in the
Open Source community, many competent options are available.
Perl may have been a good choice, but we were not comfortable with the
size of its installation and memory footprint. Python also would have been a
great choice, but the development team did not have experience with it.
The most powerful shell-scripting language appeared to be bash, although
it also is the heaviest in terms of footprint. Our smallest embedded
systems could not handle the entire footprint of bash, but the Busybox
lightweight shell-scripting interpreter, ASH, proved almost as capable
for the tasks that had to be monitored and controlled on those smaller
targets.
</p><p>
Although space here does not allow for a complete architecture
discussion of the payload control software design, at its core
the software is a series of bash scripts designed to support
various functions of the payload. The system is designed to take advantage
of POSIX-style filesystem security. Upon boot, the
first processes run as root as the system starts.
As the payload control software begins to come on-line,
it starts up as user BOOT. The system can stay
in BOOT and provide a certain number of critical
system capabilities, including providing binary telemetry
streams, file transfers and direct commands.
When a sensor mission is about to begin, the system
moves to a state of TRANSITION, and all further data
collections take place as the OPS user, who has
a different set of permissions. At the conclusion
of the data collection, OPS is commanded to shut down.
Multiple redundant copies of the BOOT directories are
designed into the system to provide backup capability
in the case of filesystem corruption or other
significant error.
</p><p>
bash scripts launch every payload control system function. They create
complex filenames we use to keep track of configuration, date and time
and other information. They un-gzip and untar commands and files
that are uplinked to the satellite. Commands themselves also are bash
scripts with simplified functionalities. They call other bash scripts
to do the actual data collection or to set environment variables that
change the behavior of other scripts.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d1a968"></a></h2></div></div><div class="sidebar"><p class="title"><b>
Listing 2. Sensor Data Processing Pipeline</b></p><pre     class="programlisting">

# Start the data processing pipeline
# (with cpf ignoring SIGINT,SIGTERM)
   eval "cat $dig_data_stream | \
      tee $raw_file | \
      cpf -i -v$cpf_verbosity $cpfparams \
      &gt; $output_file &amp;"
   # Enable the dig channel
   set_hardware 'echo $dig_channel \
     channelEnable ena | mapper 2&gt;&amp;1'

</pre></div><p>
This combination of the bash scripting language, GNU
and open-source utilities and custom command-line applications is unique
in satellite programs. For TacSat-1, most of the custom code
involves the conversion of data from the TCP/IP world to proprietary
OX.25 formats to handle sensor data.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d1ab78"></a></h2></div></div><div class="sidebar"><p class="title"><b>
Listing 3. Example Data Output Pipeline with Conversion to Proprietary Data
Format as the Last Step before Sending Out the Data</b></p><pre     class="programlisting">

# Start the pipeline
format_event -severity $severity_level \
             -status $status_code \
     -failcmd $fail_cmd \
                -text "${event_text}"  \
                -debug $debug_level  2&gt;&gt; $logFile \
        | ox25  -tbox  ${tbox}  -tque    ${tque}   \
                -sbox  ${sbox}  -sque    ${sque}   \
                -cflgs ${cflgs} -seq     ${seq}   \
                -func  ${func}  -subfunc ${subfunc} \
                -debug ${debug_level} \
                2&gt;&gt; $logFile  \
        | netcat $ncVerbose localhost ${!returnLinkService} \
                2&gt;&gt; $logFile

</pre></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d1ad30"></a>
Distributed Development and Collaboration</h2></div></div><p>
The extensive use of TCP/IP-based systems and the common Linux operating
system provided unique opportunities for a distributed development
environment. Early in TacSat-1, our custom PowerPC 8260 development
hardware had limited availability. The design cycle for much
of the payload software began on Intel x86-based computer systems,
migrated to generic PowerPC embedded processors and eventually made
its way to the final target. The software design team was distributed spatially
and tied together through a virtual private network (VPN)
architecture. Remote power control devices allowed developers who were
operating off-site to cycle power on hardware components. A Web-based
collaboration tool allowed the posting and dissemination of critical
communications and interconnection control documents (ICDs). Some developers
also used instant messaging technology to stay in contact with one
another. Recent additions to the collaborative working environment
include the use of E-Log to maintain an on-line database of lessons
learned. We also are working to integrate Bugzilla capability into the system to replace
our relatively crude Message Forum-based problem report (PR) tracking.
</p><p>
The TCP/IP nature of the payload data network allowed developers to
test communications between payload elements at each step in the design
process, from developing on a standard PC to final communications
before inserting the custom hardware required to communicate with the
bus. Even after complete integration of the payload into the bus, an
Ethernet test port allowed network access to the satellite, which
was invaluable for collaborative debugging of the system. Test ports
also allow access to serial consoles for most of the payload components
and, in some cases, JTAG or other hardware debugging ports.
</p><p>
The payload software design team consisted of experienced satellite and
ground station software experts, as well as team members accustomed to
the TCP/IP data transport and Web/CGI application development, plus embedded
systems experts. Although quite different from the typical satellite software
design team, this combination provided nearly the perfect balance of
skills and innovative methods to maximize the use of existing software
designed for aircraft applications. The extensive remote collaboration,
interface testing and networking capability provided a smooth bus-payload
integration.
</p><p>
The core of the payload control software, including many of the command
and control scripts, were developed in a span of less than four months,
from start to finish. Additional scripts were inserted into the core
payload control software infrastructure to bring on-line additional sensor
capabilities as those sensors became available. New capabilities and
patches may be uploaded to the satellite as requirements dictate.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d1af40"></a>
Conclusion</h2></div></div><p>
Few satellite programs have the sponsor-supplied latitude or the ability
to take risks that the TacSat-1 initiative provides. In this context,
the TacSat-1 program allows innovative leveraging of both GOTS and COTS
hardware components, as well as novel approaches to creating payload
software that provides maximum flexibility and standards-based
operation. The modular nature of the Copperfield-2 allowed rapid hardware
integration, proving the concept of a modular payload that scales from UAV
applications to a spacecraft application, all using Linux and GNU software
as a foundation. At the time of this writing, TacSat-1 was scheduled to
launch in February 2005.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x1c2a580.0x1d1b048"></a>
Acknowledgements</h2></div></div><p>
The author acknowledges the essential contributions to the TacSat-1
effort by Stuart Nicholson, consultant, and Eric Karlin, Mike Steininger
and Brian Davis of SGSS, Inc., for core Payload Control Software.
Brian Micek of Titan Corp., Chris Gembaroski, Don Kremer, Tim Richmeyer
and the Copperfield-2 team at Aeronix, Inc., Jeff Angielski of the PTR
Group for Linux porting, device drivers and sensor support software.
Also, thanks to Wolfgang Denx and the Linux PowerPC community for their
contributions toward making PowerPC Linux stable and robust.
</p><p>
<span   class="bold"><b>Resources for this article:</b></span> <a href="../132/8066.html" target="_self">/article/8066</a>.
</p></div></div>
<div class="authorblurb"><p>
Christopher Huffine is an electronic engineer at the US
Naval Research Laboratory, working for the Naval
Center for Space Technology. He has been using Linux
since college on various platforms, from desktop
workstations to embedded control computers.
</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../132/toc132.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>