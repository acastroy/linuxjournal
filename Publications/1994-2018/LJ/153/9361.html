<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>
SMP and Embedded Real Time</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;As embedded real-time applications start to run on SMP systems, kernel&#10;issues emerge.&#10;"><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x214b580.0x2242ab0"></a>
SMP and Embedded Real Time</h1></div><div><div class="author"><h3 class="author">
Paul
 E. 
McKenney
</h3></div><div class="issuemoyr">Issue #153, January 2007</div></div><div><p>
As embedded real-time applications start to run on SMP systems, kernel
issues emerge.
</p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x214b580.0x2243298"></a></h2></div></div><p>
With the advent of multithreaded/multicore CPUs, even embedded real-time
applications are starting to run on SMP systems&mdash;for example, both
the Xbox 360 and PS/3 are multithreaded, and there even have been SMP
ARM processors! As this trend continues, there will be an increasing
need for real-time response from SMP systems.  Because not all embedded
systems vendors will be willing or able to create or purchase SMP
real-time operating systems, we can expect that a number of them will
make use of Linux.
</p><p>
Because of this change, a number of real-time tenets have now become
myths.  This article exposes these myths and then discusses some of the
challenges that Linux is surmounting in order to meet the needs of this
new SMP-real-time-embedded world.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x214b580.0x22433f8"></a>
Real-Time Myths</h2></div></div><p>
New technologies often have a corrosive effect on the wisdom of the
ages.  The advent of commodity multicore and multithreaded hardware is
no different, making myths of the following pearls of wisdom:
</p><div class="orderedlist"><ol type="1"><li><p>
Embedded systems are always uniprocessor systems.
</p></li><li><p>
Parallel programming is mind crushingly difficult.
</p></li><li><p>
Real time must be either hard or soft.
</p></li><li><p>
Parallel real-time programming is impossibly difficult.
</p></li><li><p>
There is no connection between real-time and enterprise systems.
</p></li></ol></div><p>
Each of these myths is exposed in the following sections, and Ingo
Molnar's -rt real-time patchset (also known as the CONFIG_PREEMPT_RT
patchset after the configuration variable used to enable real-time
behavior) plays a key role in exposing the last two myths.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x214b580.0x2243920"></a>
Myth 1: Embedded Systems Are Always Uniprocessor Systems</h2></div></div><p>
Past embedded systems almost always were uniprocessors, especially given
that single-chip multiprocessors are a very recent phenomenon.  The PS/3,
the Xbox 360 and the SMP ARM are recent exceptions to this rule.  But
what does the future hold?
</p><p>
Figure 1 shows how clock frequencies have leveled off since 2003. Now,
Moore's Law is still in full force, as transistor densities are still
increasing.  However, these increasing densities are no longer providing
the side benefit of increased clock frequency that they once did.
</p><div       class="mediaobject"><a href="9361f1.large.jpg"><img src="9361f1.jpg"></a><div class="caption"><p>
Figure 1. Clock-Frequency Trend for Intel CPUs
</p></div></div><p>
Some say that parallel processing, hardware multithreading and multicore
CPU chips will be needed to make good use of the ever-increasing
numbers of transistors.  Others say that embedded systems need increasing
levels of integration and reduced power consumption more than they do
ever-increasing performance.  Embedded systems vendors might therefore
choose more on-chip I/O or memory over increased parallelism.
</p><p>
This debate will not be resolved soon, although we have all seen examples
of multithreaded and multicore CPUs in embedded systems.  That said,
as multithreaded/multicore systems become cheaper and more prevalent,
we will see more rather than fewer of them.
</p><p>
But these multithreaded/multicore systems require parallel
software.  Given the forbidding reputation of parallel programming,
how are we going to program these systems successfully?
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x214b580.0x2243d40"></a>
Myth 2: Parallel Programming Is Mind Crushingly Difficult</h2></div></div><p>
Why is parallel programming hard?
Answers include deadlocks, race conditions and testing coverage, but the
real answer is that it is not really all that hard.  After all, if parallel
programming was really so difficult, why are there so many parallel
open-source projects, including Apache, MySQL and the Linux kernel?
</p><p>
A better question would be &ldquo;Why is parallel programming perceived to
be so difficult?&rdquo; Let's go back to the year 1991.  I was walking across
the parking lot to Sequent's benchmarking center carrying six dual-80486
CPU boards, when I suddenly realized that I was carrying several times
the price of my house.  (Yes, I did walk more carefully.  Why do you
ask?) These horribly expensive systems were limited to a privileged few,
who were the only ones with the opportunity to learn parallel programming.
</p><p>
In contrast, in 2006, I am typing on a dual-core x86 laptop that is orders
of magnitude cheaper than even one of Sequent's CPU boards.  Because almost
everyone now can gain access to parallel hardware, almost everyone can
learn to program it and also learn that although it can be nontrivial,
it is really not all that hard.
</p><p>
Even so, many multithreaded/multicore embedded systems have real-time
constraints.  But what exactly is real time?
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x214b580.0x2243fa8"></a>
Myth 3: Real Time Must Be Either Hard or Soft</h2></div></div><p>
There is hard real time, which offers unconditional guarantees, and there
is soft real time, which does not.  What else do you need to know?
</p><p>
As it turns out, quite a bit.  There are at least four different
definitions of hard real time.  Needless to say, it is important to
understand which one your users have in mind.
</p><p>
In one definition of hard real time, the system always must meet its
deadlines.  However, if you show me a hard real-time system, I will show
you the hammer that will cause it to miss its deadlines, as shown in
Figure 2.
</p><div       class="mediaobject"><a href="9361f2.large.jpg"><img src="9361f2.jpg"></a><div class="caption"><p>
Figure 2. Hard Real Time: But I Have a Hammer
</p></div></div><p>
Of course, this is unfair.  After all, we cannot blame software
for hardware failures that it did not cause.  Therefore, in another
definition of hard real time, the system always must meet its deadlines,
but only in absence of hardware failure.  This divide-and-conquer approach
can simplify things, but, as shown in Figure 3, it is not sufficient at
the system level.  Nonetheless, this definition can be useful given
restrictions on the environment, including:
</p><div class="orderedlist"><ol type="1"><li><p>
Interrupt rates.
</p></li><li><p>
Cache misses.
</p></li><li><p>
Memory-system overhead due to DMA.
</p></li><li><p>
Memory-error rate in ECC-protected systems.
</p></li><li><p>
Packet-loss rate in systems requiring networking.
</p></li></ol></div><div       class="mediaobject"><a href="9361f3.large.jpg"><img src="9361f3.jpg"></a><div class="caption"><p>
Figure 3. Hard real time: sometimes system failure is not an option!
</p></div></div><p>
If these restrictions are violated, the system is permitted to miss its
deadlines.  For example, if a hyperactive interrupt system delivered
an interrupt after each instruction, the appropriate action might be
to replace the broken hardware rather than code around it.  After all,
if this degenerate situation must be accounted for, the latencies will
likely become uselessly long.  Alternatively, &ldquo;diamond hard&rdquo;
real-time
operating systems and applications might run with interrupts disabled,
giving up compatibility with off-the-shelf software in order to gain
additional robustness in face of hardware failure.
</p><p>
In yet another definition of hard real time, the system is allowed
to miss its deadline, but only if it announces its failure within the
deadline specified.  This sort of definition can be useful in data-fusion
applications.  For example, a system might have a high-precision location
sensor with unpredictable processing overhead as well as a rough-and-ready
location sensor with deterministic processing overhead.  A reasonable
hard real-time strategy would be to give the high-precision sensor a
fixed amount of time to get its job done, and if it fails to do so,
abort its calculation, relying instead on the rough-and-ready sensor.
However, one (useless) way to meet the letter of this definition would be
to announce failure unconditionally, as illustrated by Figure 4.  Clearly,
a useful system almost always would complete its work in time (and this
observation applies to soft real-time systems as well).
</p><div       class="mediaobject"><a href="9361f4.large.jpg"><img src="9361f4.jpg"></a><div class="caption"><p>
Figure 4. Hard real time: at least I let you know!
</p></div></div><p>
Finally, some define hard real time with a test suite: a system passing
the test is labeled hard real time.  Purists might object, demanding
instead a mathematical proof.  However, given that proofs can be subject
to error, especially for today's complex systems, a test suite can be
an excellent additional proof point.  I certainly do not wish to put my
life at the mercy of untested software!
</p><p>
This is not to say that hard real time is undefined or useless.  Instead,
&ldquo;hard real time&rdquo; is the start of a conversation rather than a complete
requirement.  You should ask the following questions:
</p><div class="orderedlist"><ol type="1"><li><p>
Which operations must provide hard real-time response? (For example, I
have yet to run across a requirement for real-time filesystem unmounting.)
</p></li><li><p>
What is the deadline? A ten-millisecond deadline is one thing; a
one-microsecond deadline is quite another.
</p></li><li><p>
What is to happen in case of hardware failure?
</p></li><li><p>
What is the required probability of meeting that deadline? (For hard
real time, this will be 100%.)
</p></li><li><p>
What degradation of non-real-time performance, throughput and
scalability can be tolerated?
</p></li></ol></div><p>
One piece of good news is that real-time deadlines that once required
extreme measures are now easily met with off-the-shelf hardware and
open-source software, courtesy of Moore's Law.
</p><p>
But, what if your real-time application is to run on an embedded
multicore/multithreaded system? How can you deal with both real-time
deadlines and parallel programming?
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x214b580.0x263d380"></a>
Myth 4: Parallel Real-Time Programming Is Impossibly Difficult</h2></div></div><p>
Parallel programming might not be mind crushingly hard, but it is
certainly harder than single-threaded programming.  Real-time programming
is also hard.  So, why would anyone be crazy enough to take on both at
the same time?
</p><p>
It is true that real-time parallel programming poses special challenges,
including interactions with lock-induced delays, interrupt handlers
and priority inversion.  However, Ingo Molnar's -rt patchset provides
both kernel and application developers with tools to deal with these
challenges.  These tools are described in the following sections.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x214b580.0x263d4e0"></a>
Locking and Real-Time Latency</h2></div></div><p>
Much ink has been spilled on locking and real-time latency, but we will
stick to the following simple points:
</p><div class="orderedlist"><ol type="1"><li><p>
Reducing lock contention improves SMP scalability and reduces real-time
latency.
</p></li><li><p>
When lock contention is low, there are a finite number of tasks,
critical-section execution time is bounded, and locks act in a
first-come-first-served manner to the highest-priority tasks, then
lock wait times for those tasks will be bounded.
</p></li><li><p>
An SMP Linux kernel by its very nature requires very few modifications
in order to support the aggressive preemption required by real time.
</p></li></ol></div><p>
The first point should be obvious, because spinning on locks is bad for
both scalability and latency.  For the second point, consider a queue
at a bank where each person spends a bounded time T with a solitary
teller, there are a bounded number of other people N, and the queue is
first-come-first-served.  Because there can be at most N people ahead of
you, and each can take at most time T, you will wait for at most time
NT.  Therefore, FIFO priority-based locking really can provide hard
real-time latencies.
</p><p>
For the third point, see Figure 5.  The left-hand side of the diagram
shows three functions A(), B() and C() executing on a pair of CPUs.  If
functions A() and B() must exclude function C(), some sort of locking
scheme must be used.  However, that same locking provides the protection
needed by the -rt patchset's preemption, as shown on the right-hand
side of this diagram.  If function B() is preempted, function C()
blocks as soon as it tries to acquire the lock, which permits B() to
run.  After B() completes, C() may acquire the lock and resume running.
</p><div       class="mediaobject"><a href="9361f5.large.jpg"><img src="9361f5.jpg"></a><div class="caption"><p>
Figure 5. SMP Locking and Preemption
</p></div></div><p>
This approach requires that kernel spinlocks block, and this change is
fundamental to the -rt patchset.  In addition, per-CPU variables must be
protected more rigorously.  Interestingly enough, the -rt patchset also
located a number of SMP bugs that had gone undetected.
</p><p>
However, in the standard Linux kernel, interrupt handlers cannot block.
But interrupt handlers must acquire locks, which can block in -rt.  What
can be done?
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x214b580.0x263db68"></a>
Interrupt Handlers</h2></div></div><p>
Not only are blocking locks a problem for interrupt handlers, but they
also can
seriously degrade real-time latency, as shown in Figure 6.
</p><div       class="mediaobject"><a href="9361f6.large.jpg"><img src="9361f6.jpg"></a><div class="caption"><p>
Figure 6. Interrupts Degrade Latency
</p></div></div><p>
This degradation can be avoided by running the interrupt handler in
process context, as shown in Figure 7, which also allows them to acquire
blocking locks.
</p><div       class="mediaobject"><a href="9361f7.large.jpg"><img src="9361f7.jpg"></a><div class="caption"><p>
Figure 7. Move Interrupt Handlers to Process Context
</p></div></div><p>
Even better, these process-based interrupt handlers can actually be
preempted by user-level real-time threads, as shown in Figure 8, where the
blue rectangle within the interrupt handler represents a high-priority
real-time user process preempting the interrupt handler.
</p><div       class="mediaobject"><a href="9361f8.large.jpg"><img src="9361f8.jpg"></a><div class="caption"><p>
Figure 8. Preempting Interrupt Handlers
</p></div></div><p>
Of course, &ldquo;with great power comes great responsibility.&rdquo; For example,
a high-priority real-time user process could starve interrupts entirely,
shutting down all I/O.  One way to handle this situation is to provide
a low-priority &ldquo;canary&rdquo; process.  If the &ldquo;canary&rdquo; is blocked for longer
than a predetermined time, one might kill the offending thread.
</p><p>
Running interrupts in process context permits interrupt handlers to
acquire blocking locks, which in turn allows critical sections to be
preempted, which permits extremely fast real-time scheduling latencies.  In
addition, the -rt patchset permits real-time application developers to
select the real-time priority at which interrupt handlers run.  By running
only the most critical portions of the real-time application at higher
priority than the interrupt handlers, the developers can minimize the
amount of code for which &ldquo;great responsibility&rdquo; must be shouldered.
</p><p>
However, preempting critical sections can lead to priority inversion,
as described in the next section.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x214b580.0x263e4b0"></a>
Priority Inversion</h2></div></div><p>
Priority inversion is illustrated by Figure 9.  A low-priority process
P2 holds a lock, but is preempted by medium-priority processes.  When
high-priority process P1 tries to acquire the lock, it must wait, because
P2 holds it.  But P2 cannot release it until it runs again, which will not
happen while the medium-priority processes are running.  So, in effect,
the medium-priority processes have blocked a high-priority process:
in short, priority inversion.
</p><div       class="mediaobject"><a href="9361f9.large.jpg"><img src="9361f9.jpg"></a><div class="caption"><p>
Figure 9. Priority Inversion
</p></div></div><p>
One way to prevent priority inversion is to disable preemption during
critical sections, as is done in CONFIG_PREEMPT builds of the Linux
kernel.  However, this preemption disabling can result in excessive
latencies.
</p><p>
The -rt patchset therefore uses priority inheritance instead, so that
P1 donates its priority to P2, but only for as long as P2 continues
to hold the lock, as shown in Figure 10.  Because P2 is now running at
high priority, it preempts the medium-priority processes, completing
its critical section quickly and then handing the lock off to P1.
</p><div       class="mediaobject"><a href="9361f10.large.jpg"><img src="9361f10.jpg"></a><div class="caption"><p>
Figure 10. Priority Inheritance
</p></div></div><p>
So priority inheritance works well for exclusive locks, where only one
thread can hold the lock at a given time.  But there are also reader-writer
locks, which can be held by one writer on the one hand or by an unlimited
number of readers on the other.  The fact that a reader-writer lock can be
held by an unlimited number of readers can be a real problem for priority
inheritance, as illustrated in Figure 11.  Here, several low-priority
processes are read-holding lock L1, but are preempted by medium-priority
processes.  Each low-priority process might also be blocked write-acquiring
other locks, which might be read-held by even more low-priority processes,
all of which are also preempted by the medium-priority processes.
</p><div       class="mediaobject"><a href="9361f11.large.jpg"><img src="9361f11.jpg"></a><div class="caption"><p>
Figure 11. Reader-Writer Lock Priority Inversion
</p></div></div><p>
Priority inheritance can solve this problem, but the cure is worse
than the disease.  For example, the arbitrarily bushy tree of preempted
processes requires complex and slow bookkeeping.  But even worse, before
the high-priority writer can proceed, all of the low-priority processes
must complete their critical sections, which will result in arbitrarily
long delays.
</p><p>
Such delays are not what we want in a real-time system.  This situation
resulted in numerous &ldquo;spirited&rdquo; discussions on the Linux-kernel mailing
list, which Ingo Molnar closed down with the following proposal:
</p><div class="orderedlist"><ol type="1"><li><p>
Only one task at a time may read-acquire a given reader-writer lock.
</p></li><li><p>
If #1 results in performance or scalability problems, the
problematic lock will be replaced with RCU (read-copy update).
</p></li></ol></div><p>
RCU can be thought of as a reader-writer lock where readers never block;
in fact, readers execute a deterministic number of instructions.  Writers
have much higher overhead, as they must retain old versions of the
data structure that readers might still be referencing.  RCU provides
special primitives to allow writers to determine when all readers
have completed, so that the writer can determine when it is safe to
free old versions.  RCU works best for read-mostly data structures, or
for data structures with hard real-time readers.  (More detail may be
found at <a href="http://en.wikipedia.org/wiki/RCU" target="_self">en.wikipedia.org/wiki/RCU</a>, and even more detail may be
found at <a href="http://www.rdrop.com/users/paulmck/RCU" target="_self">www.rdrop.com/users/paulmck/RCU</a>.  Although user-level
RCU implementations have been produced for experimental purposes,
for example, <a href="http://www.cs.toronto.edu/~tomhart/perflab/ipdps06.tgz" target="_self">www.cs.toronto.edu/~tomhart/perflab/ipdps06.tgz</a>,
production-quality RCU implementations are currently found only in
kernels.  Fixing this is on my to-do list.)
</p><p>
A key property of RCU is that writers never block readers, and,
conversely, readers do not block writers from modifying a data
structure.  Therefore, RCU cannot cause priority inversion.  This is
illustrated in Figure 12.  Here, the low-priority processes are in
RCU read-side critical sections and are preempted by medium-priority
processes, but because the locks are used only to coordinate updates,
the high-priority process P1 immediately can acquire the lock and carry
out the update by creating a new version.  Freeing the old version does
have to wait for readers to complete, but this freeing can be deferred
to avoid degrading real-time latencies.
</p><div       class="mediaobject"><a href="9361f12.large.jpg"><img src="9361f12.jpg"></a><div class="caption"><p>
Figure 12. RCU Prevents Priority Inversion
</p></div></div><p>
This combination of priority inheritance and RCU permits the -rt patchset
to provide real-time latencies on mid-range multiprocessors.  But priority
inheritance is not a panacea.  For example, one could imagine applying some
form of priority inheritance to real-live users who might be blocking
high-priority processes, as shown in Figure 13.  However, I would rather
we did not.
</p><div       class="mediaobject"><a href="9361f13.large.jpg"><img src="9361f13.jpg"></a><div class="caption"><p>
Figure 13. Priority Boosting for Users?
</p></div></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x214b580.0x254fd38"></a>
Parallel Real-Time Programming Summary</h2></div></div><p>
I hope I have convinced you that the -rt patchset greatly advances
Linux's parallel real-time capabilities, and that Linux is quickly
becoming capable of supporting the parallel real-time applications that
are appearing in embedded environments.  Parallel real-time programming
is decidedly nontrivial.  In fact, many exciting challenges lie ahead
in this field, but it is far from impossible.
</p><p>
But there are a number of real-time operating systems, and a few even
provide some SMP support.  What is special about real-time Linux?
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x214b580.0x254fe98"></a>
Myth 5: There Is No Connection between Real-Time and Enterprise
Systems</h2></div></div><p>
To test the fifth and final myth, and to show just what is special
about real-time Linux, let's first outline the -rt patchset's place in
the real-time pantheon.
</p><p>
The -rt patchset turns Linux into an extremely capable real-time system.  Is
Linux suited to all purposes? The answer is clearly no, as can be seen
from Figure 14.  With the -rt patchset, Linux can achieve scheduling
latencies down to a few tens of microseconds&mdash;an impressive feat, to
be sure, but some applications need even more.  Systems with very tight
hand-coded assembly-language loops might achieve sub-microsecond response
times, at which point memory and I/O-system latencies loom large.  Below
this point comes the realm of special-purpose digital hardware, and
below that the realm of analog microwave and photonics devices.
</p><div       class="mediaobject"><a href="9361f14.large.jpg"><img src="9361f14.jpg"></a><div class="caption"><p>
Figure 14. Real-Time Capability Triangle
</p></div></div><p>
However, Linux's emerging real-time capabilities are sufficient for
the vast majority of real-time applications.  Furthermore, Linux brings
other strengths to the real-time table, including full POSIX semantics,
a complete set of both open-source and proprietary applications, a high
degree of configurability, and a vibrant and productive community.
</p><p>
In addition, real-time Linux forges a bond between the real-time and
enterprise communities.  This bond will become tighter as enterprise
applications face increasing real-time requirements.  These requirements
are already upon us&mdash;for example, Web retailers find that they
lose customers when response times extend beyond a few seconds.  A few
seconds might seem like a long time, but not when you 1) subtract off
typical Internet round-trip times and 2) divide by an increasingly large
numbers of layers, including firewalls, IP load levelers, Web servers,
Web-application servers, XML accelerators and database servers&mdash;across
multiple organizations.  The required per-machine response times fall
firmly into real-time territory.
</p><p>
Web 2.0 mashups will only increase the pressure on per-machine latencies,
because such mashups must gather information from multiple Web sites, so
that the slowest site controls the overall response time.  This pressure
will be most severe in cases when information gathered from one site
is used to query other sites, thus serializing the latencies.
</p><p>
We are witnessing nothing less than the birth of a new kind of real time:
enterprise real time.  What exactly is enterprise real time? Enterprise
real time is defined by developer and user requirements, as might be
obtained from the real-time questions listed in the discussion of Myth 3.
Some of these requirements would specify latencies and guarantees
(hard or soft) for various operations, while others would surround
the ecosystem, where real-time Linux's rich array of capabilities,
environments, applications and supported hardware really shine.
</p><p>
Of course, even the rich real-time-Linux ecosystem cannot completely
remove the need for special-purpose hardware and software.  However,
the birth of enterprise real time will provide a new-found ability to
share software between embedded and enterprise systems.  Such sharing
will greatly enrich both environments.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x214b580.0x2550368"></a>
Future Prospects</h2></div></div><p>
Impressive as it is, real-time Linux with the -rt patchset
focuses primarily on user-process scheduling and interprocess
communication.  Perhaps the future holds real-time protocol stacks or
filesystems, and perhaps also greater non-real-time performance and
scalability while still maintaining real-time response, allowing
electrical power to be conserved by consolidating real-time and
non-real-time workloads onto a single system.
</p><p>
However, real-time applications and environments are just starting to
appear on Linux, both from proprietary vendors and F/OSS communities.  For
example, existing real-time Java environments require that real-time
programs avoid the garbage collector, making it impossible to use Java's
standard runtime libraries.  IBM recently announced a Java JVM that
meets real-time deadlines even when the garbage collector is running,
allowing real-time code to use standard libraries.  This JVM is expected
to ease coding of real-time systems greatly and to ease conversion of
older real-time applications using special-purpose languages, such as ADA.
</p><p>
In addition, there are real-time audio systems, SIP servers and
object brokers, but much work remains to provide a full set of real-time
Web servers, Web application servers, database kernels and so on.  Real-time
applications and environments are still few and far between.
</p><p>
I very much look forward to participating in&mdash;and making use
of&mdash;the increasing SMP-real-time capability supported by everyday computing
devices!
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x214b580.0x2550578"></a>
Acknowledgements</h2></div></div><p>
No article mentioning the -rt patchset would be complete without a note
of thanks to Ingo Molnar, Thomas Gleixner, Sven Deitrich, K. R. Foley,
Gene Heskett, Bill Huey, Esben Neilsen, Nick Piggin, Steven Rostedt,
Michal Schmidt, Daniel Walker and Karsten Wiese.  I also owe a debt of
gratitude to Ted Ts'o, Darren Hart, Dinakar Guniguntala, John Stultz,
Vernon Mauery, Jennifer Monk, Sripathi Kodi, Tim Chavez, Vivek Pallantla
and Hugh Miller for many valuable real-time-Linux words and deeds.  I am
likewise grateful to David Bacon and his real-time-GC-research team and to
Boas Betzler for many productive conversations.  We all owe Bruce Jones,
John Kacur and Mark Brown many thanks for their invaluable service
rendering this article human-readable.  Finally, many thanks go to Daniel
Frye for his unstinting support of this effort.
</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x214b580.0x2550680"></a>
Legal Statement</h2></div></div><p>
This work represents the view of the author and does not necessarily
represent the view of IBM.
</p><p>
Intel is a registered trademark of Intel Corporation or its subsidiaries
in the United States and other countries.
</p><p>
Java and all Java-based trademarks are trademarks of Sun Microsystems,
Inc., in the United States, other countries or both.
</p><p>
Linux is a registered trademark of Linus Torvalds in the United States,
other countries or both.
</p><p>
Other company, product or service names may be trademarks or service
marks of others.
</p></div></div>
<div class="authorblurb"><p>
Paul E. McKenney is a Distinguished Engineer with IBM's Linux
Technology Center.  He has worked on NUMA, SMP and real-time
algorithms and, in particular, RCU for longer than he cares
to admit.  In his spare time, he jogs and supports the usual
house-wife-and-kids habit.
</p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../153/toc153.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>