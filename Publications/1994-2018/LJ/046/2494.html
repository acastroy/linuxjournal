<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"><html><head><META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>Linux Helps Bring Titanic to Life</title><link rel="stylesheet" href="../css/archive.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.57.0"><meta name="description" content="&#10;    Digital Domain uses Linux to create high-tech visual effects for the movies.&#10;    "><link rel="stylesheet" href="../../css/archive.css" type="text/css"><script type="text/javascript" src="../../js/archive.js"></script><script type="text/javascript" src="../../js/highlight.js"></script></head><body onload="search_highlight();">
  <div class="headerdiv">
    <a href="../../index.html">
      <img class="topimg" src="../../images/CD_HeaderBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="tophrdiv">
  </div>
  
  <div id="top_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  <div class="article" lang="en"><div class="titlepage"><div><h1 class="title"><a name="N0x2556580.0x264dab0"></a>Linux Helps Bring Titanic to Life</h1></div><div><div class="authorgroup"><div class="author"><h3 class="author">Daryll Strauss</h3></div><div class="author"><h3 class="author">Wook</h3></div><div class="issuemoyr">Issue #46, February 1998</div></div></div><div><p>
    Digital Domain uses Linux to create high-tech visual effects for the movies.
    </p></div></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2556580.0x264e5b0"></a></h2></div></div><p>Digital Domain is an advanced
full-service production studio located in Venice, California.
There, we generate visual effects for feature films and commercials
as well as new media applications. Our feature film credits include
<span   class="emphasis"><em>Interview with the Vampire</em></span>, <span   class="emphasis"><em>True
Lies</em></span>, <span   class="emphasis"><em>Apollo 13</em></span>, <span   class="emphasis"><em>Dante's
Peak</em></span> and <span   class="emphasis"><em>The Fifth Element</em></span>. Our
commercial credits are challenging to count, much less list here
(see the web site at http://www.d2.com/). While we are best known
for the excellent technical quality of our work, we are also well
respected for our creative contributions to our assignments.
</p><p>The film <span   class="emphasis"><em>Titanic</em></span> (written and directed
by James Cameron) opened in theaters December 19, 1997. Set on the
Titanic during its first and final voyage across the Atlantic
ocean, this tale had to be recreated on the screen in all the
splendor and drama of both the ship and the tragedy. Digital Domain
was selected to produce a large number of extraordinarily
challenging visual effects for this demanding film.</p><p><a href="2494f1.jpg" target="_self"><span   class="bold"><b>Figure 1.
Computer Generated Image of the Titanic</b></span></a></p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2556580.0x264ea28"></a>The Task</h2></div></div><p>Digital visual effects are a large portion of our work. For
many digital effects shots, original photographic images are first
shot on film (using conventional cinematic methods) and then
scanned into the computer. Each &ldquo;cut&rdquo; or &ldquo;scene&rdquo; is set up as a
collection of directories with an &ldquo;element&rdquo; directory for all the
photographic passes that contribute to the final scene. Each frame
of film is stored as a separate file on a central file
server.</p><p>A digital artist then begins working on the shot. The work
may involve creating whole new elements such as animating and
rendering 3D models or modifying existing elements such as painting
out a wire or isolating the areas of interest in the original
film.</p><p>This work is done at the artist's desktop (often on an SGI or
NT workstation). Once the setup for this work is done, the process
is repeated for each frame of the shot. This batch processing is
done on all the available CPUs in the facility, often in parallel
and requires a distributed file system and uniform data overview. A
goal of this processing is to remain platform independent whenever
possible.</p><p>Finally, once all the elements are created, the final image
is &ldquo;composited&rdquo;. During this step the individual elements are color
corrected to match the original photography, spatially coordinated
and layered to create the final image. Again, the set up for
compositing work is usually done on a desktop SGI, and the batch
processing is done throughout the facility.</p><p>Since building a full-scale model of the Titanic would have
been prohibitively expensive, only a portion of the ship was built
full size (by the production staff), and miniatures were used for
the rest of the scenes. To this model we added other elements of
the scene such as the ocean, people, birds, smoke and other details
that make the model appear to be docked, sailing or sunk in the
ocean. To this end, we built a 3D model and photographed 2D
elements to simulate underwater, airborne and land-based
photography.</p><p>During the work on <span   class="emphasis"><em>Titanic</em></span> the facility
had approximately 350 SGI CPUs, 200 DEC Alpha CPUs and 5 terabytes
of disk all connected by a 100Mbps or faster network.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2556580.0x264ed40"></a>The Analysis</h2></div></div><p>Our objective is always to create the highest quality images
within financial and schedule constraints. Image creation is
accomplished in two phases. In the first phase, the digital artist
works at an interactive workstation utilizing specific,
sophisticated software packages and specific high-performance
hardware. During the second phase the work is processed in batch
mode on as many CPUs as possible, regardless of vintage, location
or features to enhance interactive performance.</p><p>It is difficult to improve on that first, interactive phase.
The digital artists require certain packages that are not always
available on other platforms. Even if similar packages are
available, there is a significant cost associated with
interoperating between them.</p><p>Another problem is that some of the packages require certain
high-end (often 3D) hardware acceleration. That same quality and
performance of 3D acceleration may not be available on other
platforms.</p><p>In the batch-processing phase, improvements are more easily
found, since basic requirements are high-bandwidth computation,
access to large storage and a fast network. If the appropriate
applications are available, we can improve that part of the
process. Even in cases where only a subset of the applications are
available on a particular platform, using that platform gives us
the ability to partition work flow to improve access to resources
in general.</p><p>We rapidly concluded the DEC Alpha-based systems served our
batch-processing needs very well. They provide extremely high
floating-point performance in commodity packaging. We were able to
identify certain floating-point-intensive applications as port
targets. The Alpha systems could be configured with large amounts
of memory and fast networking at extremely attractive price points.
Overall, the DEC Alpha had the best price/performance match for our
needs.</p><p>The next question was which operating system to use. We had
the usual choices: Windows/NT, DEC UNIX and Linux. We knew which
programs we needed to run on the systems, so we assembled systems
of each type and proceeded to evaluate their suitability for the
various tasks we needed to complete for this production.</p><p>Windows NT had several shortfalls. First, our standard
applications, which normally run on SGI hardware, were not
available under NT. Our software staff could port the tools, but
that solution would be quite expensive. NT also had several other
limitations; it didn't support an automounter, NFS or symbolic
links, all of which are critical to our distributed storage
architecture. There were third-party applications available to fill
some of these holes, but they added to the cost and, in many cases,
did not perform well in handling our general computing
needs.</p><p>Digital UNIX performed very well and integrated nicely into
our environment. The biggest limitations of Digital UNIX were cost
and lack of flexibility. We would be purchasing and reconfiguring a
large number of systems. Separately purchasing Digital UNIX for
each system would have been time consuming and expensive. Digital
UNIX also didn't have certain extensions we required and could not
provide them in an acceptable time frame. For example, we needed to
communicate with our NT-based file servers, connect two unusual
varieties of tape drives and allow large numbers of users on a
single system; none are supported by Digital UNIX.</p><p>Linux fulfilled the task very well. It handled every job we
threw at it. During our testing phase, we used its ability to
emulate Digital UNIX applications to benchmark standard
applications and show that its performance would meet our needs.
The flexibility of the existing devices and available source code
gave Linux a definitive advantage.</p><p>The downside of Linux was the engineering effort required to
support it. We knew that we would need to dedicate one engineer to
support these systems during their set up. Fortunately, we had
engineers with significant previous experience with Linux on Intel
systems (the author and other members of the system-administration
staff) and enough Unix-system experience to make any required
modifications. We carefully tested a variety of hardware to make
sure all were completely compatible with Linux.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2556580.0x264f160"></a>Numerology and Fate</h2></div></div><p>The Linux distribution used was Red Hat 4.1. At that time Red
Hat was shipping Linux 2.0.18, which didn't support the PC164
mainboard, so the first thing we had to do was upgrade the kernel.
During our testing we tracked down a number of problems with
devices and kept up with both the 2.0 and 2.1 series of kernels. We
ended up sticking with 2.1.42 with a few patches. We also decided
on the NCR 810 SCSI card with the BSD-based driver and the SMC
100MB Ethernet card with the de4x5 driver. It turned out to be a
very stable configuration, but there was one serious floating-point
problem that caused our water-rendering software to die with an
unexpected floating-point exception.</p><p>This turned out to be a tricky problem to fix and didn't make
it into the kernel sources until 2.0.31-pre5 and 2.1.43. The Alpha
kernel contains code to catch floating-point exceptions and to
handle them according to the IEEE standard. That code failed to
handle one of the floating-point instructions that could generate
an exception. As a result, when that case occurred, the application
would exit with a floating-point exception. Once fixed, our
applications ran quite smoothly on the Alpha systems.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2556580.0x264f2c0"></a>The Implementation</h2></div></div><p>At this point, the decision was made to purchase 160 433MHz
DEC Alpha systems from Carrera Computers of Newport Beach,
California. Of those 160 machines, 105 of the machines are running
Linux, the other 55 are running NT. The machines are connected with
100Mbps Ethernet to each other and to the rest of our
facility.</p><p>The staff at Carrera was extraordinarily helpful and provided
inestimable support for our project. This support began at the
factory, with follow-up support through delivery, support and
repair.</p><p>We created a master disk, which we provided to Carrera, along
with a single initialization script that would configure the
generic master disk to one of the 160 unique personalities by
setting up parameters such as the system name and IP address.
Carrera built, configured and burned-in the machine, then logged in
as a special user causing the setup script to execute. When the
script completed, the machine automatically shut down.</p><p>This process made configuring the machines easy for both
Carrera and us. When the hosts arrived, we just plugged them in and
flipped the switch, and they came up on the network. All 160
machines are housed in a small room at Digital Domain in ten 19
inch racks. They are all connected to a central screen, keyboard
and mouse via a switching system to allow an operator to sit in the
middle of the room and work on the console of any machine in the
room.</p><p><a href="2494f2.jpg" target="_self"><span   class="bold"><b>Figure 2.
Digital Domain Computer Room</b></span></a></p><p>The room was assembled in a time period of two weeks
including the installation of the electrical, computing and
networking. The time spent creating the initialization script was
extremely well spent as it allowed the machines to be dropped in
place with relatively little trouble. At that point we began
running the <span   class="emphasis"><em>Titanic</em></span> work through the &ldquo;Render
Ranch&rdquo; of Alphas.</p><p>The first part of this work partition was to simulate and
render the water elements. We knew that the water elements were
computationally very expensive, so this process was one of the
major reasons for purchasing the Alphas.</p><p>These jobs computed for approximately 45 minutes and then
generated several hundred megabytes of image data to be stored on
central storage servers. Intermediate data was stored on the local
SCSI disk of the Alpha. The floating-point power of the DEC Alpha
made jobs run about 3.5 times faster than on our old SGI
systems.</p><p>As the water rendering completed, the task load then switched
to compositing. These jobs were more I/O bound, because they had to
read elements from disks on servers spread around the facility and
combine them into frames to be stored centrally. Even so, we still
saw improvements of a factor of two for these tasks.</p><p>We were extremely pleased with the results. Between the
beginning of June and the end of August, the Alpha Linux systems
processed over three hundred thousand frames. The systems were up
and running 24 hours a day, seven days a week. There were no
extended downtimes, and many of the machines were up for more than
a month at a time.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2556580.0x264f7e8"></a>The Problems</h2></div></div><p>We addressed a number of different problems using a variety
of techniques. Some of the problems were Alpha specific, and some
were issues for the Linux community at large. Hopefully, these
issues will help others in the same position and provide feedback
for the Linux community.</p><p>Hardware compatibility, particularly with Alpha Linux, is
still a problem. Carrera was very cooperative about sending us
multiple card varieties, so that we could do extensive testing. The
range of choices was large enough that we were able to find a
combination that worked. We had to pay careful attention to which
products we were using, as the particular chip revision made a
difference in one case.</p><p>The floating-point problem (discussed above) was the toughest
problem we had to address. We didn't expect to find this kind of
problem when we started the project. This was a long-standing bug
that had never been tracked down&mdash;we attribute this fact to the
relatively small Alpha Linux community.</p><p>Linux software for Alpha seems to be less tested than the
equivalent software for the Intel processors&mdash;again, a function of
the user-base size. It was exacerbated by the fact that Alpha Linux
uses glibc instead of libc5, which introduced problems in our code
and, we suspect, in other packages.</p><p>We had a number of small configuration issues with respect to
the size of our facility. Most of these were just parameter changes
in the kernel, but they took some effort to track down. For
example, we had to increase the number of simultaneously mounted
file systems (64 was not sufficient). Also, NFS directory reads
were expected to fit within one page (4K on Intel, 8K on Alpha); we
had to double this number to support the average number of frames
stored in a single directory.</p><p>Boot management under Linux Alpha was more difficult than we
would have liked. We felt the documentation needed improvements to
make it more useful. Boot management required extensive knowledge
of ARC, MILO and Linux to make it work. ARC requires entering a
reasonably large amount of data to get MILO to boot. MILO worked
well and provided a good set of options, but we never managed to
get soft reboots to operate correctly. We've been working with the
engineers at DEC to improve some of these issues.</p><p>The weakest link in the current Linux kernel appeared to be
the NFS implementation, resulting in most of our system crashes. We
generally had a large number of file systems mounted
simultaneously, and those file systems were often under heavy load.
When central servers died or had problems, the Linux systems didn't
recover. The common symptoms of these problems were stale NFS
handles and kernel hangs. When all the servers were running, the
Linux boxes worked correctly. Overall, the NFS implementation
worked, but it should be more robust.</p></div><div class="simplesect" lang="en"><div class="titlepage"><div><h2 class="title"><a name="N0x2556580.0x264fb00"></a>Conclusion</h2></div></div><p>The Linux systems worked incredibly well for our problems.
The cost benefit was overwhelmingly positive even including the
engineering resources we devoted to the problems. The Alpha Linux
turned out to be slightly more difficult than first expected, but
the state of Alpha Linux is improving very rapidly and should be
substantially better now.</p><p>Digital Domain will continue to improve and expand the tools
we have available on these systems. We are engendering the
development of more commercial and in-house applications available
on Linux. We are requesting that vendors port their applications
and libraries. At this time, the Linux systems are only used for
batch processing, but we expect our compositing software to be used
interactively by our digital artists. This software does not
require dedicated acceleration hardware, and the speed provided by
the Alpha processor is a great benefit to productivity.</p><p>Feature film and television visual effects development has
provided a high-performance, cost-sensitive, proving ground for
Linux. We believe that the general purpose nature of the platform
coupled with commodity pricing gives it wide application in areas
outside our industry. The low entry cost, versatility and
interoperability of Linux is sufficiently attractive to warrant
more extensive investigation, experimentation and deployment. We
are currently at the forefront of that development within our
industry and hope to be joined shortly by our peers.</p><div class="table"><a name="N0x2556580.0x264fcb8"></a><p class="title"><b></b></p><table     summary="" border="1"><colgroup><col></colgroup><tbody><tr><td><p><span   class="bold"><b>Why Risk Linux? A Production
Perspective</b></span>
</p><p>by Wook</p><p>Currently, Digital Domain's core business is as a premier
provider of visual effects creativity and services to the feature
film and commercial production industries. As such, we often take a
conservative approach to changes in infrastructure and
methodologies in order to meet aggressive delivery schedules and
the most demanding standards of product quality.</p><p>During the course of work on several recent feature film
productions, we encountered situations where our installed base of
equipment was not adequate to meet changing production schedules
and dynamic visual effects requirements (in terms of increasing
magnitude of effort and complexity). We needed to meet these
challenges head on without impacting the existing pipeline and
without creating new methodologies or systems which would require
re-engineering or re-training. Linux Alpha helped us overcome these
challenges both cost effectively and quickly (a rare
combination).</p><p>Selecting Linux as part of the production pipeline for the
film <span   class="emphasis"><em>Titanic</em></span> required several goals to be met.
If we had not met these requirements, it is unlikely we would have
been able to deliver sufficient computing resources in a timely
fashion to the production. We needed interoperability and, to a
certain degree, compatibility with our SGI/Irix-based systems.
Interoperability and compatibility with Linux had been demonstrated
during a previous effort (<span   class="emphasis"><em>Dante's Peak</em></span>). We
ported critical infrastructure elements (to support distributed
processing) to the Linux environment in days, not weeks, using
existing staff. The developers of these tools were able to rapidly
deploy to the Linux environment, demonstrating that we could
leverage that environment in short order. We needed performance, as
the schedule for the production, as well as the magnitude of the
work implied a 100% or more increase in studio processing capacity.
As we had shown that Alpha Linux provided a factor of three to four
over our SGI systems (see main article), it was possible to deliver
that increased level of performance while physically constrained
(air, power and floor space) within our current facility.</p><p>As to cost effectiveness, we would have needed more than
twice as many Intel machines as Alphas to meet our performance
goals. SGI was a valid contender, but could not compete on a price
per CPU basis. We also needed a viable structure for delivery,
installation and support. Carrera Computers had proven their
ability to supply and support us in a timely and cost-effective
manner prior to this order, and that company continued to provide
an extraordinary level of service throughout the
<span   class="emphasis"><em>Titanic</em></span> project.</p><p>All things considered, this risk paid off in substantial
dividends of project quality and time. Because the urgency of the
situation demanded that we think &ldquo;outside the box&rdquo;, we were able to
deliver a superior solution in a framework that was entirely
compatible with our normal operating models and that gave a
productivity increase equal to double that of our previous
infrastructure. The satisfaction in this success actually made up
for the stress incurred in risking one's job and career.</p></td></tr></tbody></table></div></div></div>
<div class="authorblurb"><p>
        <div       class="mediaobject"><img src="2494aa.jpg"></div>
        <span   class="bold"><b>Daryll Strauss</b></span>
        (<a href="mailto:daryll@d2.com">daryll@d2.com</a>)
        is a software engineer at Digital
        Domain. He has been hacking on Unix systems of one variety or
        another for the last 15 years, but he gets the most enjoyment out
        of computer graphics. He has spent the last five years working in
        the film industry doing visual effects for film.
      </p><p>
        <span   class="bold"><b>Wook</b></span>
        has been a software engineer for over 20 years, having
        discovered computers and became a complete geek at the age of 14.
        He has worked for many companies over those years, finally coming
        to rest at Digital Domain, where he was considered unfit for the
        task of software engineering and has been relegated to the position
        of Director of (Digital) Engineering.
      </p></div>

  <div class="toclinks">
    <a class="link1" href="../tocindex.html">Archive Index</a>
    <a class="link2" href="../046/toc046.html">Issue Table of Contents</a>
  </div>
  <div class="bottomhrdiv">
  </div>
  
  <div id="bottom_search">
  <table class="page_search" summary="">
    <tr>
      <td valign="top" align="left">
        <p class="small_shutdown"><a href="/.exit">Shutdown Archive web server</a></p>
      </td>
      <td valign="top" align="right">
        <form method="get" action="/zoom/search.cgi">
          <input type="hidden" name="zoom_sort" value="0" />
          <input type="hidden" name="zoom_xml" value="0" />
          <input type="hidden" name="zoom_per_page" value="10" />
          <input type="hidden" name="zoom_and" value="1" />
          Search: <input type="text" name="zoom_query" size="20" value="" class="zoom_searchbox" />
          <input type="submit" value="Submit" />
        </form>
      </td>
    </tr>
  </table>
  </div>
  
  <div class="footerdiv">
    <a href="../../index.html">
      <img class="bottomimg" src="../../images/CD_FooterBanner.png" alt="LJ Archive"/>
    </a>
  </div>
  
  <div class="copyright">
    Copyright &copy; 1994 - 2018 <cite>Linux Journal</cite>.  All rights reserved.
  </div>
  </body></html>